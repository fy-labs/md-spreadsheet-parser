{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Markdown Spreadsheet Parser","text":"<p> A robust, zero-dependency Python library for converting Excel to Markdown, parsing tables, and type-safe validation. </p> <p>md-spreadsheet-parser elevates Markdown tables from simple text to first-class data structures. It offers a precise, zero-dependency engine to parse, validate, and manipulate tables with the ease of a spreadsheet and the power of Python.</p> <p>\ud83c\udf89 Official GUI Editor Released: PengSheets</p> <p>We have transformed this library into an Excel-like interface for VS Code. Edit Markdown tables with sort, filter, and easy navigation directly in your editor.</p> <p></p> <p>\ud83d\ude80 Need a quick solution? Check out the Cookbook for copy-pasteable recipes (Excel conversion, Pandas integration, Markdown table manipulation, and more).</p> <p>Read in Japanese: \u65e5\u672c\u8a9e\u7248\u306f\u3053\u3061\u3089( README, Cookbook )</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Features</li> <li>Installation</li> <li>Usage<ul> <li>1. Basic Parsing</li> <li>YAML Frontmatter &amp; Metadata</li> <li>GFM Feature Support</li> <li>2. Type-Safe Validation<ul> <li>Pydantic Integration</li> </ul> </li> <li>3. JSON &amp; Dictionary Conversion</li> <li>4. Pandas Integration &amp; Export</li> <li>5. Excel Import</li> <li>6. Markdown Generation</li> <li>7. Advanced Features</li> <li>8. Advanced Type Conversion</li> <li>9. Robustness</li> <li>10. In-Cell Line Break Support</li> <li>11. Performance &amp; Scalability (Streaming API)</li> <li>12. Programmatic Manipulation</li> <li>13. Visual Metadata Persistence</li> <li>Command Line Interface (CLI)</li> </ul> </li> <li>Configuration</li> <li>Ecosystem</li> <li>License</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Pure Python &amp; Zero Dependencies: Lightweight and portable. Perfect for AWS Lambda Layers and constrained environments. Runs anywhere Python runs, including WebAssembly (Pyodide).</li> <li>Type-Safe Validation: Convert loose Markdown tables into strongly-typed Python <code>dataclasses</code> with automatic type conversion, including customizable boolean logic (I18N) and custom type converters.</li> <li>Markdown as a Database: Treat your Markdown files as Git-managed configuration or master data. Validate schema and types automatically, preventing human error in handwritten tables.</li> <li>Round-Trip Support: Parse to objects, modify data, and generate Markdown back. Perfect for editors.</li> <li>GFM Compliance: Supports GitHub Flavored Markdown (GFM) specifications, including column alignment (<code>:--</code>, <code>:--:</code>, <code>--:</code>) and correct handling of pipes within inline code (<code>`|`</code>).</li> <li>Robust Parsing: Gracefully handles malformed tables (missing/extra columns) and escaped characters.</li> <li>Multi-Table Workbooks: Support for parsing multiple sheets and tables from a single file, including metadata.</li> <li>JSON &amp; Dict Support: Column-level JSON parsing and direct conversion to <code>dict</code>/<code>TypedDict</code>.</li> <li>Pandas Integration: seamlessly create DataFrames from markdown tables.</li> <li>Excel Import &amp; Data Cleaning: Convert Excel/TSV/CSV to Markdown with intelligent merged cell handling. Automatically flattens hierarchical headers and fills gaps, turning \"dirty\" spreadsheets into clean, structured data.</li> <li>JSON-Friendly: Easy export to dictionaries/JSON for integration with other tools.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install md-spreadsheet-parser\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#1-basic-parsing","title":"1. Basic Parsing","text":"<p>Single Table Parse a standard Markdown table into a structured object.</p> <pre><code>from md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| Name | Age |\n| --- | --- |\n| Alice | 30 |\n| Bob | 25 |\n\"\"\"\n\nresult = parse_table(markdown)\n\nprint(result.headers)\n# ['Name', 'Age']\n\nprint(result.rows)\n# [['Alice', '30'], ['Bob', '25']]\n</code></pre> <p>Multiple Tables (Workbook) Parse a file containing multiple sheets (sections). By default, it auto-detects the workbook root (e.g., a single <code># Workbook</code> header) and calculates sheet headers automatically.</p> <pre><code>from md_spreadsheet_parser import parse_workbook, MultiTableParsingSchema\n\nmarkdown = \"\"\"\n# Workbook\n\n## Users\n| ID | Name |\n| -- | ---- |\n| 1  | Alice|\n\n## Products\n| ID | Item |\n| -- | ---- |\n| A  | Apple|\n\"\"\"\n\n# Use default schema\nschema = MultiTableParsingSchema()\nworkbook = parse_workbook(markdown, schema)\n\nfor sheet in workbook.sheets:\n    print(f\"Sheet: {sheet.name}\")\n    for table in sheet.tables:\n        print(table.rows)\n</code></pre> <p>Lookup API &amp; Metadata Retrieve sheets and tables directly by name, and access parsed metadata like descriptions.</p> <pre><code>from md_spreadsheet_parser import parse_workbook\n\nmarkdown = \"\"\"\n# Workbook\n\n## Sales Data\n\n### Q1 Results\nFinancial performance for the first quarter.\n\n| Year | Revenue |\n| ---- | ------- |\n| 2023 | 1000    |\n\"\"\"\n\nworkbook = parse_workbook(markdown)\n\n# Access by name\nsheet = workbook.get_sheet(\"Sales Data\")\nif sheet:\n    # Retrieve table by name (from ### Header)\n    table = sheet.get_table(\"Q1 Results\")\n\n    print(table.description)\n    # \"Financial performance for the first quarter.\"\n\n    print(table.rows)\n    # [['2023', '1000']]\n</code></pre> <p>Simple Scan Interface If you want to extract all tables from a document regardless of its structure (ignoring sheets and headers), use <code>scan_tables</code>.</p> <pre><code>from md_spreadsheet_parser import scan_tables\n\nmarkdown = \"\"\"\n| ID | Name |\n| -- | ---- |\n| 1  | Alice|\n\n... text ...\n\n| ID | Item |\n| -- | ---- |\n| A  | Apple|\n\"\"\"\n\n# Returns a flat list of all tables found\ntables = scan_tables(markdown)\nprint(len(tables)) # 2\n</code></pre> <p>File Loading Helpers</p> <p>For convenience, you can parse directly from a file path (<code>str</code> or <code>Path</code>) or file-like object using the <code>_from_file</code> variants:</p> <pre><code>from md_spreadsheet_parser import parse_workbook_from_file\n\n# Clean and easy\nworkbook = parse_workbook_from_file(\"data.md\")\n</code></pre> <p>Available helpers: - <code>parse_table_from_file(path_or_file)</code> - <code>parse_workbook_from_file(path_or_file)</code> - <code>scan_tables_from_file(path_or_file)</code></p>"},{"location":"#yaml-frontmatter-metadata","title":"YAML Frontmatter &amp; Metadata","text":"<p>The parser supports extracting YAML frontmatter from the beginning of a document.  If the frontmatter contains a <code>title</code> property, it is automatically treated as the document's primary H1 heading (<code>Workbook.name</code>), and its keys are stored in <code>Workbook.metadata</code>. Frontmatter without a <code>title</code> is ignored and not treated as a Workbook.</p> <pre><code>markdown = \"\"\"---\ntitle: My Project\nauthor: Alice\n---\n## Sheet 1\n| A |\n|---|\n| 1 |\n\"\"\"\nworkbook = parse_workbook(markdown)\nprint(workbook.name)          # \"My Project\"\nprint(workbook.metadata)      # {\"title\": \"My Project\", \"author\": \"Alice\"}\n</code></pre>"},{"location":"#gfm-feature-support","title":"GFM Feature Support","text":"<p>The parser strictly adheres to GitHub Flavored Markdown (GFM) specifications for tables.</p> <p>Column Alignment Alignment markers in the separator row are parsed and preserved.</p> <pre><code>markdown = \"\"\"\n| Left | Center | Right |\n| :--- | :----: | ----: |\n| 1    | 2      | 3     |\n\"\"\"\ntable = parse_table(markdown)\nprint(table.alignments)\n# [\"left\", \"center\", \"right\"]\n</code></pre> <p>Pipes in Code &amp; Escaping Pipes <code>|</code> inside inline code blocks (backticks) or escaped with <code>\\</code> are correctly treated as content, not column separators.</p> <pre><code>markdown = \"\"\"\n| Code  | Escaped |\n| ----- | ------- |\n| `a|b` | \\|      |\n\"\"\"\ntable = parse_table(markdown)\n# table.rows[0] == [\"`a|b`\", \"|\"]\n</code></pre>"},{"location":"#2-type-safe-validation-recommended","title":"2. Type-Safe Validation (Recommended)","text":"<p>The most powerful feature of this library is converting loose markdown tables into strongly-typed Python objects using <code>dataclasses</code>. This ensures your data is valid and easy to work with.</p> <pre><code>from dataclasses import dataclass\nfrom md_spreadsheet_parser import parse_table, TableValidationError\n\n@dataclass\nclass User:\n    name: str\n    age: int\n    is_active: bool = True\n\nmarkdown = \"\"\"\n| Name | Age | Is Active |\n|---|---|---|\n| Alice | 30 | yes |\n| Bob | 25 | no |\n\"\"\"\n\ntry:\n    # Parse and validate in one step\n    users = parse_table(markdown).to_models(User)\n\n    for user in users:\n        print(f\"{user.name} is {user.age} years old.\")\n        # Alice is 30 years old.\n        # Bob is 25 years old.\n\nexcept TableValidationError as e:\n    print(e)\n</code></pre> <p>Features: *   Type Conversion: Automatically converts strings to <code>int</code>, <code>float</code>, <code>bool</code> using standard rules. *   Boolean Handling (Default): Supports standard pairs out-of-the-box: <code>true/false</code>, <code>yes/no</code>, <code>on/off</code>, <code>1/0</code>, and native GFM Task Lists <code>[x]/[ ]</code>. (See Advanced Type Conversion for customization). *   Optional Fields: Handles <code>Optional[T]</code> by converting empty strings to <code>None</code>. *   Validation: Raises detailed errors if data doesn't match the schema.</p>"},{"location":"#pydantic-integration","title":"Pydantic Integration","text":"<p>For more advanced validation (email format, ranges, regex), you can use Pydantic models instead of dataclasses. This feature is enabled automatically if <code>pydantic</code> is installed.</p> <pre><code>from pydantic import BaseModel, Field, EmailStr\n\nclass User(BaseModel):\n    name: str = Field(alias=\"User Name\")\n    age: int = Field(gt=0)\n    email: EmailStr\n\n# Automatically detects Pydantic model and uses it for validation\nusers = parse_table(markdown).to_models(User)\n</code></pre> <p>The parser respects Pydantic's <code>alias</code> and <code>Field</code> constraints.</p>"},{"location":"#3-json-dictionary-conversion","title":"3. JSON &amp; Dictionary Conversion","text":"<p>Sometimes you don't want to define a full Dataclass or Pydantic model, or you have columns containing JSON strings.</p> <p>Simple Dictionary Output Convert tables directly to a list of dictionaries. Keys are derived from headers.</p> <pre><code># Returns list[dict[str, Any]] (Values are raw strings)\nrows = parse_table(markdown).to_models(dict)\nprint(rows[0])\n# {'Name': 'Alice', 'Age': '30'}\n</code></pre> <p>TypedDict Support Use <code>TypedDict</code> for lightweight type safety. The parser uses the type annotations to convert values automatically.</p> <pre><code>from typing import TypedDict\n\nclass User(TypedDict):\n    name: str\n    age: int\n    active: bool\n\nrows = parse_table(markdown).to_models(User)\nprint(rows[0])\n# {'name': 'Alice', 'age': 30, 'active': True}\n</code></pre> <p>Column-Level JSON Parsing If a field is typed as <code>dict</code> or <code>list</code> (in a Dataclass or Pydantic model), the parser automatically parses the cell value as JSON.</p> <pre><code>@dataclass\nclass Config:\n    id: int\n    metadata: dict  # Cell: '{\"debug\": true}' -&gt; Parsed to dict\n    tags: list      # Cell: '[\"a\", \"b\"]'      -&gt; Parsed to list\n\n# Pydantic models also work without Json[] wrapper\nclass ConfigModel(BaseModel):\n    metadata: dict\n</code></pre> <p>Limitations: *   JSON Syntax: The cell content must be valid JSON (e.g. double quotes <code>{\"a\": 1}</code>). Malformed JSON raises a <code>ValueError</code>. *   Simple Dict Parsing: <code>to_models(dict)</code> does not automatically parse inner JSON strings unless you use a custom schema. It only creates a shallow dictionary of strings.</p>"},{"location":"#4-pandas-integration-export","title":"4. Pandas Integration &amp; Export","text":"<p>This library is designed to be a bridge between Markdown and Data Science tools like Pandas.</p> <p>Convert to DataFrame (Easiest Way) The cleanest way to create a DataFrame is using <code>to_models(dict)</code>. This returns a list of dictionaries that Pandas can ingest directly.</p> <pre><code>import pandas as pd\nfrom md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| Date       | Sales | Region |\n|------------|-------|--------|\n| 2023-01-01 | 100   | US     |\n| 2023-01-02 | 150   | EU     |\n\"\"\"\n\ntable = parse_table(markdown)\n\n# 1. Convert to list of dicts\ndata = table.to_models(dict)\n\n# 2. Create DataFrame\ndf = pd.DataFrame(data)\n\n# 3. Post-Process: Convert types (Pandas usually infers strings initially)\ndf[\"Sales\"] = pd.to_numeric(df[\"Sales\"])\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\n\nprint(df.dtypes)\n# Date      datetime64[ns]\n# Sales              int64\n# Region            object\n</code></pre> <p>Convert from Type-Safe Objects If you want to validate data before creating a DataFrame (e.g., ensuring \"Sales\" is an integer during parsing), use a <code>dataclass</code> and then convert to Pandas.</p> <pre><code>from dataclasses import dataclass, asdict\n\n@dataclass\nclass SalesRecord:\n    date: str\n    amount: int\n    region: str\n\n# 1. Parse and Validate (Raises TableValidationError if invalid)\nrecords = parse_table(markdown).to_models(SalesRecord)\n\n# 2. Convert to DataFrame using asdict()\ndf = pd.DataFrame([asdict(r) for r in records])\n\n# The 'amount' column is already int64 because validation handled conversion\nprint(df[\"amount\"].dtype) # int64\n</code></pre> <p>JSON Export All result objects (<code>Workbook</code>, <code>Sheet</code>, <code>Table</code>) have a <code>.json</code> property that returns a dictionary structure suitable for serialization.</p> <pre><code>import json\n\n# Export entire workbook structure\nprint(json.dumps(workbook.json, indent=2))\n</code></pre>"},{"location":"#5-excel-import","title":"5. Excel Import","text":"<p>Import Excel data (via TSV/CSV or <code>openpyxl</code>) with intelligent handling of merged cells and hierarchical headers.</p> <p>[!NOTE] Importing from TSV/CSV text works with zero dependencies. Direct <code>.xlsx</code> file loading requires <code>openpyxl</code> (a user-managed optional dependency).</p> <p>Basic Usage</p> <p>\ud83d\ude80 See the Cookbook for more comprehensive recipes.</p> <pre><code>from md_spreadsheet_parser import parse_excel\n\n# From TSV/CSV (Zero Dependency)\ntable = parse_excel(\"Name\\tAge\\nAlice\\t30\")\n\n# From .xlsx (requires openpyxl)\nimport openpyxl\nwb = openpyxl.load_workbook(\"data.xlsx\")\ntable = parse_excel(wb.active)\n</code></pre> <p>Merged Header Handling</p> <p>When Excel exports merged cells, they appear as empty cells. The parser automatically forward-fills these gaps:</p> <pre><code>Excel (merged headers):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Category (3 cols)      \u2502  Info  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    A    \u2502    B    \u2502    C    \u2502   D    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n          \u2193 parse_excel()\n\nMarkdown:\n| Category | Category | Category | Info |\n|----------|----------|----------|------|\n| A        | B        | C        | D    |\n</code></pre> <p>2-Row Hierarchical Headers</p> <p>For complex headers with parent-child relationships, use <code>ExcelParsingSchema(header_rows=2)</code>:</p> <pre><code>Excel (2-row header):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       Info        \u2502      Metrics      \u2502  \u2190 Row 1 (Parent)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Name   \u2502   ID    \u2502  Score  \u2502  Rank   \u2502  \u2190 Row 2 (Child)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Alice  \u2502   001   \u2502   95    \u2502    1    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n          \u2193 parse_excel(schema=ExcelParsingSchema(header_rows=2))\n\nMarkdown:\n| Info - Name | Info - ID | Metrics - Score | Metrics - Rank |\n|-------------|-----------|-----------------|----------------|\n| Alice       | 001       | 95              | 1              |\n</code></pre> <p>Note: Currently supports up to 2 header rows. For deeper hierarchies, pre-process your data before parsing.</p> <p>Excel to Structured Objects (The \"Killer\" Feature)</p> <p>Don't just convert to text\u2014convert Excel directly to valid, type-safe Python objects in one step.</p> <pre><code>@dataclass\nclass SalesRecord:\n    category: str\n    item: str\n    amount: int  # Automatic string-to-int conversion\n\n# 1. Parse Excel (handles merged cells automatically)\n# 2. Validate &amp; Convert to objects\nrecords = parse_excel(ws).to_models(SalesRecord)\n\n# Now you have clean, typed data\nassert records[0].amount == 1000\n</code></pre> <p>Configuration</p> <p>Use <code>ExcelParsingSchema</code> to customize parsing behavior:</p> <pre><code>from md_spreadsheet_parser import parse_excel, ExcelParsingSchema\n\nschema = ExcelParsingSchema(\n    header_rows=2,\n    fill_merged_headers=True,\n    header_separator=\" / \"\n)\n\ntable = parse_excel(source, schema)\n</code></pre> Option Default Description <code>header_rows</code> <code>1</code> Number of header rows (1 or 2). <code>fill_merged_headers</code> <code>True</code> Forward-fill empty header cells. <code>header_separator</code> <code>\" - \"</code> Separator for flattened 2-row headers. <code>delimiter</code> <code>\"\\t\"</code> Column separator for TSV/CSV."},{"location":"#6-markdown-generation-round-trip","title":"6. Markdown Generation (Round-Trip)","text":"<p>You can modify parsed objects and convert them back to Markdown strings using <code>to_markdown()</code>. This enables a complete \"Parse -&gt; Modify -&gt; Generate\" workflow.</p> <pre><code>from md_spreadsheet_parser import parse_table, ParsingSchema\n\nmarkdown = \"| A | B |\\n|---|---| \\n| 1 | 2 |\"\ntable = parse_table(markdown)\n\n# Modify data\ntable.rows.append([\"3\", \"4\"])\n\n# Generate Markdown\n# You can customize the output format using a schema\nschema = ParsingSchema(require_outer_pipes=True)\nprint(table.to_markdown(schema))\n# | A | B |\n# | --- | --- |\n# | 1 | 2 |\n# | 3 | 4 |\n</code></pre>"},{"location":"#7-advanced-features","title":"7. Advanced Features","text":"<p>Metadata Extraction Configuration By default, the parser captures table names (level 3 headers) and descriptions. You can customize this behavior with <code>MultiTableParsingSchema</code>.</p> <pre><code>from md_spreadsheet_parser import MultiTableParsingSchema\n\nschema = MultiTableParsingSchema(\n    table_header_level=3,     # Treat ### Header as table name\n    capture_description=True  # Capture text between header and table\n)\n# Pass schema to parse_workbook...\n</code></pre>"},{"location":"#8-advanced-type-conversion","title":"8. Advanced Type Conversion","text":"<p>You can customize how string values are converted to Python objects by passing a <code>ConversionSchema</code> to <code>to_models()</code>. This is useful for internationalization (I18N) and handling custom types.</p> <p>Internationalization (I18N): Custom Boolean Pairs</p> <p>Configure which string pairs map to <code>True</code>/<code>False</code> (case-insensitive).</p> <pre><code>from md_spreadsheet_parser import parse_table, ConversionSchema\n\nmarkdown = \"\"\"\n| User | Active? |\n| --- | --- |\n| Tanaka | \u306f\u3044 |\n| Suzuki | \u3044\u3044\u3048 |\n\"\"\"\n\n# Configure \"\u306f\u3044\" -&gt; True, \"\u3044\u3044\u3048\" -&gt; False\nschema = ConversionSchema(\n    boolean_pairs=((\"\u306f\u3044\", \"\u3044\u3044\u3048\"),)\n)\n\nusers = parse_table(markdown).to_models(User, conversion_schema=schema)\n# Tanaka.active is True\n</code></pre> <p>Custom Type Converters</p> <p>Register custom conversion functions for specific types. You can use ANY Python type as a key, including:</p> <ul> <li>Built-ins: <code>int</code>, <code>float</code>, <code>bool</code> (to override default behavior)</li> <li>Standard Library: <code>Decimal</code>, <code>datetime</code>, <code>date</code>, <code>ZoneInfo</code>, <code>UUID</code></li> <li>Custom Classes: Your own data classes or objects</li> </ul> <p>Example using standard library types and a custom class:</p> <pre><code>from dataclasses import dataclass\nfrom uuid import UUID\nfrom zoneinfo import ZoneInfo\nfrom md_spreadsheet_parser import ConversionSchema, parse_table\n\n@dataclass\nclass Color:\n    r: int\n    g: int\n    b: int\n\n@dataclass\nclass Config:\n    timezone: ZoneInfo\n    session_id: UUID\n    theme_color: Color\n\nmarkdown = \"\"\"\n| Timezone | Session ID | Theme Color |\n| --- | --- | --- |\n| Asia/Tokyo | 12345678-1234-5678-1234-567812345678 | 255,0,0 |\n\"\"\"\n\nschema = ConversionSchema(\n    custom_converters={\n        # Standard Library Types\n        ZoneInfo: lambda v: ZoneInfo(v),\n        UUID: lambda v: UUID(v),\n        # Custom Class\n        Color: lambda v: Color(*map(int, v.split(\",\")))\n    }\n)\n\ndata = parse_table(markdown).to_models(Config, conversion_schema=schema)\n# data[0].timezone is ZoneInfo(\"Asia/Tokyo\")\n# data[0].theme_color is Color(255, 0, 0)\n</code></pre> <p>Field-Specific Converters</p> <p>For granular control, you can define converters for specific field names, which take precedence over type-based converters.</p> <pre><code>def parse_usd(val): ...\ndef parse_jpy(val): ...\n\nschema = ConversionSchema(\n    # Type-based defaults (Low priority)\n    custom_converters={\n        Decimal: parse_usd \n    },\n    # Field-name overrides (High priority)\n    field_converters={\n        \"price_jpy\": parse_jpy,\n        \"created_at\": lambda x: datetime.strptime(x, \"%Y/%m/%d\")\n    }\n)\n\n# price_usd (no override) -&gt; custom_converters (parse_usd)\n# price_jpy (override)    -&gt; field_converters (parse_jpy)\ndata = parse_table(markdown).to_models(Product, conversion_schema=schema)\n</code></pre> <p>Standard Converters Library</p> <p>For common patterns (currencies, lists), you can use the built-in helper functions in <code>md_spreadsheet_parser.converters</code> instead of writing your own.</p> <pre><code>from md_spreadsheet_parser.converters import (\n    to_decimal_clean,        # Handles \"$1,000\", \"\u00a5500\" -&gt; Decimal\n    make_datetime_converter, # Factory for parse/TZ logic\n    make_list_converter,     # \"a,b,c\" -&gt; [\"a\", \"b\", \"c\"]\n    make_bool_converter      # Custom strict boolean sets\n)\n\nschema = ConversionSchema(\n    custom_converters={\n        # Currency: removes $, \u00a5, \u20ac, \u00a3, comma, space\n        Decimal: to_decimal_clean,\n        # DateTime: ISO format default, attach Tokyo TZ if naive\n        datetime: make_datetime_converter(tz=ZoneInfo(\"Asia/Tokyo\")),\n        # Lists: Split by comma, strip whitespace\n        list: make_list_converter(separator=\",\")\n    },\n    field_converters={\n        # Custom boolean for specific field\n        \"is_valid\": make_bool_converter(true_values=[\"OK\"], false_values=[\"NG\"])\n    }\n)\n</code></pre>"},{"location":"#9-robustness-handling-malformed-tables","title":"9. Robustness (Handling Malformed Tables)","text":"<p>The parser is designed to handle imperfect markdown tables gracefully.</p> <ul> <li>Missing Columns: Rows with fewer columns than the header are automatically padded with empty strings.</li> <li>Extra Columns: Rows with more columns than the header are automatically truncated.</li> </ul> <pre><code>from md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| A | B |\n|---|---|\n| 1 |       &lt;-- Missing column\n| 1 | 2 | 3 &lt;-- Extra column\n\"\"\"\n\ntable = parse_table(markdown)\n\nprint(table.rows)\n# [['1', ''], ['1', '2']]\n</code></pre> <p>This ensures that <code>table.rows</code> always matches the structure of <code>table.headers</code>, preventing crashes during iteration or validation.</p>"},{"location":"#10-in-cell-line-break-support","title":"10. In-Cell Line Break Support","text":"<p>The parser automatically converts HTML line breaks to Python newlines (<code>\\n</code>). This enables handling multiline cells naturally.</p> <p>Supported Tags (Case-Insensitive): - <code>&lt;br&gt;</code> - <code>&lt;br/&gt;</code> - <code>&lt;br /&gt;</code></p> <pre><code>markdown = \"| Line1&lt;br&gt;Line2 |\"\ntable = parse_table(markdown)\n# table.rows[0][0] == \"Line1\\nLine2\"\n</code></pre> <p>Round-Trip Support: When generating Markdown (e.g., <code>table.to_markdown()</code>), Python newlines (<code>\\n</code>) are automatically converted back to <code>&lt;br&gt;</code> tags to preserve the table structure.</p> <p>To disable this, set <code>convert_br_to_newline=False</code> in <code>ParsingSchema</code>.</p>"},{"location":"#11-performance-scalability-streaming-api","title":"11. Performance &amp; Scalability (Streaming API)","text":"<p>Do you really have a 10GB Markdown file?</p> <p>Probably not. We sincerely hope you don't. Markdown wasn't built for that.</p> <p>But if you do\u2014perhaps you're generating extensive logs or auditing standard converters\u2014this library has your back. While Excel gives up after 1,048,576 rows, <code>md-spreadsheet-parser</code> supports streaming processing for files of unlimited size, keeping memory usage constant.</p> <p>scan_tables_iter: This function reads the file line-by-line and yields <code>Table</code> objects as they are found. It does not load the entire file into memory.</p> <pre><code>from md_spreadsheet_parser import scan_tables_iter\n\n# Process a massive log file (e.g., 10GB)\n# Memory usage remains low (only the size of a single table block)\nfor table in scan_tables_iter(\"huge_server_log.md\"):\n    print(f\"Found table with {len(table.rows)} rows\")\n\n    # Process rows...\n    for row in table.rows:\n        pass\n</code></pre> <p>This is ideal for data pipelines, log analysis, and processing exports that are too large to open in standard spreadsheet editors.</p>"},{"location":"#12-programmatic-manipulation","title":"12. Programmatic Manipulation","text":"<p>The library provides immutable methods to modify the data structure. These methods return a new instance of the object with the changes applied, keeping the original object unchanged.</p> <p>Workbook Operations</p> <pre><code># Add a new sheet (creates a default table with headers A, B, C)\nnew_wb = workbook.add_sheet(\"New Sheet\")\n\n# Rename a sheet\nnew_wb = workbook.rename_sheet(sheet_index=0, new_name(\"Budget 2024\"))\n\n# Delete a sheet\nnew_wb = workbook.delete_sheet(sheet_index=1)\n</code></pre> <p>Sheet Operations</p> <pre><code># Rename sheet (direct method)\nnew_sheet = sheet.rename(\"Q1 Data\")\n\n# Update table (get a table and rename it)\ntable = sheet.get_table(\"Q1 Results\")\nif table:\n    new_table = table.rename(\"Old Results\")\n    # Replace the table in the sheet\n    new_sheet = sheet.replace_table(0, new_table)\n\n</code></pre> <p>Table Operations</p> <pre><code># Update a cell (automatically expands table if index is out of bounds)\nnew_table = table.update_cell(row_idx=5, col_idx=2, value=\"Updated\")\n\n# Delete a row (structural delete)\nnew_table = table.delete_row(row_idx=2)\n\n# Clear column data (keeps headers and row structure, empties cells)\nnew_table = table.clear_column_data(col_idx=3)\n</code></pre>"},{"location":"#13-visual-metadata-persistence","title":"13. Visual Metadata Persistence","text":"<p>The library supports persisting visual state (like column widths and filter settings) without altering the Markdown table structure itself. This is achieved via a hidden HTML comment appended after the table.</p> <pre><code>| A | B |\n|---|---|\n| 1 | 2 |\n\n&lt;!-- md-spreadsheet-table-metadata: {\"columnWidths\": [100, 200]} --&gt;\n</code></pre> <p>This ensures that: 1.  Clean Data: The table remains standard Markdown, readable by any renderer. 2.  Rich State: Compatible tools (like our VS Code Extension) can read the comment to restore UI state (column widths, hidden columns, etc.). 3.  Robustness: The parser automatically associates this metadata with the preceding table, even if separated by blank lines.</p>"},{"location":"#command-line-interface-cli","title":"Command Line Interface (CLI)","text":"<p>You can use the <code>md-spreadsheet-parser</code> command to parse Markdown files and output JSON. This is useful for piping data to other tools.</p> <pre><code># Read from file\nmd-spreadsheet-parser input.md\n\n# Read from stdin (pipe)\ncat input.md | md-spreadsheet-parser\n</code></pre> <p>Options: - <code>--scan</code>: Scan for all tables ignoring workbook structure (returns a list of tables). - <code>--root-marker</code>: Set the root marker explicitly (default: auto-detect). - <code>--sheet-header-level</code>: Set sheet header level (default: 2). - <code>--table-header-level</code>: Set table header level (default: 3). - <code>--capture-description</code>: Capture table descriptions (default: True). - <code>--column-separator</code>: Character used to separate columns (default: <code>|</code>). - <code>--header-separator-char</code>: Character used in the separator row (default: <code>-</code>). - <code>--no-outer-pipes</code>: Allow tables without outer pipes (default: False). - <code>--no-strip-whitespace</code>: Do not strip whitespace from cell values (default: False). - <code>--no-br-conversion</code>: Disable automatic conversion of <code>&lt;br&gt;</code> tags to newlines (default: False).</p>"},{"location":"#configuration","title":"Configuration","text":"<p>Customize parsing behavior using <code>ParsingSchema</code> and <code>MultiTableParsingSchema</code>.</p> Option Default Description <code>column_separator</code> <code>\\|</code> Character used to separate columns. <code>header_separator_char</code> <code>-</code> Character used in the separator row. <code>require_outer_pipes</code> <code>True</code> If <code>True</code>, generated markdown tables will include outer pipes. <code>strip_whitespace</code> <code>True</code> If <code>True</code>, whitespace is stripped from cell values. <code>convert_br_to_newline</code> <code>True</code> If <code>True</code>, <code>&lt;br&gt;</code> tags are converted to <code>\\n</code> (and back). <code>root_marker</code> <code>None</code> (MultiTable) Marker indicating start of data section. Defaults to auto-detect. <code>sheet_header_level</code> <code>2</code> (MultiTable) Header level for sheets. <code>table_header_level</code> <code>3</code> (MultiTable) Header level for tables. <code>capture_description</code> <code>True</code> (MultiTable) Capture text between header and table."},{"location":"#ecosystem","title":"Ecosystem","text":"<p>This parser is the core foundation of a new ecosystem: Text-Based Spreadsheet Management.</p> <p>It powers PengSheets, a rich VS Code extension that provides a full GUI Spreadsheet Editor for Markdown files.</p> <p>The Vision: \"Excel-like UX, Git-native Data\" By combining a high-performance editor with this robust parser, we aim to solve the long-standing problem of managing binary spreadsheet files in software projects. *   For Humans: Edit data with a comfortable, familiar UI (cell formatting, improved navigation, visual feedback). *   For Machines: Data is saved as clean, diff-able Markdown that this library can parse, validate, and convert into Python objects instantaneously.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License.</p>"},{"location":"COOKBOOK/","title":"Cookbook","text":"<p>This guide provides immediate solutions for common tasks.</p>"},{"location":"COOKBOOK/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation</li> <li>Read Tables from File</li> <li>Read Table from Text</li> <li>Excel Integration</li> <li>Pandas Integration</li> <li>Programmatic Editing</li> <li>Formatting &amp; Linting</li> <li>JSON Conversion</li> <li>Type-Safe Validation</li> </ol>"},{"location":"COOKBOOK/#1-installation","title":"1. Installation","text":"<pre><code>pip install md-spreadsheet-parser\n</code></pre>"},{"location":"COOKBOOK/#2-read-tables-from-file-recommended","title":"2. Read Tables from File (Recommended)","text":"<p>The easiest way to extract data from a Markdown file is using <code>scan_tables_from_file</code>. This works regardless of the file structure (ignoring headers like <code>#</code> or <code>##</code>).</p> <p>data.md</p> <pre><code>| ID | Name |\n| -- | ---- |\n| 1  | Alice |\n| 2  | Bob   |\n</code></pre> <p>Python</p> <pre><code>from md_spreadsheet_parser import scan_tables_from_file\n\n# Returns a list of Table objects\ntables = scan_tables_from_file(\"data.md\")\n\nfor table in tables:\n    print(table.rows)\n    # [['1', 'Alice'], ['2', 'Bob']]\n</code></pre>"},{"location":"COOKBOOK/#3-read-table-from-text-simple","title":"3. Read Table from Text (Simple)","text":"<p>If you have a markdown string, use <code>parse_table</code>.</p> <pre><code>from md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| ID | Name |\n| -- | ---- |\n| 1  | Alice |\n\"\"\"\n\ntable = parse_table(markdown)\nprint(table.headers) # ['ID', 'Name']\nprint(table.rows[0]) # ['1', 'Alice']\n</code></pre>"},{"location":"COOKBOOK/#4-excel-integration","title":"4. Excel Integration","text":""},{"location":"COOKBOOK/#excel-tsvcsv-markdown","title":"Excel (TSV/CSV) \u2192 Markdown","text":"<p>This is the easiest method! Just copy cells from Excel and paste them as a string.</p> <p>Convert Excel-exported TSV or CSV data to Markdown. Handles merged headers and in-cell newlines.</p> <pre><code>from md_spreadsheet_parser import parse_excel, ExcelParsingSchema\n\n# Paste your Excel data (TSV format)\ntsv_data = \"\"\"\nID\\tName\\tNotes\n1\\tAlice\\t\"Lines\ninclude\nnewlines\"\n2\\tBob\\tSimple\n\"\"\".strip()\n\ntable = parse_excel(tsv_data)\nprint(table.to_markdown())\n</code></pre> <p>With Merged Headers (Forward-Fill)</p> <pre><code># Excel merged cells export as: \"Category\\t\\t\\tInfo\"\ntsv = \"Category\\t\\t\\tInfo\\nA\\tB\\tC\\tD\"\ntable = parse_excel(tsv)\n# Headers: [\"Category\", \"Category\", \"Category\", \"Info\"]\n</code></pre> <p>With 2-Row Hierarchical Headers</p> <pre><code># Parent row: \"Info\\t\\tMetrics\\t\"\n# Child row:  \"Name\\tID\\tScore\\tRank\"\ntsv = \"Info\\t\\tMetrics\\t\\nName\\tID\\tScore\\tRank\\nAlice\\t001\\t95\\t1\"\ntable = parse_excel(tsv, ExcelParsingSchema(header_rows=2))\n# Headers: [\"Info - Name\", \"Info - ID\", \"Metrics - Score\", \"Metrics - Rank\"]\n</code></pre>"},{"location":"COOKBOOK/#excel-xlsx-markdown-with-openpyxl","title":"Excel (.xlsx) \u2192 Markdown (with openpyxl)","text":"<p>If you have <code>openpyxl</code> installed, you can pass Worksheets directly.</p> <pre><code># pip install openpyxl  # User-managed dependency\nimport openpyxl\nfrom md_spreadsheet_parser import parse_excel, ExcelParsingSchema\n\nwb = openpyxl.load_workbook(\"report.xlsx\", data_only=True)\nws = wb[\"SalesData\"]  # Select sheet by name\n\ntable = parse_excel(ws, ExcelParsingSchema(header_rows=2))\nprint(table.to_markdown())\n</code></pre>"},{"location":"COOKBOOK/#5-pandas-integration","title":"5. Pandas Integration","text":"<p>This library acts as a bridge between Markdown and Data Science tools.</p>"},{"location":"COOKBOOK/#markdown-pandas-dataframe","title":"Markdown -&gt; Pandas DataFrame","text":"<p>Convert parsed tables directly to a list of dictionaries, which Pandas can ingest.</p> <pre><code>import pandas as pd\nfrom md_spreadsheet_parser import scan_tables_from_file\n\ntables = scan_tables_from_file(\"data.md\")\ndf = pd.DataFrame(tables[0].to_models(dict))\n\nprint(df)\n#   ID   Name\n# 0  1  Alice\n# 1  2    Bob\n</code></pre>"},{"location":"COOKBOOK/#pandas-dataframe-markdown","title":"Pandas DataFrame -&gt; Markdown","text":"<p>Convert a Pandas DataFrame into a <code>Table</code> object to generate Markdown.</p> <pre><code>import pandas as pd\nfrom md_spreadsheet_parser import Table\n\n# 1. Setup your DataFrame\ndf = pd.DataFrame({\n    \"ID\": [1, 2],\n    \"Name\": [\"Alice\", \"Bob\"]\n})\n\n# 2. Convert to Table\n# Ensure all data is stringified for the parser\nheaders = df.columns.tolist()\nrows = df.astype(str).values.tolist()\n\ntable = Table(headers=headers, rows=rows)\n\n# 3. Generate Markdown\nprint(table.to_markdown())\n# | ID | Name |\n# | --- | --- |\n# | 1 | Alice |\n# | 2 | Bob |\n</code></pre>"},{"location":"COOKBOOK/#6-programmatic-editing-excel-like","title":"6. Programmatic Editing (Excel-like)","text":"<p>You can load a table, modify values based on logic (e.g., formulas), and save it back.</p> <pre><code>from md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| Item | Price | Qty | Total |\n|---|---|---|---|\n| Apple | 100 | 2 | |\n| Banana | 50 | 3 | |\n\"\"\"\n\ntable = parse_table(markdown)\n\n# Update \"Total\" column\n# 1. basic string parsing (or use to_models for type safety)\nnew_rows = []\nfor row in table.rows:\n    price = int(row[1])\n    qty = int(row[2])\n    total = price * qty\n\n    # Create new row with updated total\n    new_rows.append([row[0], row[1], row[2], str(total)])\n\n# 2. Create new table with updates\nupdated_table = Table(headers=table.headers, rows=new_rows)\nprint(updated_table.to_markdown())\n</code></pre>"},{"location":"COOKBOOK/#7-formatting-linting","title":"7. Formatting &amp; Linting","text":"<p>Read a messy, misaligned Markdown table and output it perfectly formatted.</p> <pre><code>from md_spreadsheet_parser import parse_table\n\n# Messy input\nmessy_markdown = \"\"\"\n|Name|Age|\n|---|---|\n|Alice|30|\n|Bob|25|\n\"\"\"\n\ntable = parse_table(messy_markdown)\n\n# Output clean Markdown\nprint(table.to_markdown())\n# | Name | Age |\n# | --- | --- |\n# | Alice | 30 |\n# | Bob | 25 |\n</code></pre>"},{"location":"COOKBOOK/#8-json-conversion","title":"8. JSON Conversion","text":"<p>Convert a table directly to a JSON string or list of dictionaries for API usage.</p> <pre><code>import json\nfrom md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| ID | Status |\n| -- | ------ |\n| 1  | Open   |\n\"\"\"\n\ntable = parse_table(markdown)\n\n# Convert to list of dicts\ndata = table.to_models(dict)\n\n# Dump to JSON\nprint(json.dumps(data, indent=2))\n# [\n#   {\n#     \"ID\": \"1\",\n#     \"Status\": \"Open\"\n#   }\n# ]\n</code></pre>"},{"location":"COOKBOOK/#9-type-safe-validation","title":"9. Type-Safe Validation","text":"<p>Convert loose text into strongly-typed Python objects.</p> <pre><code>from dataclasses import dataclass\nfrom md_spreadsheet_parser import parse_table\n\n@dataclass\nclass User:\n    id: int\n    name: str\n    active: bool = True\n\nmarkdown = \"\"\"\n| id | name | active |\n| -- | ---- | ------ |\n| 1  | Alice| yes    |\n| 2  | Bob  | no     |\n\"\"\"\n\nusers = parse_table(markdown).to_models(User)\n\nfor user in users:\n    print(f\"{user.name} (Active: {user.active})\")\n    # Alice (Active: True)\n    # Bob (Active: False)\n</code></pre>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#md_spreadsheet_parser","title":"<code>md_spreadsheet_parser</code>","text":""},{"location":"api/#md_spreadsheet_parser.ConversionSchema","title":"<code>ConversionSchema</code>  <code>dataclass</code>","text":"<p>Configuration for converting string values to Python types.</p> <p>Attributes:</p> Name Type Description <code>boolean_pairs</code> <code>tuple[tuple[str, str], ...]</code> <p>Pairs of strings representing (True, False). Case-insensitive.            Example: <code>((\"yes\", \"no\"), (\"on\", \"off\"))</code>.</p> <code>custom_converters</code> <code>dict[type, Callable[[str], Any]]</code> <p>Dictionary mapping ANY Python type to a conversion function <code>str -&gt; Any</code>.                You can specify:                - Built-in types: <code>int</code>, <code>float</code>, <code>bool</code> (to override default behavior)                - Standard library types: <code>Decimal</code>, <code>datetime</code>, <code>date</code>, <code>ZoneInfo</code>                - Custom classes: <code>MyClass</code>, <code>Product</code></p> <code>field_converters</code> <code>dict[str, Callable[[str], Any]]</code> <p>Dictionary mapping field names (str) to conversion functions.               Takes precedence over <code>custom_converters</code>.</p> Source code in <code>src/md_spreadsheet_parser/schemas.py</code> <pre><code>@dataclass(frozen=True)\nclass ConversionSchema:\n    \"\"\"\n    Configuration for converting string values to Python types.\n\n    Attributes:\n        boolean_pairs: Pairs of strings representing (True, False). Case-insensitive.\n                       Example: `((\"yes\", \"no\"), (\"on\", \"off\"))`.\n        custom_converters: Dictionary mapping ANY Python type to a conversion function `str -&gt; Any`.\n                           You can specify:\n                           - Built-in types: `int`, `float`, `bool` (to override default behavior)\n                           - Standard library types: `Decimal`, `datetime`, `date`, `ZoneInfo`\n                           - Custom classes: `MyClass`, `Product`\n        field_converters: Dictionary mapping field names (str) to conversion functions.\n                          Takes precedence over `custom_converters`.\n    \"\"\"\n\n    boolean_pairs: tuple[tuple[str, str], ...] = (\n        (\"true\", \"false\"),\n        (\"yes\", \"no\"),\n        (\"1\", \"0\"),\n        (\"on\", \"off\"),\n        (\"[x]\", \"[ ]\"),\n    )\n    custom_converters: dict[type, Callable[[str], Any]] = field(default_factory=dict)\n    field_converters: dict[str, Callable[[str], Any]] = field(default_factory=dict)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.ExcelParsingSchema","title":"<code>ExcelParsingSchema</code>  <code>dataclass</code>","text":"<p>Configuration for parsing Excel-exported data (TSV/CSV or openpyxl).</p> <p>Attributes:</p> Name Type Description <code>header_rows</code> <code>int</code> <p>Number of header rows (1 or 2).          If 2, headers are flattened to \"Parent - Child\" format.</p> <code>fill_merged_headers</code> <code>bool</code> <p>Whether to forward-fill empty header cells                  (for merged cells in Excel exports).</p> <code>delimiter</code> <code>str</code> <p>Column separator for TSV/CSV parsing. Default is tab.</p> <code>header_separator</code> <code>str</code> <p>Separator used when flattening 2-row headers.</p> Source code in <code>src/md_spreadsheet_parser/schemas.py</code> <pre><code>@dataclass(frozen=True)\nclass ExcelParsingSchema:\n    \"\"\"\n    Configuration for parsing Excel-exported data (TSV/CSV or openpyxl).\n\n    Attributes:\n        header_rows: Number of header rows (1 or 2).\n                     If 2, headers are flattened to \"Parent - Child\" format.\n        fill_merged_headers: Whether to forward-fill empty header cells\n                             (for merged cells in Excel exports).\n        delimiter: Column separator for TSV/CSV parsing. Default is tab.\n        header_separator: Separator used when flattening 2-row headers.\n    \"\"\"\n\n    header_rows: int = 1\n    fill_merged_headers: bool = True\n    delimiter: str = \"\\t\"\n    header_separator: str = \" - \"\n\n    def __post_init__(self):\n        if self.header_rows not in (1, 2):\n            raise ValueError(\"header_rows must be 1 or 2\")\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.MultiTableParsingSchema","title":"<code>MultiTableParsingSchema</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ParsingSchema</code></p> <p>Configuration for parsing multiple tables (workbook mode). Inherits from ParsingSchema.</p> <p>Attributes:</p> Name Type Description <code>root_marker</code> <code>str | None</code> <p>The marker indicating the start of the data section. If None, auto-detection is used: single H1 \u2192 Workbook, or fallback to \"# Tables\" / \"# Workbook\". Defaults to None.</p> <code>sheet_header_level</code> <code>int | None</code> <p>The markdown header level for sheets. If None, derived from workbook_level + 1. Defaults to None.</p> <code>table_header_level</code> <code>int | None</code> <p>The markdown header level for tables. If None, derived from workbook_level + 2. Defaults to None.</p> <code>capture_description</code> <code>bool</code> <p>Whether to capture text between the table header and the table as a description. Defaults to True.</p> Source code in <code>src/md_spreadsheet_parser/schemas.py</code> <pre><code>@dataclass(frozen=True)\nclass MultiTableParsingSchema(ParsingSchema):\n    \"\"\"\n    Configuration for parsing multiple tables (workbook mode).\n    Inherits from ParsingSchema.\n\n    Attributes:\n        root_marker (str | None): The marker indicating the start of the data section.\n            If None, auto-detection is used: single H1 \u2192 Workbook, or fallback to\n            \"# Tables\" / \"# Workbook\". Defaults to None.\n        sheet_header_level (int | None): The markdown header level for sheets.\n            If None, derived from workbook_level + 1. Defaults to None.\n        table_header_level (int | None): The markdown header level for tables.\n            If None, derived from workbook_level + 2. Defaults to None.\n        capture_description (bool): Whether to capture text between the table header\n            and the table as a description. Defaults to True.\n    \"\"\"\n\n    root_marker: str | None = None\n    sheet_header_level: int | None = None\n    table_header_level: int | None = None\n    capture_description: bool = True\n\n    def __post_init__(self):\n        # Handle ParsingSchema defaults manually since they are separate fields in instance\n        if self.column_separator is None:\n            object.__setattr__(self, \"column_separator\", \"|\")\n        if self.header_separator_char is None:\n            object.__setattr__(self, \"header_separator_char\", \"-\")\n        if self.require_outer_pipes is None:\n            object.__setattr__(self, \"require_outer_pipes\", True)\n        if self.strip_whitespace is None:\n            object.__setattr__(self, \"strip_whitespace\", True)\n        if self.convert_br_to_newline is None:\n            object.__setattr__(self, \"convert_br_to_newline\", True)\n\n        # root_marker, sheet_header_level, table_header_level can all be None\n        # (auto-detection is handled in parsing.py)\n\n        if self.capture_description is None:\n            object.__setattr__(self, \"capture_description\", True)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.ParsingSchema","title":"<code>ParsingSchema</code>  <code>dataclass</code>","text":"<p>Configuration for parsing markdown tables. Designed to be immutable and passed to pure functions.</p> <p>Attributes:</p> Name Type Description <code>column_separator</code> <code>str</code> <p>Character used to separate columns. Defaults to \"|\".</p> <code>header_separator_char</code> <code>str</code> <p>Character used in the separator row. Defaults to \"-\".</p> <code>require_outer_pipes</code> <code>bool</code> <p>Whether tables must have outer pipes (e.g. <code>| col |</code>). Defaults to True.</p> <code>strip_whitespace</code> <code>bool</code> <p>Whether to strip whitespace from cell values. Defaults to True.</p> Source code in <code>src/md_spreadsheet_parser/schemas.py</code> <pre><code>@dataclass(frozen=True)\nclass ParsingSchema:\n    \"\"\"\n    Configuration for parsing markdown tables.\n    Designed to be immutable and passed to pure functions.\n\n    Attributes:\n        column_separator (str): Character used to separate columns. Defaults to \"|\".\n        header_separator_char (str): Character used in the separator row. Defaults to \"-\".\n        require_outer_pipes (bool): Whether tables must have outer pipes (e.g. `| col |`). Defaults to True.\n        strip_whitespace (bool): Whether to strip whitespace from cell values. Defaults to True.\n    \"\"\"\n\n    column_separator: str = \"|\"\n    header_separator_char: str = \"-\"\n    require_outer_pipes: bool = True\n    strip_whitespace: bool = True\n    convert_br_to_newline: bool = True\n\n    def __post_init__(self):\n        # Ensure defaults if None is passed (e.g. from WASM)\n        if self.column_separator is None:\n            object.__setattr__(self, \"column_separator\", \"|\")\n        if self.header_separator_char is None:\n            object.__setattr__(self, \"header_separator_char\", \"-\")\n        if self.require_outer_pipes is None:\n            object.__setattr__(self, \"require_outer_pipes\", True)\n        if self.strip_whitespace is None:\n            object.__setattr__(self, \"strip_whitespace\", True)\n        if self.convert_br_to_newline is None:\n            object.__setattr__(self, \"convert_br_to_newline\", True)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Sheet","title":"<code>Sheet</code>  <code>dataclass</code>","text":"<p>Represents a single sheet containing tables.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the sheet.</p> <code>tables</code> <code>list[Table]</code> <p>List of tables contained in this sheet.</p> <code>sheet_type</code> <code>SheetType</code> <p>Type of sheet - \"table\" for table sheet, \"doc\" for document sheet.</p> <code>content</code> <code>str | None</code> <p>Raw markdown content for doc sheets. Only set when sheet_type=\"doc\".</p> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Arbitrary metadata (e.g. layout). Defaults to None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>@dataclass(frozen=True)\nclass Sheet:\n    \"\"\"\n    Represents a single sheet containing tables.\n\n    Attributes:\n        name (str): Name of the sheet.\n        tables (list[Table]): List of tables contained in this sheet.\n        sheet_type (SheetType): Type of sheet - \"table\" for table sheet, \"doc\" for document sheet.\n        content (str | None): Raw markdown content for doc sheets. Only set when sheet_type=\"doc\".\n        metadata (dict[str, Any] | None): Arbitrary metadata (e.g. layout). Defaults to None.\n    \"\"\"\n\n    name: str\n    tables: list[Table]\n    sheet_type: SheetType = \"table\"\n    content: str | None = None\n    metadata: dict[str, Any] | None = None\n\n    def __post_init__(self):\n        if self.metadata is None:\n            # Hack to allow default value for mutable type in frozen dataclass\n            object.__setattr__(self, \"metadata\", {})\n\n    @property\n    def json(self) -&gt; SheetJSON:\n        \"\"\"\n        Returns a JSON-compatible dictionary representation of the sheet.\n\n        Returns:\n            SheetJSON: A dictionary containing the sheet data.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"sheet_type\": self.sheet_type,\n            \"content\": self.content,\n            \"tables\": [t.json for t in self.tables],\n            \"metadata\": self.metadata if self.metadata is not None else {},\n        }\n\n    def get_table(self, name: str) -&gt; Table | None:\n        \"\"\"\n        Retrieve a table by its name.\n\n        Args:\n            name (str): The name of the table to retrieve.\n\n        Returns:\n            Table | None: The table object if found, otherwise None.\n        \"\"\"\n        for table in self.tables:\n            if table.name == name:\n                return table\n        return None\n\n    def to_markdown(self, schema: ParsingSchema = DEFAULT_SCHEMA) -&gt; str:\n        \"\"\"\n        Generates a Markdown string representation of the sheet.\n\n        Args:\n            schema (ParsingSchema, optional): Configuration for formatting.\n\n        Returns:\n            str: The Markdown string.\n        \"\"\"\n        return generate_sheet_markdown(self, schema)\n\n    def rename(self, new_name: str) -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with the name changed.\n        \"\"\"\n        return replace(self, name=new_name)\n\n    def add_table(self, name: str | None = None) -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with a new empty table appended.\n        \"\"\"\n        new_table = Table(headers=[\"A\", \"B\", \"C\"], rows=[[\"\", \"\", \"\"]], name=name)\n        new_tables = list(self.tables)\n        new_tables.append(new_table)\n        return replace(self, tables=new_tables)\n\n    def delete_table(self, index: int) -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with the table at index removed.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.tables):\n            raise IndexError(\"Table index out of range\")\n\n        new_tables = list(self.tables)\n        new_tables.pop(index)\n        return replace(self, tables=new_tables)\n\n    def replace_table(self, index: int, table: \"Table\") -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with the table at index replaced.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.tables):\n            raise IndexError(\"Table index out of range\")\n\n        new_tables = list(self.tables)\n        new_tables[index] = table\n        return replace(self, tables=new_tables)\n\n    def move_table(self, from_index: int, to_index: int) -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with the table moved from from_index to to_index.\n        \"\"\"\n        if from_index &lt; 0 or from_index &gt;= len(self.tables):\n            raise IndexError(\"from_index out of range\")\n        if to_index &lt; 0 or to_index &gt;= len(self.tables):\n            raise IndexError(\"to_index out of range\")\n\n        new_tables = list(self.tables)\n        table = new_tables.pop(from_index)\n        new_tables.insert(to_index, table)\n        return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Sheet.json","title":"<code>json</code>  <code>property</code>","text":"<p>Returns a JSON-compatible dictionary representation of the sheet.</p> <p>Returns:</p> Name Type Description <code>SheetJSON</code> <code>SheetJSON</code> <p>A dictionary containing the sheet data.</p>"},{"location":"api/#md_spreadsheet_parser.Sheet.add_table","title":"<code>add_table(name=None)</code>","text":"<p>Return a new Sheet with a new empty table appended.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def add_table(self, name: str | None = None) -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with a new empty table appended.\n    \"\"\"\n    new_table = Table(headers=[\"A\", \"B\", \"C\"], rows=[[\"\", \"\", \"\"]], name=name)\n    new_tables = list(self.tables)\n    new_tables.append(new_table)\n    return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Sheet.delete_table","title":"<code>delete_table(index)</code>","text":"<p>Return a new Sheet with the table at index removed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def delete_table(self, index: int) -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with the table at index removed.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.tables):\n        raise IndexError(\"Table index out of range\")\n\n    new_tables = list(self.tables)\n    new_tables.pop(index)\n    return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Sheet.get_table","title":"<code>get_table(name)</code>","text":"<p>Retrieve a table by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the table to retrieve.</p> required <p>Returns:</p> Type Description <code>Table | None</code> <p>Table | None: The table object if found, otherwise None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def get_table(self, name: str) -&gt; Table | None:\n    \"\"\"\n    Retrieve a table by its name.\n\n    Args:\n        name (str): The name of the table to retrieve.\n\n    Returns:\n        Table | None: The table object if found, otherwise None.\n    \"\"\"\n    for table in self.tables:\n        if table.name == name:\n            return table\n    return None\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Sheet.move_table","title":"<code>move_table(from_index, to_index)</code>","text":"<p>Return a new Sheet with the table moved from from_index to to_index.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def move_table(self, from_index: int, to_index: int) -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with the table moved from from_index to to_index.\n    \"\"\"\n    if from_index &lt; 0 or from_index &gt;= len(self.tables):\n        raise IndexError(\"from_index out of range\")\n    if to_index &lt; 0 or to_index &gt;= len(self.tables):\n        raise IndexError(\"to_index out of range\")\n\n    new_tables = list(self.tables)\n    table = new_tables.pop(from_index)\n    new_tables.insert(to_index, table)\n    return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Sheet.rename","title":"<code>rename(new_name)</code>","text":"<p>Return a new Sheet with the name changed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def rename(self, new_name: str) -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with the name changed.\n    \"\"\"\n    return replace(self, name=new_name)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Sheet.replace_table","title":"<code>replace_table(index, table)</code>","text":"<p>Return a new Sheet with the table at index replaced.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def replace_table(self, index: int, table: \"Table\") -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with the table at index replaced.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.tables):\n        raise IndexError(\"Table index out of range\")\n\n    new_tables = list(self.tables)\n    new_tables[index] = table\n    return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Sheet.to_markdown","title":"<code>to_markdown(schema=DEFAULT_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the sheet.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def to_markdown(self, schema: ParsingSchema = DEFAULT_SCHEMA) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the sheet.\n\n    Args:\n        schema (ParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    return generate_sheet_markdown(self, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table","title":"<code>Table</code>  <code>dataclass</code>","text":"<p>Represents a parsed table with optional metadata.</p> <p>Attributes:</p> Name Type Description <code>headers</code> <code>list[str] | None</code> <p>List of column headers, or None if the table has no headers.</p> <code>rows</code> <code>list[list[str]]</code> <p>List of data rows.</p> <code>alignments</code> <code>list[AlignmentType] | None</code> <p>List of column alignments ('left', 'center', 'right'). Defaults to None.</p> <code>name</code> <code>str | None</code> <p>Name of the table (e.g. from a header). Defaults to None.</p> <code>description</code> <code>str | None</code> <p>Description of the table. Defaults to None.</p> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Arbitrary metadata. Defaults to None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>@dataclass(frozen=True)\nclass Table:\n    \"\"\"\n    Represents a parsed table with optional metadata.\n\n    Attributes:\n        headers (list[str] | None): List of column headers, or None if the table has no headers.\n        rows (list[list[str]]): List of data rows.\n        alignments (list[AlignmentType] | None): List of column alignments ('left', 'center', 'right'). Defaults to None.\n        name (str | None): Name of the table (e.g. from a header). Defaults to None.\n        description (str | None): Description of the table. Defaults to None.\n        metadata (dict[str, Any] | None): Arbitrary metadata. Defaults to None.\n    \"\"\"\n\n    headers: list[str] | None\n    rows: list[list[str]]\n    alignments: list[AlignmentType] | None = None\n    name: str | None = None\n    description: str | None = None\n    metadata: dict[str, Any] | None = None\n    start_line: int | None = None\n    end_line: int | None = None\n\n    def __post_init__(self):\n        if self.metadata is None:\n            # Hack to allow default value for mutable type in frozen dataclass\n            object.__setattr__(self, \"metadata\", {})\n\n    @property\n    def json(self) -&gt; TableJSON:\n        \"\"\"\n        Returns a JSON-compatible dictionary representation of the table.\n\n        Returns:\n            TableJSON: A dictionary containing the table data.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"headers\": self.headers,\n            \"rows\": self.rows,\n            \"metadata\": self.metadata if self.metadata is not None else {},\n            \"start_line\": self.start_line,\n            \"end_line\": self.end_line,\n            \"alignments\": self.alignments,\n        }\n\n    def to_models(\n        self,\n        schema_cls: type[T],\n        conversion_schema: ConversionSchema = DEFAULT_CONVERSION_SCHEMA,\n    ) -&gt; list[T]:\n        \"\"\"\n        Converts the table rows into a list of dataclass instances, performing validation and type conversion.\n\n        Args:\n            schema_cls (type[T]): The dataclass type to validate against.\n            conversion_schema (ConversionSchema, optional): Configuration for type conversion.\n\n        Returns:\n            list[T]: A list of validated dataclass instances.\n\n        Raises:\n            ValueError: If schema_cls is not a dataclass.\n            TableValidationError: If validation fails for any row or if the table has no headers.\n        \"\"\"\n        return validate_table(self, schema_cls, conversion_schema)\n\n    def to_markdown(self, schema: ParsingSchema = DEFAULT_SCHEMA) -&gt; str:\n        \"\"\"\n        Generates a Markdown string representation of the table.\n\n        Args:\n            schema (ParsingSchema, optional): Configuration for formatting.\n\n        Returns:\n            str: The Markdown string.\n        \"\"\"\n        return generate_table_markdown(self, schema)\n\n    def update_cell(self, row_idx: int, col_idx: int, value: str) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the specified cell updated.\n        \"\"\"\n        # Handle header update\n        if row_idx == -1:\n            if self.headers is None:\n                # Determine width from rows if possible, or start fresh\n                width = len(self.rows[0]) if self.rows else (col_idx + 1)\n                new_headers = [\"\"] * width\n                # Ensure width enough\n                if col_idx &gt;= len(new_headers):\n                    new_headers.extend([\"\"] * (col_idx - len(new_headers) + 1))\n            else:\n                new_headers = list(self.headers)\n                if col_idx &gt;= len(new_headers):\n                    new_headers.extend([\"\"] * (col_idx - len(new_headers) + 1))\n\n            # Update alignments if headers grew\n            new_alignments = list(self.alignments) if self.alignments else []\n            if len(new_headers) &gt; len(new_alignments):\n                # Fill with default/None up to new width\n                # But we only need as many alignments as columns.\n                # If alignments is None, it stays None?\n                # Ideally if we start tracking alignments, we should init it?\n                # If self.alignments was None, we might keep it None unless explicitly set?\n                # Consistent behavior: If alignments is NOT None, expand it.\n                if self.alignments is not None:\n                    # Cast or explicit type check might be needed for strict type checkers with literals\n                    # Using a typed list to satisfy invariant list[AlignmentType]\n                    extension: list[AlignmentType] = [\"default\"] * (\n                        len(new_headers) - len(new_alignments)\n                    )\n                    new_alignments.extend(extension)\n\n            final_alignments = new_alignments if self.alignments is not None else None\n\n            new_headers[col_idx] = value\n\n            return replace(self, headers=new_headers, alignments=final_alignments)\n\n        # Handle Body update\n        # 1. Ensure row exists\n        new_rows = [list(r) for r in self.rows]\n\n        # Grow rows if needed\n        if row_idx &gt;= len(new_rows):\n            # Calculate width\n            width = (\n                len(self.headers)\n                if self.headers\n                else (len(new_rows[0]) if new_rows else 0)\n            )\n            if width == 0:\n                width = col_idx + 1  # At least cover the new cell\n\n            rows_to_add = row_idx - len(new_rows) + 1\n            for _ in range(rows_to_add):\n                new_rows.append([\"\"] * width)\n\n        # If columns expanded due to row update, we might need to expand alignments too\n        current_width = len(new_rows[0]) if new_rows else 0\n        if col_idx &gt;= current_width:\n            # This means we are expanding columns\n            if self.alignments is not None:\n                width_needed = col_idx + 1\n                current_align_len = len(self.alignments)\n                if width_needed &gt; current_align_len:\n                    new_alignments = list(self.alignments)\n                    extension: list[AlignmentType] = [\"default\"] * (\n                        width_needed - current_align_len\n                    )\n                    new_alignments.extend(extension)\n                    return replace(\n                        self,\n                        rows=self._update_rows_cell(new_rows, row_idx, col_idx, value),\n                        alignments=new_alignments,\n                    )\n\n        return replace(\n            self, rows=self._update_rows_cell(new_rows, row_idx, col_idx, value)\n        )\n\n    def _update_rows_cell(self, new_rows, row_idx, col_idx, value):\n        target_row = new_rows[row_idx]\n        if col_idx &gt;= len(target_row):\n            target_row.extend([\"\"] * (col_idx - len(target_row) + 1))\n        target_row[col_idx] = value\n        return new_rows\n\n    def delete_row(self, row_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the row at index removed.\n        \"\"\"\n        new_rows = [list(r) for r in self.rows]\n        if 0 &lt;= row_idx &lt; len(new_rows):\n            new_rows.pop(row_idx)\n        return replace(self, rows=new_rows)\n\n    def delete_column(self, col_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the column at index removed.\n        \"\"\"\n        new_headers = list(self.headers) if self.headers else None\n        if new_headers and 0 &lt;= col_idx &lt; len(new_headers):\n            new_headers.pop(col_idx)\n\n        new_rows = []\n        for row in self.rows:\n            new_row = list(row)\n            if 0 &lt;= col_idx &lt; len(new_row):\n                new_row.pop(col_idx)\n            new_rows.append(new_row)\n\n        new_alignments = None\n        if self.alignments is not None:\n            new_alignments = list(self.alignments)\n            if 0 &lt;= col_idx &lt; len(new_alignments):\n                new_alignments.pop(col_idx)\n\n        return replace(\n            self, headers=new_headers, rows=new_rows, alignments=new_alignments\n        )\n\n    def clear_column_data(self, col_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with data in the specified column cleared (set to empty string),\n        but headers and column structure preserved.\n        \"\"\"\n        # Headers remain unchanged\n\n        new_rows = []\n        for row in self.rows:\n            new_row = list(row)\n            if 0 &lt;= col_idx &lt; len(new_row):\n                new_row[col_idx] = \"\"\n            new_rows.append(new_row)\n\n        return replace(self, rows=new_rows)\n\n    def insert_row(self, row_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with an empty row inserted at row_idx.\n        Subsequent rows are shifted down.\n        \"\"\"\n        new_rows = [list(r) for r in self.rows]\n\n        # Determine width\n        width = (\n            len(self.headers) if self.headers else (len(new_rows[0]) if new_rows else 0)\n        )\n        if width == 0:\n            width = 1  # Default to 1 column if table is empty\n\n        new_row = [\"\"] * width\n\n        if row_idx &lt; 0:\n            row_idx = 0\n        if row_idx &gt; len(new_rows):\n            row_idx = len(new_rows)\n\n        new_rows.insert(row_idx, new_row)\n        return replace(self, rows=new_rows)\n\n    def insert_column(self, col_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with an empty column inserted at col_idx.\n        Subsequent columns are shifted right.\n        \"\"\"\n        new_headers = list(self.headers) if self.headers else None\n\n        if new_headers:\n            if col_idx &lt; 0:\n                col_idx = 0\n            if col_idx &gt; len(new_headers):\n                col_idx = len(new_headers)\n            new_headers.insert(col_idx, \"\")\n\n        new_alignments = None\n        if self.alignments is not None:\n            new_alignments = list(self.alignments)\n            # Pad if needed before insertion?\n            if col_idx &gt; len(new_alignments):\n                extension: list[AlignmentType] = [\"default\"] * (\n                    col_idx - len(new_alignments)\n                )\n                new_alignments.extend(extension)\n            new_alignments.insert(col_idx, \"default\")  # Default alignment\n\n        new_rows = []\n        for row in self.rows:\n            new_row = list(row)\n            # Ensure row is long enough before insertion logic?\n            # Or just insert.\n            # If col_idx is way past end, we might need padding?\n            # Standard list.insert handles index &gt; len -&gt; append.\n            current_len = len(new_row)\n            target_idx = col_idx\n            if target_idx &gt; current_len:\n                # Pad up to target\n                new_row.extend([\"\"] * (target_idx - current_len))\n                target_idx = len(new_row)  # Append\n\n            new_row.insert(target_idx, \"\")\n            new_rows.append(new_row)\n\n        return replace(\n            self, headers=new_headers, rows=new_rows, alignments=new_alignments\n        )\n\n    def rename(self, new_name: str) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the name changed.\n        \"\"\"\n        return replace(self, name=new_name)\n\n    def move_row(self, from_index: int, to_index: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the row moved from from_index to to_index.\n        \"\"\"\n        if from_index &lt; 0 or from_index &gt;= len(self.rows):\n            raise IndexError(\"from_index out of range\")\n        if to_index &lt; 0 or to_index &gt;= len(self.rows):\n            raise IndexError(\"to_index out of range\")\n\n        new_rows = [list(r) for r in self.rows]\n        row = new_rows.pop(from_index)\n        new_rows.insert(to_index, row)\n        return replace(self, rows=new_rows)\n\n    def move_column(self, from_index: int, to_index: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the column moved from from_index to to_index.\n        \"\"\"\n        # Determine width from headers or first row\n        width = (\n            len(self.headers)\n            if self.headers\n            else (len(self.rows[0]) if self.rows else 0)\n        )\n        if from_index &lt; 0 or from_index &gt;= width:\n            raise IndexError(\"from_index out of range\")\n        if to_index &lt; 0 or to_index &gt;= width:\n            raise IndexError(\"to_index out of range\")\n\n        # Move header\n        new_headers = None\n        if self.headers:\n            new_headers = list(self.headers)\n            header = new_headers.pop(from_index)\n            new_headers.insert(to_index, header)\n\n        # Move alignments\n        new_alignments = None\n        if self.alignments:\n            new_alignments = list(self.alignments)\n            if from_index &lt; len(new_alignments):\n                alignment = new_alignments.pop(from_index)\n                new_alignments.insert(to_index, alignment)\n\n        # Move data in each row\n        new_rows = []\n        for row in self.rows:\n            new_row = list(row)\n            if from_index &lt; len(new_row):\n                cell = new_row.pop(from_index)\n                new_row.insert(to_index, cell)\n            new_rows.append(new_row)\n\n        return replace(\n            self, headers=new_headers, rows=new_rows, alignments=new_alignments\n        )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.json","title":"<code>json</code>  <code>property</code>","text":"<p>Returns a JSON-compatible dictionary representation of the table.</p> <p>Returns:</p> Name Type Description <code>TableJSON</code> <code>TableJSON</code> <p>A dictionary containing the table data.</p>"},{"location":"api/#md_spreadsheet_parser.Table.clear_column_data","title":"<code>clear_column_data(col_idx)</code>","text":"<p>Return a new Table with data in the specified column cleared (set to empty string), but headers and column structure preserved.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def clear_column_data(self, col_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with data in the specified column cleared (set to empty string),\n    but headers and column structure preserved.\n    \"\"\"\n    # Headers remain unchanged\n\n    new_rows = []\n    for row in self.rows:\n        new_row = list(row)\n        if 0 &lt;= col_idx &lt; len(new_row):\n            new_row[col_idx] = \"\"\n        new_rows.append(new_row)\n\n    return replace(self, rows=new_rows)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.delete_column","title":"<code>delete_column(col_idx)</code>","text":"<p>Return a new Table with the column at index removed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def delete_column(self, col_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the column at index removed.\n    \"\"\"\n    new_headers = list(self.headers) if self.headers else None\n    if new_headers and 0 &lt;= col_idx &lt; len(new_headers):\n        new_headers.pop(col_idx)\n\n    new_rows = []\n    for row in self.rows:\n        new_row = list(row)\n        if 0 &lt;= col_idx &lt; len(new_row):\n            new_row.pop(col_idx)\n        new_rows.append(new_row)\n\n    new_alignments = None\n    if self.alignments is not None:\n        new_alignments = list(self.alignments)\n        if 0 &lt;= col_idx &lt; len(new_alignments):\n            new_alignments.pop(col_idx)\n\n    return replace(\n        self, headers=new_headers, rows=new_rows, alignments=new_alignments\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.delete_row","title":"<code>delete_row(row_idx)</code>","text":"<p>Return a new Table with the row at index removed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def delete_row(self, row_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the row at index removed.\n    \"\"\"\n    new_rows = [list(r) for r in self.rows]\n    if 0 &lt;= row_idx &lt; len(new_rows):\n        new_rows.pop(row_idx)\n    return replace(self, rows=new_rows)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.insert_column","title":"<code>insert_column(col_idx)</code>","text":"<p>Return a new Table with an empty column inserted at col_idx. Subsequent columns are shifted right.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def insert_column(self, col_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with an empty column inserted at col_idx.\n    Subsequent columns are shifted right.\n    \"\"\"\n    new_headers = list(self.headers) if self.headers else None\n\n    if new_headers:\n        if col_idx &lt; 0:\n            col_idx = 0\n        if col_idx &gt; len(new_headers):\n            col_idx = len(new_headers)\n        new_headers.insert(col_idx, \"\")\n\n    new_alignments = None\n    if self.alignments is not None:\n        new_alignments = list(self.alignments)\n        # Pad if needed before insertion?\n        if col_idx &gt; len(new_alignments):\n            extension: list[AlignmentType] = [\"default\"] * (\n                col_idx - len(new_alignments)\n            )\n            new_alignments.extend(extension)\n        new_alignments.insert(col_idx, \"default\")  # Default alignment\n\n    new_rows = []\n    for row in self.rows:\n        new_row = list(row)\n        # Ensure row is long enough before insertion logic?\n        # Or just insert.\n        # If col_idx is way past end, we might need padding?\n        # Standard list.insert handles index &gt; len -&gt; append.\n        current_len = len(new_row)\n        target_idx = col_idx\n        if target_idx &gt; current_len:\n            # Pad up to target\n            new_row.extend([\"\"] * (target_idx - current_len))\n            target_idx = len(new_row)  # Append\n\n        new_row.insert(target_idx, \"\")\n        new_rows.append(new_row)\n\n    return replace(\n        self, headers=new_headers, rows=new_rows, alignments=new_alignments\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.insert_row","title":"<code>insert_row(row_idx)</code>","text":"<p>Return a new Table with an empty row inserted at row_idx. Subsequent rows are shifted down.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def insert_row(self, row_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with an empty row inserted at row_idx.\n    Subsequent rows are shifted down.\n    \"\"\"\n    new_rows = [list(r) for r in self.rows]\n\n    # Determine width\n    width = (\n        len(self.headers) if self.headers else (len(new_rows[0]) if new_rows else 0)\n    )\n    if width == 0:\n        width = 1  # Default to 1 column if table is empty\n\n    new_row = [\"\"] * width\n\n    if row_idx &lt; 0:\n        row_idx = 0\n    if row_idx &gt; len(new_rows):\n        row_idx = len(new_rows)\n\n    new_rows.insert(row_idx, new_row)\n    return replace(self, rows=new_rows)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.move_column","title":"<code>move_column(from_index, to_index)</code>","text":"<p>Return a new Table with the column moved from from_index to to_index.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def move_column(self, from_index: int, to_index: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the column moved from from_index to to_index.\n    \"\"\"\n    # Determine width from headers or first row\n    width = (\n        len(self.headers)\n        if self.headers\n        else (len(self.rows[0]) if self.rows else 0)\n    )\n    if from_index &lt; 0 or from_index &gt;= width:\n        raise IndexError(\"from_index out of range\")\n    if to_index &lt; 0 or to_index &gt;= width:\n        raise IndexError(\"to_index out of range\")\n\n    # Move header\n    new_headers = None\n    if self.headers:\n        new_headers = list(self.headers)\n        header = new_headers.pop(from_index)\n        new_headers.insert(to_index, header)\n\n    # Move alignments\n    new_alignments = None\n    if self.alignments:\n        new_alignments = list(self.alignments)\n        if from_index &lt; len(new_alignments):\n            alignment = new_alignments.pop(from_index)\n            new_alignments.insert(to_index, alignment)\n\n    # Move data in each row\n    new_rows = []\n    for row in self.rows:\n        new_row = list(row)\n        if from_index &lt; len(new_row):\n            cell = new_row.pop(from_index)\n            new_row.insert(to_index, cell)\n        new_rows.append(new_row)\n\n    return replace(\n        self, headers=new_headers, rows=new_rows, alignments=new_alignments\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.move_row","title":"<code>move_row(from_index, to_index)</code>","text":"<p>Return a new Table with the row moved from from_index to to_index.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def move_row(self, from_index: int, to_index: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the row moved from from_index to to_index.\n    \"\"\"\n    if from_index &lt; 0 or from_index &gt;= len(self.rows):\n        raise IndexError(\"from_index out of range\")\n    if to_index &lt; 0 or to_index &gt;= len(self.rows):\n        raise IndexError(\"to_index out of range\")\n\n    new_rows = [list(r) for r in self.rows]\n    row = new_rows.pop(from_index)\n    new_rows.insert(to_index, row)\n    return replace(self, rows=new_rows)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.rename","title":"<code>rename(new_name)</code>","text":"<p>Return a new Table with the name changed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def rename(self, new_name: str) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the name changed.\n    \"\"\"\n    return replace(self, name=new_name)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.to_markdown","title":"<code>to_markdown(schema=DEFAULT_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the table.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def to_markdown(self, schema: ParsingSchema = DEFAULT_SCHEMA) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the table.\n\n    Args:\n        schema (ParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    return generate_table_markdown(self, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.to_models","title":"<code>to_models(schema_cls, conversion_schema=DEFAULT_CONVERSION_SCHEMA)</code>","text":"<p>Converts the table rows into a list of dataclass instances, performing validation and type conversion.</p> <p>Parameters:</p> Name Type Description Default <code>schema_cls</code> <code>type[T]</code> <p>The dataclass type to validate against.</p> required <code>conversion_schema</code> <code>ConversionSchema</code> <p>Configuration for type conversion.</p> <code>DEFAULT_CONVERSION_SCHEMA</code> <p>Returns:</p> Type Description <code>list[T]</code> <p>list[T]: A list of validated dataclass instances.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If schema_cls is not a dataclass.</p> <code>TableValidationError</code> <p>If validation fails for any row or if the table has no headers.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def to_models(\n    self,\n    schema_cls: type[T],\n    conversion_schema: ConversionSchema = DEFAULT_CONVERSION_SCHEMA,\n) -&gt; list[T]:\n    \"\"\"\n    Converts the table rows into a list of dataclass instances, performing validation and type conversion.\n\n    Args:\n        schema_cls (type[T]): The dataclass type to validate against.\n        conversion_schema (ConversionSchema, optional): Configuration for type conversion.\n\n    Returns:\n        list[T]: A list of validated dataclass instances.\n\n    Raises:\n        ValueError: If schema_cls is not a dataclass.\n        TableValidationError: If validation fails for any row or if the table has no headers.\n    \"\"\"\n    return validate_table(self, schema_cls, conversion_schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Table.update_cell","title":"<code>update_cell(row_idx, col_idx, value)</code>","text":"<p>Return a new Table with the specified cell updated.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def update_cell(self, row_idx: int, col_idx: int, value: str) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the specified cell updated.\n    \"\"\"\n    # Handle header update\n    if row_idx == -1:\n        if self.headers is None:\n            # Determine width from rows if possible, or start fresh\n            width = len(self.rows[0]) if self.rows else (col_idx + 1)\n            new_headers = [\"\"] * width\n            # Ensure width enough\n            if col_idx &gt;= len(new_headers):\n                new_headers.extend([\"\"] * (col_idx - len(new_headers) + 1))\n        else:\n            new_headers = list(self.headers)\n            if col_idx &gt;= len(new_headers):\n                new_headers.extend([\"\"] * (col_idx - len(new_headers) + 1))\n\n        # Update alignments if headers grew\n        new_alignments = list(self.alignments) if self.alignments else []\n        if len(new_headers) &gt; len(new_alignments):\n            # Fill with default/None up to new width\n            # But we only need as many alignments as columns.\n            # If alignments is None, it stays None?\n            # Ideally if we start tracking alignments, we should init it?\n            # If self.alignments was None, we might keep it None unless explicitly set?\n            # Consistent behavior: If alignments is NOT None, expand it.\n            if self.alignments is not None:\n                # Cast or explicit type check might be needed for strict type checkers with literals\n                # Using a typed list to satisfy invariant list[AlignmentType]\n                extension: list[AlignmentType] = [\"default\"] * (\n                    len(new_headers) - len(new_alignments)\n                )\n                new_alignments.extend(extension)\n\n        final_alignments = new_alignments if self.alignments is not None else None\n\n        new_headers[col_idx] = value\n\n        return replace(self, headers=new_headers, alignments=final_alignments)\n\n    # Handle Body update\n    # 1. Ensure row exists\n    new_rows = [list(r) for r in self.rows]\n\n    # Grow rows if needed\n    if row_idx &gt;= len(new_rows):\n        # Calculate width\n        width = (\n            len(self.headers)\n            if self.headers\n            else (len(new_rows[0]) if new_rows else 0)\n        )\n        if width == 0:\n            width = col_idx + 1  # At least cover the new cell\n\n        rows_to_add = row_idx - len(new_rows) + 1\n        for _ in range(rows_to_add):\n            new_rows.append([\"\"] * width)\n\n    # If columns expanded due to row update, we might need to expand alignments too\n    current_width = len(new_rows[0]) if new_rows else 0\n    if col_idx &gt;= current_width:\n        # This means we are expanding columns\n        if self.alignments is not None:\n            width_needed = col_idx + 1\n            current_align_len = len(self.alignments)\n            if width_needed &gt; current_align_len:\n                new_alignments = list(self.alignments)\n                extension: list[AlignmentType] = [\"default\"] * (\n                    width_needed - current_align_len\n                )\n                new_alignments.extend(extension)\n                return replace(\n                    self,\n                    rows=self._update_rows_cell(new_rows, row_idx, col_idx, value),\n                    alignments=new_alignments,\n                )\n\n    return replace(\n        self, rows=self._update_rows_cell(new_rows, row_idx, col_idx, value)\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.TableValidationError","title":"<code>TableValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when table validation fails. Contains a list of errors found during validation.</p> Source code in <code>src/md_spreadsheet_parser/validation.py</code> <pre><code>class TableValidationError(Exception):\n    \"\"\"\n    Exception raised when table validation fails.\n    Contains a list of errors found during validation.\n    \"\"\"\n\n    def __init__(self, errors: list[str]):\n        self.errors = errors\n        super().__init__(\n            f\"Validation failed with {len(errors)} errors:\\n\" + \"\\n\".join(errors)\n        )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Workbook","title":"<code>Workbook</code>  <code>dataclass</code>","text":"<p>Represents a collection of sheets (multi-table output).</p> <p>Attributes:</p> Name Type Description <code>sheets</code> <code>list[Sheet]</code> <p>List of sheets in the workbook.</p> <code>name</code> <code>str</code> <p>Name of the workbook (extracted from root marker). Defaults to \"Workbook\".</p> <code>start_line</code> <code>int | None</code> <p>0-indexed line number where workbook header starts. None if not detected.</p> <code>end_line</code> <code>int | None</code> <p>0-indexed line number where workbook section ends. None if not detected.</p> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Arbitrary metadata. Defaults to None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>@dataclass(frozen=True)\nclass Workbook:\n    \"\"\"\n    Represents a collection of sheets (multi-table output).\n\n    Attributes:\n        sheets (list[Sheet]): List of sheets in the workbook.\n        name (str): Name of the workbook (extracted from root marker). Defaults to \"Workbook\".\n        start_line (int | None): 0-indexed line number where workbook header starts. None if not detected.\n        end_line (int | None): 0-indexed line number where workbook section ends. None if not detected.\n        metadata (dict[str, Any] | None): Arbitrary metadata. Defaults to None.\n    \"\"\"\n\n    sheets: list[Sheet]\n    name: str = \"Workbook\"\n    start_line: int | None = None\n    end_line: int | None = None\n    metadata: dict[str, Any] | None = None\n    root_content: str | None = None\n\n    def __post_init__(self):\n        if self.metadata is None:\n            # Hack to allow default value for mutable type in frozen dataclass\n            object.__setattr__(self, \"metadata\", {})\n\n    @property\n    def json(self) -&gt; WorkbookJSON:\n        \"\"\"\n        Returns a JSON-compatible dictionary representation of the workbook.\n\n        Returns:\n            WorkbookJSON: A dictionary containing the workbook data.\n        \"\"\"\n        result: WorkbookJSON = {\n            \"name\": self.name,\n            \"sheets\": [s.json for s in self.sheets],\n            \"metadata\": self.metadata if self.metadata is not None else {},\n        }\n        if self.start_line is not None:\n            result[\"startLine\"] = self.start_line\n        if self.end_line is not None:\n            result[\"endLine\"] = self.end_line\n        if self.root_content is not None:\n            result[\"rootContent\"] = self.root_content  # type: ignore[typeddict-item]\n        return result\n\n    def get_sheet(self, name: str) -&gt; Sheet | None:\n        \"\"\"\n        Retrieve a sheet by its name.\n\n        Args:\n            name (str): The name of the sheet to retrieve.\n\n        Returns:\n            Sheet | None: The sheet object if found, otherwise None.\n        \"\"\"\n        for sheet in self.sheets:\n            if sheet.name == name:\n                return sheet\n        return None\n\n    def to_markdown(\n        self, schema: MultiTableParsingSchema = DEFAULT_MULTI_TABLE_SCHEMA\n    ) -&gt; str:\n        \"\"\"\n        Generates a Markdown string representation of the workbook.\n\n        Args:\n            schema (MultiTableParsingSchema, optional): Configuration for formatting.\n\n        Returns:\n            str: The Markdown string.\n        \"\"\"\n        return generate_workbook_markdown(self, schema)\n\n    def add_sheet(self, name: str) -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with a new sheet added.\n        \"\"\"\n        # Create new sheet with one empty table as default\n        new_table = Table(headers=[\"A\", \"B\", \"C\"], rows=[[\"\", \"\", \"\"]])\n        new_sheet = Sheet(name=name, tables=[new_table])\n\n        new_sheets = list(self.sheets)\n        new_sheets.append(new_sheet)\n\n        return replace(self, sheets=new_sheets)\n\n    def delete_sheet(self, index: int) -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with the sheet at index removed.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.sheets):\n            raise IndexError(\"Sheet index out of range\")\n\n        new_sheets = list(self.sheets)\n        new_sheets.pop(index)\n\n        return replace(self, sheets=new_sheets)\n\n    def move_sheet(self, from_index: int, to_index: int) -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with the sheet moved from from_index to to_index.\n        \"\"\"\n        if from_index &lt; 0 or from_index &gt;= len(self.sheets):\n            raise IndexError(\"from_index out of range\")\n        if to_index &lt; 0 or to_index &gt;= len(self.sheets):\n            raise IndexError(\"to_index out of range\")\n\n        new_sheets = list(self.sheets)\n        sheet = new_sheets.pop(from_index)\n        new_sheets.insert(to_index, sheet)\n\n        return replace(self, sheets=new_sheets)\n\n    def replace_sheet(self, index: int, sheet: \"Sheet\") -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with the sheet at index replaced.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.sheets):\n            raise IndexError(\"Sheet index out of range\")\n\n        new_sheets = list(self.sheets)\n        new_sheets[index] = sheet\n\n        return replace(self, sheets=new_sheets)\n\n    def rename_sheet(self, index: int, new_name: str) -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with the sheet at index renamed.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.sheets):\n            raise IndexError(\"Sheet index out of range\")\n\n        old_sheet = self.sheets[index]\n        new_sheet = replace(old_sheet, name=new_name)\n\n        new_sheets = list(self.sheets)\n        new_sheets[index] = new_sheet\n\n        return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Workbook.json","title":"<code>json</code>  <code>property</code>","text":"<p>Returns a JSON-compatible dictionary representation of the workbook.</p> <p>Returns:</p> Name Type Description <code>WorkbookJSON</code> <code>WorkbookJSON</code> <p>A dictionary containing the workbook data.</p>"},{"location":"api/#md_spreadsheet_parser.Workbook.add_sheet","title":"<code>add_sheet(name)</code>","text":"<p>Return a new Workbook with a new sheet added.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def add_sheet(self, name: str) -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with a new sheet added.\n    \"\"\"\n    # Create new sheet with one empty table as default\n    new_table = Table(headers=[\"A\", \"B\", \"C\"], rows=[[\"\", \"\", \"\"]])\n    new_sheet = Sheet(name=name, tables=[new_table])\n\n    new_sheets = list(self.sheets)\n    new_sheets.append(new_sheet)\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Workbook.delete_sheet","title":"<code>delete_sheet(index)</code>","text":"<p>Return a new Workbook with the sheet at index removed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def delete_sheet(self, index: int) -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with the sheet at index removed.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.sheets):\n        raise IndexError(\"Sheet index out of range\")\n\n    new_sheets = list(self.sheets)\n    new_sheets.pop(index)\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Workbook.get_sheet","title":"<code>get_sheet(name)</code>","text":"<p>Retrieve a sheet by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the sheet to retrieve.</p> required <p>Returns:</p> Type Description <code>Sheet | None</code> <p>Sheet | None: The sheet object if found, otherwise None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def get_sheet(self, name: str) -&gt; Sheet | None:\n    \"\"\"\n    Retrieve a sheet by its name.\n\n    Args:\n        name (str): The name of the sheet to retrieve.\n\n    Returns:\n        Sheet | None: The sheet object if found, otherwise None.\n    \"\"\"\n    for sheet in self.sheets:\n        if sheet.name == name:\n            return sheet\n    return None\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Workbook.move_sheet","title":"<code>move_sheet(from_index, to_index)</code>","text":"<p>Return a new Workbook with the sheet moved from from_index to to_index.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def move_sheet(self, from_index: int, to_index: int) -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with the sheet moved from from_index to to_index.\n    \"\"\"\n    if from_index &lt; 0 or from_index &gt;= len(self.sheets):\n        raise IndexError(\"from_index out of range\")\n    if to_index &lt; 0 or to_index &gt;= len(self.sheets):\n        raise IndexError(\"to_index out of range\")\n\n    new_sheets = list(self.sheets)\n    sheet = new_sheets.pop(from_index)\n    new_sheets.insert(to_index, sheet)\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Workbook.rename_sheet","title":"<code>rename_sheet(index, new_name)</code>","text":"<p>Return a new Workbook with the sheet at index renamed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def rename_sheet(self, index: int, new_name: str) -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with the sheet at index renamed.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.sheets):\n        raise IndexError(\"Sheet index out of range\")\n\n    old_sheet = self.sheets[index]\n    new_sheet = replace(old_sheet, name=new_name)\n\n    new_sheets = list(self.sheets)\n    new_sheets[index] = new_sheet\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Workbook.replace_sheet","title":"<code>replace_sheet(index, sheet)</code>","text":"<p>Return a new Workbook with the sheet at index replaced.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def replace_sheet(self, index: int, sheet: \"Sheet\") -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with the sheet at index replaced.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.sheets):\n        raise IndexError(\"Sheet index out of range\")\n\n    new_sheets = list(self.sheets)\n    new_sheets[index] = sheet\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.Workbook.to_markdown","title":"<code>to_markdown(schema=DEFAULT_MULTI_TABLE_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the workbook.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>MultiTableParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_MULTI_TABLE_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def to_markdown(\n    self, schema: MultiTableParsingSchema = DEFAULT_MULTI_TABLE_SCHEMA\n) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the workbook.\n\n    Args:\n        schema (MultiTableParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    return generate_workbook_markdown(self, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.generate_sheet_markdown","title":"<code>generate_sheet_markdown(sheet, schema=DEFAULT_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the sheet.</p> <p>For doc sheets (type=\"doc\"), outputs the content directly. For table sheets (type=\"table\"), outputs table markdown.</p> <p>Parameters:</p> Name Type Description Default <code>sheet</code> <code>Sheet</code> <p>The Sheet object.</p> required <code>schema</code> <code>ParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/generator.py</code> <pre><code>def generate_sheet_markdown(\n    sheet: \"Sheet\", schema: ParsingSchema = DEFAULT_SCHEMA\n) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the sheet.\n\n    For doc sheets (type=\"doc\"), outputs the content directly.\n    For table sheets (type=\"table\"), outputs table markdown.\n\n    Args:\n        sheet: The Sheet object.\n        schema (ParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    lines = []\n\n    if isinstance(schema, MultiTableParsingSchema):\n        sheet_level = schema.sheet_header_level or 2\n        lines.append(f\"{'#' * sheet_level} {sheet.name}\")\n        lines.append(\"\")\n\n    # For doc sheets, output content directly\n    if sheet.sheet_type == \"doc\" and sheet.content is not None:\n        lines.append(sheet.content)\n    else:\n        # Table sheet: output tables\n        for i, table in enumerate(sheet.tables):\n            lines.append(generate_table_markdown(table, schema))\n            if i &lt; len(sheet.tables) - 1:\n                lines.append(\"\")  # Empty line between tables\n\n    # Append Sheet Metadata if present (at the end)\n    if isinstance(schema, MultiTableParsingSchema) and sheet.metadata:\n        lines.append(\"\")\n        metadata_json = json.dumps(sheet.metadata, ensure_ascii=False)\n        comment = f\"&lt;!-- md-spreadsheet-sheet-metadata: {metadata_json} --&gt;\"\n        lines.append(comment)\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.generate_table_markdown","title":"<code>generate_table_markdown(table, schema=DEFAULT_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>The Table object.</p> required <code>schema</code> <code>ParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/generator.py</code> <pre><code>def generate_table_markdown(\n    table: \"Table\", schema: ParsingSchema = DEFAULT_SCHEMA\n) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the table.\n\n    Args:\n        table: The Table object.\n        schema (ParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    lines = []\n\n    # Handle metadata (name and description) if MultiTableParsingSchema\n    if isinstance(schema, MultiTableParsingSchema):\n        table_level = schema.table_header_level\n        if table.name and table_level is not None:\n            lines.append(f\"{'#' * table_level} {table.name}\")\n            lines.append(\"\")  # Empty line after name\n\n        if table.description and schema.capture_description:\n            lines.append(table.description)\n            lines.append(\"\")  # Empty line after description\n\n    # Build table\n\n    sep = f\" {schema.column_separator or '|'} \"\n\n    def _prepare_cell(cell: str) -&gt; str:\n        \"\"\"Prepare cell for markdown generation.\"\"\"\n        if schema.convert_br_to_newline and \"\\n\" in cell:\n            return cell.replace(\"\\n\", \"&lt;br&gt;\")\n        return cell\n\n    # Headers\n    if table.headers:\n        # Add outer pipes if required\n        processed_headers = [_prepare_cell(h) for h in table.headers]\n        header_row = sep.join(processed_headers)\n        if schema.require_outer_pipes:\n            header_row = f\"{schema.column_separator or '|'} {header_row} {schema.column_separator or '|'}\"\n        lines.append(header_row)\n\n        # Separator row\n        separator_cells = []\n        separator_char = schema.header_separator_char or \"-\"\n        for i, _ in enumerate(table.headers):\n            alignment = \"default\"\n            if table.alignments and i &lt; len(table.alignments):\n                # Ensure we handle potentially None values if list has gaps (unlikely by design but safe)\n                alignment = table.alignments[i] or \"default\"\n\n            # Construct separator cell based on alignment\n            # Use 3 hyphens as base\n            if alignment == \"left\":\n                cell = \":\" + separator_char * 3\n            elif alignment == \"right\":\n                cell = separator_char * 3 + \":\"\n            elif alignment == \"center\":\n                cell = \":\" + separator_char * 3 + \":\"\n            else:\n                # default\n                cell = separator_char * 3\n\n            separator_cells.append(cell)\n\n        separator_row = sep.join(separator_cells)\n        if schema.require_outer_pipes:\n            separator_row = f\"{schema.column_separator or '|'} {separator_row} {schema.column_separator or '|'}\"\n        lines.append(separator_row)\n\n    # Rows\n    for row in table.rows:\n        processed_row = [_prepare_cell(cell) for cell in row]\n        row_str = sep.join(processed_row)\n        if schema.require_outer_pipes:\n            row_str = f\"{schema.column_separator or '|'} {row_str} {schema.column_separator or '|'}\"\n        lines.append(row_str)\n\n    # Append Metadata if present\n    if table.metadata and \"visual\" in table.metadata:\n        metadata_json = json.dumps(table.metadata[\"visual\"], ensure_ascii=False)\n        comment = f\"&lt;!-- md-spreadsheet-table-metadata: {metadata_json} --&gt;\"\n        lines.append(\"\")\n        lines.append(comment)\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.generate_workbook_markdown","title":"<code>generate_workbook_markdown(workbook, schema)</code>","text":"<p>Generates a Markdown string representation of the workbook.</p> <p>Parameters:</p> Name Type Description Default <code>workbook</code> <code>Workbook</code> <p>The Workbook object.</p> required <code>schema</code> <code>MultiTableParsingSchema</code> <p>Configuration for formatting.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/generator.py</code> <pre><code>def generate_workbook_markdown(\n    workbook: \"Workbook\", schema: MultiTableParsingSchema\n) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the workbook.\n\n    Args:\n        workbook: The Workbook object.\n        schema (MultiTableParsingSchema): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    lines = []\n    metadata = workbook.metadata or {}\n    is_frontmatter = metadata.get(\"header_type\") == \"frontmatter\"\n\n    if is_frontmatter:\n        # Output YAML frontmatter block\n        frontmatter_data = metadata.get(\"frontmatter\", {})\n        if frontmatter_data:\n            lines.append(generate_yaml_frontmatter(frontmatter_data))\n            lines.append(\"\")\n    elif schema.root_marker:\n        lines.append(schema.root_marker)\n        lines.append(\"\")\n    else:\n        # Default: generate root marker from workbook name\n        root_marker_level = (\n            schema.sheet_header_level - 1 if schema.sheet_header_level else 1\n        )\n        lines.append(f\"{'#' * root_marker_level} {workbook.name}\")\n        lines.append(\"\")\n\n    if workbook.root_content:\n        lines.append(workbook.root_content)\n        lines.append(\"\")\n\n    for i, sheet in enumerate(workbook.sheets):\n        lines.append(generate_sheet_markdown(sheet, schema))\n        if i &lt; len(workbook.sheets) - 1:\n            lines.append(\"\")  # Empty line between sheets\n\n    # Append Workbook Metadata if present (excluding internal keys)\n    comment_metadata = {\n        k: v for k, v in metadata.items() if k not in _METADATA_INTERNAL_KEYS\n    }\n    if comment_metadata:\n        # Ensure separation from last sheet\n        if lines and lines[-1] != \"\":\n            lines.append(\"\")\n\n        metadata_json = json.dumps(comment_metadata, ensure_ascii=False)\n        comment = f\"&lt;!-- md-spreadsheet-workbook-metadata: {metadata_json} --&gt;\"\n        lines.append(comment)\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.parse_excel","title":"<code>parse_excel(source, schema=DEFAULT_EXCEL_SCHEMA)</code>","text":"<p>Parse Excel data from various sources.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>ExcelSource</code> <p>One of: - openpyxl.Worksheet (if openpyxl is installed) - str: TSV/CSV text content - list[list[str]]: Pre-parsed 2D array</p> required <code>schema</code> <code>ExcelParsingSchema</code> <p>Configuration for parsing.</p> <code>DEFAULT_EXCEL_SCHEMA</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table object with processed headers and data.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If source type is not supported.</p> Source code in <code>src/md_spreadsheet_parser/excel.py</code> <pre><code>def parse_excel(\n    source: ExcelSource,\n    schema: ExcelParsingSchema = DEFAULT_EXCEL_SCHEMA,\n) -&gt; Table:\n    \"\"\"\n    Parse Excel data from various sources.\n\n    Args:\n        source: One of:\n            - openpyxl.Worksheet (if openpyxl is installed)\n            - str: TSV/CSV text content\n            - list[list[str]]: Pre-parsed 2D array\n        schema: Configuration for parsing.\n\n    Returns:\n        Table object with processed headers and data.\n\n    Raises:\n        TypeError: If source type is not supported.\n    \"\"\"\n    rows: list[list[str]]\n\n    # Check for openpyxl Worksheet (duck typing via hasattr)\n    if HAS_OPENPYXL and hasattr(source, \"iter_rows\"):\n        # At runtime, source is a Worksheet with iter_rows method\n        ws: Any = source\n        rows = [\n            [_safe_str(cell) for cell in row] for row in ws.iter_rows(values_only=True)\n        ]\n\n    # Check for string (TSV/CSV content)\n    elif isinstance(source, str):\n        rows = _parse_tsv(source, schema.delimiter)\n\n    # Check for pre-parsed 2D array\n    elif isinstance(source, list):\n        # Assume it's already list[list[str]]\n        rows = source\n\n    else:\n        supported = \"openpyxl.Worksheet, str, or list[list[str]]\"\n        if not HAS_OPENPYXL:\n            supported = (\n                \"str or list[list[str]] (install openpyxl for Worksheet support)\"\n            )\n        raise TypeError(\n            f\"Unsupported source type: {type(source).__name__}. Expected {supported}.\"\n        )\n\n    return parse_excel_text(rows, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.parse_excel_text","title":"<code>parse_excel_text(rows, schema=DEFAULT_EXCEL_SCHEMA)</code>","text":"<p>Parse a 2D string array into a Table with merged cell and header handling.</p> <p>Parameters:</p> Name Type Description Default <code>rows</code> <code>list[list[str]]</code> <p>2D list of strings (e.g., from csv.reader or worksheet iteration).</p> required <code>schema</code> <code>ExcelParsingSchema</code> <p>Configuration for header processing.</p> <code>DEFAULT_EXCEL_SCHEMA</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table object with processed headers and data rows.</p> Source code in <code>src/md_spreadsheet_parser/excel.py</code> <pre><code>def parse_excel_text(\n    rows: list[list[str]],\n    schema: ExcelParsingSchema = DEFAULT_EXCEL_SCHEMA,\n) -&gt; Table:\n    \"\"\"\n    Parse a 2D string array into a Table with merged cell and header handling.\n\n    Args:\n        rows: 2D list of strings (e.g., from csv.reader or worksheet iteration).\n        schema: Configuration for header processing.\n\n    Returns:\n        Table object with processed headers and data rows.\n    \"\"\"\n    if not rows:\n        return Table(headers=None, rows=[])\n\n    if schema.header_rows == 1:\n        # Single header row\n        header_row = rows[0]\n        if schema.fill_merged_headers:\n            header_row = _forward_fill(header_row)\n        headers = header_row\n        data_rows = rows[1:]\n\n    elif schema.header_rows == 2:\n        # Two header rows: Parent-Child flattening\n        if len(rows) &lt; 2:\n            # Not enough rows for 2-row header\n            return Table(headers=rows[0] if rows else None, rows=[])\n\n        parent_row = rows[0]\n        child_row = rows[1]\n\n        if schema.fill_merged_headers:\n            parent_row = _forward_fill(parent_row)\n\n        headers = _flatten_headers(parent_row, child_row, schema.header_separator)\n        data_rows = rows[2:]\n\n    else:\n        # Should not reach here due to schema validation\n        raise ValueError(f\"Invalid header_rows: {schema.header_rows}\")\n\n    # Convert data_rows to list[list[str]] ensuring all are strings\n    processed_rows = [[_safe_str(cell) for cell in row] for row in data_rows]\n\n    return Table(headers=headers, rows=processed_rows)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.parse_sheet","title":"<code>parse_sheet(markdown, name, schema, start_line_offset=0)</code>","text":"<p>Parse a sheet (section) containing one or more tables.</p> <p>If the section contains valid tables, sheet_type=\"table\" and content=None. If no tables are found, sheet_type=\"doc\" and content stores the raw markdown.</p> Source code in <code>src/md_spreadsheet_parser/parsing.py</code> <pre><code>def parse_sheet(\n    markdown: str,\n    name: str,\n    schema: MultiTableParsingSchema,\n    start_line_offset: int = 0,\n) -&gt; Sheet:\n    \"\"\"\n    Parse a sheet (section) containing one or more tables.\n\n    If the section contains valid tables, sheet_type=\"table\" and content=None.\n    If no tables are found, sheet_type=\"doc\" and content stores the raw markdown.\n    \"\"\"\n    metadata: dict[str, Any] | None = None\n\n    # Scan for sheet metadata\n    # We prioritize the first match if multiple exist (though usually only one)\n    metadata_match = re.search(\n        r\"^&lt;!-- md-spreadsheet-sheet-metadata: (.*) --&gt;$\", markdown, re.MULTILINE\n    )\n    if metadata_match:\n        try:\n            metadata = json.loads(metadata_match.group(1))\n        except json.JSONDecodeError:\n            pass  # Ignore invalid JSON\n\n    tables = _extract_tables(markdown, schema, start_line_offset)\n\n    # Determine sheet type based on whether tables were found\n    if tables:\n        # Table sheet: store tables but not raw content\n        return Sheet(\n            name=name,\n            tables=tables,\n            sheet_type=\"table\",\n            content=None,\n            metadata=metadata,\n        )\n    else:\n        # Doc sheet: no tables, store the raw markdown content\n        return Sheet(\n            name=name,\n            tables=[],\n            sheet_type=\"doc\",\n            content=markdown.rstrip() if markdown.strip() else None,\n            metadata=metadata,\n        )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.parse_table","title":"<code>parse_table(markdown, schema=DEFAULT_SCHEMA)</code>","text":"<p>Parse a markdown table into a Table object.</p> <p>Parameters:</p> Name Type Description Default <code>markdown</code> <code>str</code> <p>The markdown string containing the table.</p> required <code>schema</code> <code>ParsingSchema</code> <p>Configuration for parsing.</p> <code>DEFAULT_SCHEMA</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table object with headers and rows.</p> Source code in <code>src/md_spreadsheet_parser/parsing.py</code> <pre><code>def parse_table(markdown: str, schema: ParsingSchema = DEFAULT_SCHEMA) -&gt; Table:\n    \"\"\"\n    Parse a markdown table into a Table object.\n\n    Args:\n        markdown: The markdown string containing the table.\n        schema: Configuration for parsing.\n\n    Returns:\n        Table object with headers and rows.\n    \"\"\"\n    lines = markdown.strip().split(\"\\n\")\n    headers: list[str] | None = None\n    rows: list[list[str]] = []\n    alignments: list[AlignmentType] | None = None\n    potential_header: list[str] | None = None\n    visual_metadata: dict | None = None\n\n    # Buffer for potential header row until we confirm it's a header with a separator\n    potential_header: list[str] | None = None\n\n    for line in lines:\n        line = line.strip()\n        if not line:\n            continue\n\n        # Check for metadata comment\n        metadata_match = re.match(\n            r\"^&lt;!-- md-spreadsheet-table-metadata: (.*) --&gt;$\", line\n        )\n        if metadata_match:\n            try:\n                json_content = metadata_match.group(1)\n                visual_metadata = json.loads(json_content)\n                continue\n            except json.JSONDecodeError:\n                # If invalid JSON, treat as normal text/comment (or ignore?)\n                # For robustness, we ignore it as metadata but let parse_row handle it or skip?\n                # Usually comments are ignored by parse_row if they don't look like tables?\n                # parse_row will likely return [\"&lt;!-- ... --&gt;\"].\n                # If we want to hide it from table data, we should continue here even if error?\n                # User constraint: \"if user manually edits... handle gracefully\".\n                # Let's log/ignore and continue, effectively stripping bad metadata lines from table data.\n                continue\n\n        parsed_row = parse_row(line, schema)\n\n        if parsed_row is None:\n            continue\n\n        if headers is None and potential_header is not None:\n            detected_alignments = parse_separator_row(parsed_row, schema)\n            if detected_alignments is not None:\n                headers = potential_header\n                alignments: list[AlignmentType] | None = detected_alignments\n                potential_header = None\n                continue\n                potential_header = None\n                continue\n            else:\n                # Previous row was not a header, treat as data\n                rows.append(potential_header)\n                potential_header = parsed_row\n        elif headers is None and potential_header is None:\n            potential_header = parsed_row\n        else:\n            rows.append(parsed_row)\n\n    if potential_header is not None:\n        rows.append(potential_header)\n\n    # Normalize rows to match header length\n    if headers:\n        header_len = len(headers)\n        normalized_rows = []\n        for row in rows:\n            if len(row) &lt; header_len:\n                # Pad with empty strings\n                row.extend([\"\"] * (header_len - len(row)))\n            elif len(row) &gt; header_len:\n                # Truncate\n                row = row[:header_len]\n            normalized_rows.append(row)\n        rows = normalized_rows\n\n    metadata: dict[str, Any] = {\"schema_used\": str(schema)}\n    if visual_metadata:\n        metadata[\"visual\"] = visual_metadata\n\n    return Table(headers=headers, rows=rows, metadata=metadata, alignments=alignments)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.parse_table_from_file","title":"<code>parse_table_from_file(source, schema=DEFAULT_SCHEMA)</code>","text":"<p>Parse a markdown table from a file.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[str, Path, TextIO]</code> <p>File path (str/Path) or file-like object.</p> required <code>schema</code> <code>ParsingSchema</code> <p>Parsing configuration.</p> <code>DEFAULT_SCHEMA</code> Source code in <code>src/md_spreadsheet_parser/loader.py</code> <pre><code>def parse_table_from_file(\n    source: Union[str, Path, TextIO], schema: ParsingSchema = DEFAULT_SCHEMA\n) -&gt; Table:\n    \"\"\"\n    Parse a markdown table from a file.\n\n    Args:\n        source: File path (str/Path) or file-like object.\n        schema: Parsing configuration.\n    \"\"\"\n    content = _read_content(source)\n    return parse_table(content, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.parse_workbook","title":"<code>parse_workbook(markdown, schema=MultiTableParsingSchema())</code>","text":"<p>Parse a markdown document into a Workbook.</p> <p>When schema.root_marker is None, auto-detection is used: 1. If a single H1 header exists, it becomes the Workbook. 2. If md-spreadsheet metadata comment exists, the H1 containing it becomes Workbook. 3. Fallback to searching for \"# Tables\" or \"# Workbook\". 4. If not found, return empty Workbook.</p> <p>When root_marker/sheet_header_level/table_header_level are None, they are auto-calculated from the detected workbook level.</p> Source code in <code>src/md_spreadsheet_parser/parsing.py</code> <pre><code>def parse_workbook(\n    markdown: str, schema: MultiTableParsingSchema = MultiTableParsingSchema()\n) -&gt; Workbook:\n    \"\"\"\n    Parse a markdown document into a Workbook.\n\n    When schema.root_marker is None, auto-detection is used:\n    1. If a single H1 header exists, it becomes the Workbook.\n    2. If md-spreadsheet metadata comment exists, the H1 containing it becomes Workbook.\n    3. Fallback to searching for \"# Tables\" or \"# Workbook\".\n    4. If not found, return empty Workbook.\n\n    When root_marker/sheet_header_level/table_header_level are None,\n    they are auto-calculated from the detected workbook level.\n    \"\"\"\n    frontmatter_text, remaining_markdown = extract_frontmatter(markdown)\n    frontmatter_metadata: dict[str, Any] = {}\n    if frontmatter_text is not None:\n        frontmatter_metadata = parse_yaml_frontmatter(frontmatter_text)\n\n    # If the frontmatter does not have a title, it does not constitute a Workbook,\n    # and its metadata should not be implicitly merged into subsequent Workbooks.\n    if \"title\" not in frontmatter_metadata:\n        frontmatter_metadata = {}\n\n    lines = remaining_markdown.split(\"\\n\")\n    sheets: list[Sheet] = []\n    metadata: dict[str, Any] | None = None\n\n    # Check for Workbook metadata at the end of the file\n    # Scan for Workbook metadata anywhere in the file\n    # We filter it out from the lines so it doesn't interfere with sheet content\n    filtered_lines: list[str] = []\n    wb_metadata_pattern = re.compile(\n        r\"^&lt;!-- md-spreadsheet-workbook-metadata: (.*) --&gt;$\"\n    )\n\n    for line in lines:\n        stripped = line.strip()\n        match = wb_metadata_pattern.match(stripped)\n        if match:\n            try:\n                metadata = json.loads(match.group(1))\n            except json.JSONDecodeError:\n                pass\n            # Skip adding this line to filtered_lines\n        else:\n            filtered_lines.append(line)\n\n    lines = filtered_lines\n\n    # Determine root marker and header levels\n    root_marker = schema.root_marker\n    workbook_name = \"Workbook\"\n    workbook_level = 1  # Default H1\n\n    virtual_root = False\n    if root_marker is None and \"title\" in frontmatter_metadata:\n        title_val = str(frontmatter_metadata[\"title\"]).strip()\n        if title_val and not _has_h1_headers(lines):\n            # No actual H1 headers \u2192 frontmatter title is the workbook root\n            root_marker = \"# \" + title_val\n            workbook_name = title_val\n            workbook_level = 1\n            virtual_root = True\n        # else: H1 exists \u2192 frontmatter is a Document section,\n        # let normal auto-detection (below) handle workbook selection\n\n    # Isolate frontmatter in sub-dict for round-trip fidelity\n    # Only when frontmatter IS the workbook root (virtual_root)\n    if virtual_root and frontmatter_metadata:\n        if metadata is None:\n            metadata = {}\n        metadata[\"header_type\"] = \"frontmatter\"\n        metadata[\"frontmatter\"] = frontmatter_metadata\n\n    if root_marker is None:\n        # Auto-detection mode\n        # Find all H1 headers (not in code blocks)\n        h1_headers: list[tuple[int, str]] = []  # (line_index, header_text)\n        in_code_block = False\n\n        for i, line in enumerate(lines):\n            stripped = line.strip()\n            if stripped.startswith(\"```\"):\n                in_code_block = not in_code_block\n            elif (\n                not in_code_block\n                and stripped.startswith(\"# \")\n                and not stripped.startswith(\"## \")\n            ):\n                # This is an H1 header (starts with \"# \" but not \"## \")\n                header_text = stripped[2:].strip()\n                h1_headers.append((i, header_text))\n\n        if len(h1_headers) == 1:\n            # Single H1: use it as workbook\n            root_marker = h1_headers[0][1]\n            workbook_name = root_marker\n            root_marker = \"# \" + root_marker\n            workbook_level = 1\n        elif metadata is not None and len(h1_headers) &gt; 0:\n            # Step 3: If md-spreadsheet metadata exists, find the H1 that contains it\n            # The metadata comment should be inside a section, so we find the H1\n            # header that precedes the metadata comment location.\n            # Since we already extracted metadata, we need to find which H1 section\n            # contains it by re-scanning the original lines.\n\n            # Re-scan original lines to find metadata line index\n            original_lines = markdown.split(\"\\n\")\n            metadata_line_idx = None\n            for i, line in enumerate(original_lines):\n                stripped = line.strip()\n                if wb_metadata_pattern.match(stripped):\n                    metadata_line_idx = i\n                    break\n\n            if metadata_line_idx is not None:\n                # Find the H1 header that precedes this metadata line\n                # Map original line indices to filtered line indices\n                selected_h1 = None\n                for line_idx, header_text in h1_headers:\n                    # h1_headers contains indices in filtered_lines\n                    # Need to find corresponding original index\n                    # Actually, h1_headers was built from filtered_lines (after metadata removal)\n                    # So we need to re-scan original to find H1 before metadata\n                    pass\n\n                # Simpler approach: scan original lines for H1 headers before metadata\n                in_code_block = False\n                for i in range(metadata_line_idx - 1, -1, -1):\n                    stripped = original_lines[i].strip()\n                    if stripped.startswith(\"```\"):\n                        in_code_block = not in_code_block\n                    elif (\n                        not in_code_block\n                        and stripped.startswith(\"# \")\n                        and not stripped.startswith(\"## \")\n                    ):\n                        # Found the H1 header that contains the metadata\n                        header_text = stripped[2:].strip()\n                        root_marker = \"# \" + header_text\n                        workbook_name = header_text\n                        workbook_level = 1\n                        selected_h1 = header_text\n                        break\n\n                if selected_h1 is None:\n                    # Metadata exists but no H1 before it - use first H1\n                    if h1_headers:\n                        root_marker = h1_headers[0][1]\n                        workbook_name = root_marker\n                        root_marker = \"# \" + root_marker\n                        workbook_level = 1\n            else:\n                # Shouldn't happen since metadata was found\n                pass\n\n        if root_marker is None:\n            # Multiple or no H1: fallback to \"# Tables\" or \"# Workbook\"\n            in_code_block = False\n            for i, line in enumerate(lines):\n                stripped = line.strip()\n                if stripped.startswith(\"```\"):\n                    in_code_block = not in_code_block\n                elif not in_code_block:\n                    if stripped == \"# Tables\":\n                        root_marker = \"# Tables\"\n                        workbook_name = \"Tables\"\n                        workbook_level = 1\n                        break\n                    elif stripped == \"# Workbook\":\n                        root_marker = \"# Workbook\"\n                        workbook_name = \"Workbook\"\n                        workbook_level = 1\n                        break\n            if root_marker is None:\n                # No workbook found\n                return Workbook(sheets=[], name=workbook_name, metadata=metadata)\n    else:\n        # Explicit root_marker: extract name and level from it\n        if root_marker.startswith(\"#\"):\n            level = 0\n            for char in root_marker:\n                if char == \"#\":\n                    level += 1\n                else:\n                    break\n            workbook_level = level\n            workbook_name = root_marker[level:].strip()\n\n    # Calculate header levels if not explicitly set\n    # Only auto-calculate from workbook_level if root_marker was auto-detected\n    # When root_marker is explicit, honor the explicit None values (meaning \"no headers\")\n    root_marker_auto_detected = schema.root_marker is None\n\n    if schema.sheet_header_level is not None:\n        sheet_header_level = schema.sheet_header_level\n    elif root_marker_auto_detected:\n        sheet_header_level = workbook_level + 1\n    else:\n        # Explicit root_marker but no sheet_header_level: default to 2\n        sheet_header_level = 2\n\n    if schema.table_header_level is not None:\n        table_header_level: int | None = schema.table_header_level\n    elif root_marker_auto_detected:\n        table_header_level = workbook_level + 2\n    else:\n        # Explicit root_marker but no table_header_level: keep as None (no table headers)\n        table_header_level = None\n\n    # Create an effective schema with resolved values\n    effective_schema = replace(\n        schema,\n        root_marker=root_marker,\n        sheet_header_level=sheet_header_level,\n        table_header_level=table_header_level,\n    )\n\n    # Find root marker\n    start_index = 0\n    workbook_start_line: int | None = None\n    in_code_block = False\n    found = False\n\n    if virtual_root:\n        start_index = 0\n        workbook_start_line = 0\n        found = True\n    else:\n        for i, line in enumerate(lines):\n            stripped = line.strip()\n            if stripped.startswith(\"```\"):\n                in_code_block = not in_code_block\n\n            if not in_code_block and stripped == root_marker:\n                start_index = i + 1\n                workbook_start_line = i\n                found = True\n                break\n\n    if not found:\n        return Workbook(sheets=[], name=workbook_name, metadata=metadata)\n\n    # Split by sheet headers\n    header_prefix = \"#\" * sheet_header_level + \" \"\n\n    current_sheet_name: str | None = None\n    current_sheet_lines: list[str] = []\n    current_sheet_start_line = start_index\n\n    # Reset code block state for the second pass\n    # If we started after a root marker, check if that root marker line was just a marker.\n    # We assume valid markdown structure where root marker is not inside a code block (handled above).\n    in_code_block = False\n\n    # Capture root content (text between workbook header and first sheet header)\n    root_content_lines: list[str] = []\n\n    # Track workbook section end line\n    # If loop breaks due to another H1, end is line before that H1\n    # Otherwise end is the last line of the file\n    workbook_end_line: int | None = None\n\n    for idx, line in enumerate(lines[start_index:], start=start_index):\n        stripped = line.strip()\n\n        if stripped.startswith(\"```\"):\n            in_code_block = not in_code_block\n\n        if in_code_block:\n            # Just collect lines if we are in a sheet or root content\n            if current_sheet_name:\n                current_sheet_lines.append(line)\n            else:\n                root_content_lines.append(line)\n            workbook_end_line = idx + 1  # Track last line in section\n            continue\n\n        # Check if line is a header\n        if stripped.startswith(\"#\"):\n            # Count header level\n            level = 0\n            for char in stripped:\n                if char == \"#\":\n                    level += 1\n                else:\n                    break\n\n            # If header level is less than sheet_header_level (e.g. # vs ##),\n            # it indicates a higher-level section, so we stop parsing the workbook.\n            if level &lt; sheet_header_level:\n                # workbook_end_line is already set to last processed line\n                break\n\n            # If header match sheet_header_level, it's a new sheet\n            if level == sheet_header_level and stripped.startswith(header_prefix):\n                if current_sheet_name:\n                    sheet_content = \"\\n\".join(current_sheet_lines)\n                    sheets.append(\n                        parse_sheet(\n                            sheet_content,\n                            current_sheet_name,\n                            effective_schema,\n                            start_line_offset=current_sheet_start_line + 1,\n                        )\n                    )\n\n                current_sheet_name = stripped[len(header_prefix) :].strip()\n                current_sheet_lines = []\n                current_sheet_start_line = idx\n                workbook_end_line = idx + 1\n                continue\n\n        # Not a sheet header\n        if current_sheet_name:\n            current_sheet_lines.append(line)\n        else:\n            # We are in root content area (between Workbook header and first Sheet)\n            root_content_lines.append(line)\n\n        workbook_end_line = idx + 1  # Track last line processed (exclusive end)\n\n    if current_sheet_name:\n        sheet_content = \"\\n\".join(current_sheet_lines)\n        sheets.append(\n            parse_sheet(\n                sheet_content,\n                current_sheet_name,\n                effective_schema,\n                start_line_offset=current_sheet_start_line + 1,\n            )\n        )\n\n    # If no lines were processed, end_line is start_line + 1\n    if workbook_end_line is None:\n        workbook_end_line = (\n            workbook_start_line + 1 if workbook_start_line is not None else None\n        )\n\n    root_content: str | None = None\n    if root_content_lines:\n        content = \"\\n\".join(root_content_lines)\n        if content.strip():\n            root_content = content.strip()\n\n    return Workbook(\n        sheets=sheets,\n        name=workbook_name,\n        start_line=workbook_start_line,\n        end_line=workbook_end_line,\n        metadata=metadata,\n        root_content=root_content,\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.parse_workbook_from_file","title":"<code>parse_workbook_from_file(source, schema=MultiTableParsingSchema())</code>","text":"<p>Parse a markdown workbook from a file.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[str, Path, TextIO]</code> <p>File path (str/Path) or file-like object.</p> required <code>schema</code> <code>MultiTableParsingSchema</code> <p>Parsing configuration.</p> <code>MultiTableParsingSchema()</code> Source code in <code>src/md_spreadsheet_parser/loader.py</code> <pre><code>def parse_workbook_from_file(\n    source: Union[str, Path, TextIO],\n    schema: MultiTableParsingSchema = MultiTableParsingSchema(),\n) -&gt; Workbook:\n    \"\"\"\n    Parse a markdown workbook from a file.\n\n    Args:\n        source: File path (str/Path) or file-like object.\n        schema: Parsing configuration.\n    \"\"\"\n    content = _read_content(source)\n    return parse_workbook(content, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.scan_tables","title":"<code>scan_tables(markdown, schema=None)</code>","text":"<p>Scan a markdown document for all tables, ignoring sheet structure.</p> <p>Parameters:</p> Name Type Description Default <code>markdown</code> <code>str</code> <p>The markdown text.</p> required <code>schema</code> <code>MultiTableParsingSchema | None</code> <p>Optional schema. If None, uses default MultiTableParsingSchema.</p> <code>None</code> <p>Returns:</p> Source code in <code>src/md_spreadsheet_parser/parsing.py</code> <pre><code>def scan_tables(\n    markdown: str, schema: MultiTableParsingSchema | None = None\n) -&gt; list[Table]:\n    \"\"\"\n    Scan a markdown document for all tables, ignoring sheet structure.\n\n    Args:\n        markdown: The markdown text.\n        schema: Optional schema. If None, uses default MultiTableParsingSchema.\n\n    Returns:\n    \"\"\"\n    if schema is None:\n        schema = MultiTableParsingSchema()\n\n    return _extract_tables(markdown, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.scan_tables_from_file","title":"<code>scan_tables_from_file(source, schema=None)</code>","text":"<p>Scan a markdown file for all tables.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[str, Path, TextIO]</code> <p>File path (str/Path) or file-like object.</p> required <code>schema</code> <code>MultiTableParsingSchema | None</code> <p>Optional schema.</p> <code>None</code> Source code in <code>src/md_spreadsheet_parser/loader.py</code> <pre><code>def scan_tables_from_file(\n    source: Union[str, Path, TextIO], schema: MultiTableParsingSchema | None = None\n) -&gt; list[Table]:\n    \"\"\"\n    Scan a markdown file for all tables.\n\n    Args:\n        source: File path (str/Path) or file-like object.\n        schema: Optional schema.\n    \"\"\"\n    content = _read_content(source)\n    return scan_tables(content, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.scan_tables_iter","title":"<code>scan_tables_iter(source, schema=None)</code>","text":"<p>Stream tables from a source (file path, file object, or iterable) one by one. This allows processing files larger than memory, provided that individual tables fit in memory.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[str, Path, TextIO, Iterable[str]]</code> <p>File path, open file object, or iterable of strings.</p> required <code>schema</code> <code>MultiTableParsingSchema | None</code> <p>Parsing configuration.</p> <code>None</code> <p>Yields:</p> Type Description <code>Table</code> <p>Table objects found in the stream.</p> Source code in <code>src/md_spreadsheet_parser/loader.py</code> <pre><code>def scan_tables_iter(\n    source: Union[str, Path, TextIO, Iterable[str]],\n    schema: MultiTableParsingSchema | None = None,\n) -&gt; Iterator[Table]:\n    \"\"\"\n    Stream tables from a source (file path, file object, or iterable) one by one.\n    This allows processing files larger than memory, provided that individual tables fit in memory.\n\n    Args:\n        source: File path, open file object, or iterable of strings.\n        schema: Parsing configuration.\n\n    Yields:\n        Table objects found in the stream.\n    \"\"\"\n    if schema is None:\n        schema = MultiTableParsingSchema()\n\n    header_prefix = None\n    if schema.table_header_level is not None:\n        header_prefix = \"#\" * schema.table_header_level + \" \"\n\n    current_lines: list[str] = []\n    current_name: str | None = None\n    # We track line number manually for metadata\n    current_line_idx = 0\n    # Start of the current block\n    block_start_line = 0\n\n    def parse_and_yield(\n        lines: list[str], name: str | None, start_offset: int\n    ) -&gt; Iterator[Table]:\n        if not lines:\n            return\n\n        # Check if block looks like a table (has separator)\n        block_text = \"\".join(lines)\n\n        if schema.column_separator not in block_text:\n            return\n\n        # Simple extraction logic similar to process_table_block\n        # We reuse parsing logic.\n\n        # Split description vs table\n        # We need list of lines stripped of newline for index finding\n        stripped_lines = [line_val.rstrip(\"\\n\") for line_val in lines]\n\n        table_start_idx = -1\n        for idx, line in enumerate(stripped_lines):\n            if schema.column_separator in line:\n                table_start_idx = idx\n                break\n\n        if table_start_idx != -1:\n            desc_lines = stripped_lines[:table_start_idx]\n            table_lines = stripped_lines[table_start_idx:]\n\n            table_text = \"\\n\".join(table_lines)\n            table = parse_table(table_text, schema)\n\n            if table.rows or table.headers:\n                description = None\n                if schema.capture_description:\n                    desc_text = \"\\n\".join(d.strip() for d in desc_lines if d.strip())\n                    if desc_text:\n                        description = desc_text\n\n                table = replace(\n                    table,\n                    name=name,\n                    description=description,\n                    start_line=start_offset + table_start_idx,\n                    end_line=start_offset + len(lines),\n                )\n                yield table\n\n    for line in _iter_lines(source):\n        # normalize: file iter yields line with \\n\n        stripped_line = line.strip()\n\n        is_header = header_prefix and stripped_line.startswith(header_prefix)\n\n        if is_header:\n            # New section starts. Yield previous buffer if any.\n            yield from parse_and_yield(current_lines, current_name, block_start_line)\n\n            assert header_prefix is not None\n            current_name = stripped_line[len(header_prefix) :].strip()\n            current_lines = []\n            block_start_line = current_line_idx\n\n        elif stripped_line == \"\":\n            # Blank line.\n            yield from parse_and_yield(current_lines, current_name, block_start_line)\n            current_lines = []\n            # block_start_line for NEXT block will be current_line_idx + 1\n            block_start_line = current_line_idx + 1\n\n        else:\n            current_lines.append(line)\n\n        current_line_idx += 1\n\n    # End of stream\n    yield from parse_and_yield(current_lines, current_name, block_start_line)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.schemas","title":"<code>md_spreadsheet_parser.schemas</code>","text":""},{"location":"api/#md_spreadsheet_parser.schemas.ConversionSchema","title":"<code>ConversionSchema</code>  <code>dataclass</code>","text":"<p>Configuration for converting string values to Python types.</p> <p>Attributes:</p> Name Type Description <code>boolean_pairs</code> <code>tuple[tuple[str, str], ...]</code> <p>Pairs of strings representing (True, False). Case-insensitive.            Example: <code>((\"yes\", \"no\"), (\"on\", \"off\"))</code>.</p> <code>custom_converters</code> <code>dict[type, Callable[[str], Any]]</code> <p>Dictionary mapping ANY Python type to a conversion function <code>str -&gt; Any</code>.                You can specify:                - Built-in types: <code>int</code>, <code>float</code>, <code>bool</code> (to override default behavior)                - Standard library types: <code>Decimal</code>, <code>datetime</code>, <code>date</code>, <code>ZoneInfo</code>                - Custom classes: <code>MyClass</code>, <code>Product</code></p> <code>field_converters</code> <code>dict[str, Callable[[str], Any]]</code> <p>Dictionary mapping field names (str) to conversion functions.               Takes precedence over <code>custom_converters</code>.</p> Source code in <code>src/md_spreadsheet_parser/schemas.py</code> <pre><code>@dataclass(frozen=True)\nclass ConversionSchema:\n    \"\"\"\n    Configuration for converting string values to Python types.\n\n    Attributes:\n        boolean_pairs: Pairs of strings representing (True, False). Case-insensitive.\n                       Example: `((\"yes\", \"no\"), (\"on\", \"off\"))`.\n        custom_converters: Dictionary mapping ANY Python type to a conversion function `str -&gt; Any`.\n                           You can specify:\n                           - Built-in types: `int`, `float`, `bool` (to override default behavior)\n                           - Standard library types: `Decimal`, `datetime`, `date`, `ZoneInfo`\n                           - Custom classes: `MyClass`, `Product`\n        field_converters: Dictionary mapping field names (str) to conversion functions.\n                          Takes precedence over `custom_converters`.\n    \"\"\"\n\n    boolean_pairs: tuple[tuple[str, str], ...] = (\n        (\"true\", \"false\"),\n        (\"yes\", \"no\"),\n        (\"1\", \"0\"),\n        (\"on\", \"off\"),\n        (\"[x]\", \"[ ]\"),\n    )\n    custom_converters: dict[type, Callable[[str], Any]] = field(default_factory=dict)\n    field_converters: dict[str, Callable[[str], Any]] = field(default_factory=dict)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.schemas.ExcelParsingSchema","title":"<code>ExcelParsingSchema</code>  <code>dataclass</code>","text":"<p>Configuration for parsing Excel-exported data (TSV/CSV or openpyxl).</p> <p>Attributes:</p> Name Type Description <code>header_rows</code> <code>int</code> <p>Number of header rows (1 or 2).          If 2, headers are flattened to \"Parent - Child\" format.</p> <code>fill_merged_headers</code> <code>bool</code> <p>Whether to forward-fill empty header cells                  (for merged cells in Excel exports).</p> <code>delimiter</code> <code>str</code> <p>Column separator for TSV/CSV parsing. Default is tab.</p> <code>header_separator</code> <code>str</code> <p>Separator used when flattening 2-row headers.</p> Source code in <code>src/md_spreadsheet_parser/schemas.py</code> <pre><code>@dataclass(frozen=True)\nclass ExcelParsingSchema:\n    \"\"\"\n    Configuration for parsing Excel-exported data (TSV/CSV or openpyxl).\n\n    Attributes:\n        header_rows: Number of header rows (1 or 2).\n                     If 2, headers are flattened to \"Parent - Child\" format.\n        fill_merged_headers: Whether to forward-fill empty header cells\n                             (for merged cells in Excel exports).\n        delimiter: Column separator for TSV/CSV parsing. Default is tab.\n        header_separator: Separator used when flattening 2-row headers.\n    \"\"\"\n\n    header_rows: int = 1\n    fill_merged_headers: bool = True\n    delimiter: str = \"\\t\"\n    header_separator: str = \" - \"\n\n    def __post_init__(self):\n        if self.header_rows not in (1, 2):\n            raise ValueError(\"header_rows must be 1 or 2\")\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.schemas.MultiTableParsingSchema","title":"<code>MultiTableParsingSchema</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ParsingSchema</code></p> <p>Configuration for parsing multiple tables (workbook mode). Inherits from ParsingSchema.</p> <p>Attributes:</p> Name Type Description <code>root_marker</code> <code>str | None</code> <p>The marker indicating the start of the data section. If None, auto-detection is used: single H1 \u2192 Workbook, or fallback to \"# Tables\" / \"# Workbook\". Defaults to None.</p> <code>sheet_header_level</code> <code>int | None</code> <p>The markdown header level for sheets. If None, derived from workbook_level + 1. Defaults to None.</p> <code>table_header_level</code> <code>int | None</code> <p>The markdown header level for tables. If None, derived from workbook_level + 2. Defaults to None.</p> <code>capture_description</code> <code>bool</code> <p>Whether to capture text between the table header and the table as a description. Defaults to True.</p> Source code in <code>src/md_spreadsheet_parser/schemas.py</code> <pre><code>@dataclass(frozen=True)\nclass MultiTableParsingSchema(ParsingSchema):\n    \"\"\"\n    Configuration for parsing multiple tables (workbook mode).\n    Inherits from ParsingSchema.\n\n    Attributes:\n        root_marker (str | None): The marker indicating the start of the data section.\n            If None, auto-detection is used: single H1 \u2192 Workbook, or fallback to\n            \"# Tables\" / \"# Workbook\". Defaults to None.\n        sheet_header_level (int | None): The markdown header level for sheets.\n            If None, derived from workbook_level + 1. Defaults to None.\n        table_header_level (int | None): The markdown header level for tables.\n            If None, derived from workbook_level + 2. Defaults to None.\n        capture_description (bool): Whether to capture text between the table header\n            and the table as a description. Defaults to True.\n    \"\"\"\n\n    root_marker: str | None = None\n    sheet_header_level: int | None = None\n    table_header_level: int | None = None\n    capture_description: bool = True\n\n    def __post_init__(self):\n        # Handle ParsingSchema defaults manually since they are separate fields in instance\n        if self.column_separator is None:\n            object.__setattr__(self, \"column_separator\", \"|\")\n        if self.header_separator_char is None:\n            object.__setattr__(self, \"header_separator_char\", \"-\")\n        if self.require_outer_pipes is None:\n            object.__setattr__(self, \"require_outer_pipes\", True)\n        if self.strip_whitespace is None:\n            object.__setattr__(self, \"strip_whitespace\", True)\n        if self.convert_br_to_newline is None:\n            object.__setattr__(self, \"convert_br_to_newline\", True)\n\n        # root_marker, sheet_header_level, table_header_level can all be None\n        # (auto-detection is handled in parsing.py)\n\n        if self.capture_description is None:\n            object.__setattr__(self, \"capture_description\", True)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.schemas.ParsingSchema","title":"<code>ParsingSchema</code>  <code>dataclass</code>","text":"<p>Configuration for parsing markdown tables. Designed to be immutable and passed to pure functions.</p> <p>Attributes:</p> Name Type Description <code>column_separator</code> <code>str</code> <p>Character used to separate columns. Defaults to \"|\".</p> <code>header_separator_char</code> <code>str</code> <p>Character used in the separator row. Defaults to \"-\".</p> <code>require_outer_pipes</code> <code>bool</code> <p>Whether tables must have outer pipes (e.g. <code>| col |</code>). Defaults to True.</p> <code>strip_whitespace</code> <code>bool</code> <p>Whether to strip whitespace from cell values. Defaults to True.</p> Source code in <code>src/md_spreadsheet_parser/schemas.py</code> <pre><code>@dataclass(frozen=True)\nclass ParsingSchema:\n    \"\"\"\n    Configuration for parsing markdown tables.\n    Designed to be immutable and passed to pure functions.\n\n    Attributes:\n        column_separator (str): Character used to separate columns. Defaults to \"|\".\n        header_separator_char (str): Character used in the separator row. Defaults to \"-\".\n        require_outer_pipes (bool): Whether tables must have outer pipes (e.g. `| col |`). Defaults to True.\n        strip_whitespace (bool): Whether to strip whitespace from cell values. Defaults to True.\n    \"\"\"\n\n    column_separator: str = \"|\"\n    header_separator_char: str = \"-\"\n    require_outer_pipes: bool = True\n    strip_whitespace: bool = True\n    convert_br_to_newline: bool = True\n\n    def __post_init__(self):\n        # Ensure defaults if None is passed (e.g. from WASM)\n        if self.column_separator is None:\n            object.__setattr__(self, \"column_separator\", \"|\")\n        if self.header_separator_char is None:\n            object.__setattr__(self, \"header_separator_char\", \"-\")\n        if self.require_outer_pipes is None:\n            object.__setattr__(self, \"require_outer_pipes\", True)\n        if self.strip_whitespace is None:\n            object.__setattr__(self, \"strip_whitespace\", True)\n        if self.convert_br_to_newline is None:\n            object.__setattr__(self, \"convert_br_to_newline\", True)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models","title":"<code>md_spreadsheet_parser.models</code>","text":""},{"location":"api/#md_spreadsheet_parser.models.Sheet","title":"<code>Sheet</code>  <code>dataclass</code>","text":"<p>Represents a single sheet containing tables.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the sheet.</p> <code>tables</code> <code>list[Table]</code> <p>List of tables contained in this sheet.</p> <code>sheet_type</code> <code>SheetType</code> <p>Type of sheet - \"table\" for table sheet, \"doc\" for document sheet.</p> <code>content</code> <code>str | None</code> <p>Raw markdown content for doc sheets. Only set when sheet_type=\"doc\".</p> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Arbitrary metadata (e.g. layout). Defaults to None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>@dataclass(frozen=True)\nclass Sheet:\n    \"\"\"\n    Represents a single sheet containing tables.\n\n    Attributes:\n        name (str): Name of the sheet.\n        tables (list[Table]): List of tables contained in this sheet.\n        sheet_type (SheetType): Type of sheet - \"table\" for table sheet, \"doc\" for document sheet.\n        content (str | None): Raw markdown content for doc sheets. Only set when sheet_type=\"doc\".\n        metadata (dict[str, Any] | None): Arbitrary metadata (e.g. layout). Defaults to None.\n    \"\"\"\n\n    name: str\n    tables: list[Table]\n    sheet_type: SheetType = \"table\"\n    content: str | None = None\n    metadata: dict[str, Any] | None = None\n\n    def __post_init__(self):\n        if self.metadata is None:\n            # Hack to allow default value for mutable type in frozen dataclass\n            object.__setattr__(self, \"metadata\", {})\n\n    @property\n    def json(self) -&gt; SheetJSON:\n        \"\"\"\n        Returns a JSON-compatible dictionary representation of the sheet.\n\n        Returns:\n            SheetJSON: A dictionary containing the sheet data.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"sheet_type\": self.sheet_type,\n            \"content\": self.content,\n            \"tables\": [t.json for t in self.tables],\n            \"metadata\": self.metadata if self.metadata is not None else {},\n        }\n\n    def get_table(self, name: str) -&gt; Table | None:\n        \"\"\"\n        Retrieve a table by its name.\n\n        Args:\n            name (str): The name of the table to retrieve.\n\n        Returns:\n            Table | None: The table object if found, otherwise None.\n        \"\"\"\n        for table in self.tables:\n            if table.name == name:\n                return table\n        return None\n\n    def to_markdown(self, schema: ParsingSchema = DEFAULT_SCHEMA) -&gt; str:\n        \"\"\"\n        Generates a Markdown string representation of the sheet.\n\n        Args:\n            schema (ParsingSchema, optional): Configuration for formatting.\n\n        Returns:\n            str: The Markdown string.\n        \"\"\"\n        return generate_sheet_markdown(self, schema)\n\n    def rename(self, new_name: str) -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with the name changed.\n        \"\"\"\n        return replace(self, name=new_name)\n\n    def add_table(self, name: str | None = None) -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with a new empty table appended.\n        \"\"\"\n        new_table = Table(headers=[\"A\", \"B\", \"C\"], rows=[[\"\", \"\", \"\"]], name=name)\n        new_tables = list(self.tables)\n        new_tables.append(new_table)\n        return replace(self, tables=new_tables)\n\n    def delete_table(self, index: int) -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with the table at index removed.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.tables):\n            raise IndexError(\"Table index out of range\")\n\n        new_tables = list(self.tables)\n        new_tables.pop(index)\n        return replace(self, tables=new_tables)\n\n    def replace_table(self, index: int, table: \"Table\") -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with the table at index replaced.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.tables):\n            raise IndexError(\"Table index out of range\")\n\n        new_tables = list(self.tables)\n        new_tables[index] = table\n        return replace(self, tables=new_tables)\n\n    def move_table(self, from_index: int, to_index: int) -&gt; \"Sheet\":\n        \"\"\"\n        Return a new Sheet with the table moved from from_index to to_index.\n        \"\"\"\n        if from_index &lt; 0 or from_index &gt;= len(self.tables):\n            raise IndexError(\"from_index out of range\")\n        if to_index &lt; 0 or to_index &gt;= len(self.tables):\n            raise IndexError(\"to_index out of range\")\n\n        new_tables = list(self.tables)\n        table = new_tables.pop(from_index)\n        new_tables.insert(to_index, table)\n        return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Sheet.json","title":"<code>json</code>  <code>property</code>","text":"<p>Returns a JSON-compatible dictionary representation of the sheet.</p> <p>Returns:</p> Name Type Description <code>SheetJSON</code> <code>SheetJSON</code> <p>A dictionary containing the sheet data.</p>"},{"location":"api/#md_spreadsheet_parser.models.Sheet.add_table","title":"<code>add_table(name=None)</code>","text":"<p>Return a new Sheet with a new empty table appended.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def add_table(self, name: str | None = None) -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with a new empty table appended.\n    \"\"\"\n    new_table = Table(headers=[\"A\", \"B\", \"C\"], rows=[[\"\", \"\", \"\"]], name=name)\n    new_tables = list(self.tables)\n    new_tables.append(new_table)\n    return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Sheet.delete_table","title":"<code>delete_table(index)</code>","text":"<p>Return a new Sheet with the table at index removed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def delete_table(self, index: int) -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with the table at index removed.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.tables):\n        raise IndexError(\"Table index out of range\")\n\n    new_tables = list(self.tables)\n    new_tables.pop(index)\n    return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Sheet.get_table","title":"<code>get_table(name)</code>","text":"<p>Retrieve a table by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the table to retrieve.</p> required <p>Returns:</p> Type Description <code>Table | None</code> <p>Table | None: The table object if found, otherwise None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def get_table(self, name: str) -&gt; Table | None:\n    \"\"\"\n    Retrieve a table by its name.\n\n    Args:\n        name (str): The name of the table to retrieve.\n\n    Returns:\n        Table | None: The table object if found, otherwise None.\n    \"\"\"\n    for table in self.tables:\n        if table.name == name:\n            return table\n    return None\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Sheet.move_table","title":"<code>move_table(from_index, to_index)</code>","text":"<p>Return a new Sheet with the table moved from from_index to to_index.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def move_table(self, from_index: int, to_index: int) -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with the table moved from from_index to to_index.\n    \"\"\"\n    if from_index &lt; 0 or from_index &gt;= len(self.tables):\n        raise IndexError(\"from_index out of range\")\n    if to_index &lt; 0 or to_index &gt;= len(self.tables):\n        raise IndexError(\"to_index out of range\")\n\n    new_tables = list(self.tables)\n    table = new_tables.pop(from_index)\n    new_tables.insert(to_index, table)\n    return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Sheet.rename","title":"<code>rename(new_name)</code>","text":"<p>Return a new Sheet with the name changed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def rename(self, new_name: str) -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with the name changed.\n    \"\"\"\n    return replace(self, name=new_name)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Sheet.replace_table","title":"<code>replace_table(index, table)</code>","text":"<p>Return a new Sheet with the table at index replaced.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def replace_table(self, index: int, table: \"Table\") -&gt; \"Sheet\":\n    \"\"\"\n    Return a new Sheet with the table at index replaced.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.tables):\n        raise IndexError(\"Table index out of range\")\n\n    new_tables = list(self.tables)\n    new_tables[index] = table\n    return replace(self, tables=new_tables)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Sheet.to_markdown","title":"<code>to_markdown(schema=DEFAULT_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the sheet.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def to_markdown(self, schema: ParsingSchema = DEFAULT_SCHEMA) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the sheet.\n\n    Args:\n        schema (ParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    return generate_sheet_markdown(self, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.SheetJSON","title":"<code>SheetJSON</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>JSON-compatible dictionary representation of a Sheet.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>class SheetJSON(TypedDict):\n    \"\"\"\n    JSON-compatible dictionary representation of a Sheet.\n    \"\"\"\n\n    name: str\n    sheet_type: SheetType\n    content: str | None\n    tables: list[TableJSON]\n    metadata: dict[str, Any]\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table","title":"<code>Table</code>  <code>dataclass</code>","text":"<p>Represents a parsed table with optional metadata.</p> <p>Attributes:</p> Name Type Description <code>headers</code> <code>list[str] | None</code> <p>List of column headers, or None if the table has no headers.</p> <code>rows</code> <code>list[list[str]]</code> <p>List of data rows.</p> <code>alignments</code> <code>list[AlignmentType] | None</code> <p>List of column alignments ('left', 'center', 'right'). Defaults to None.</p> <code>name</code> <code>str | None</code> <p>Name of the table (e.g. from a header). Defaults to None.</p> <code>description</code> <code>str | None</code> <p>Description of the table. Defaults to None.</p> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Arbitrary metadata. Defaults to None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>@dataclass(frozen=True)\nclass Table:\n    \"\"\"\n    Represents a parsed table with optional metadata.\n\n    Attributes:\n        headers (list[str] | None): List of column headers, or None if the table has no headers.\n        rows (list[list[str]]): List of data rows.\n        alignments (list[AlignmentType] | None): List of column alignments ('left', 'center', 'right'). Defaults to None.\n        name (str | None): Name of the table (e.g. from a header). Defaults to None.\n        description (str | None): Description of the table. Defaults to None.\n        metadata (dict[str, Any] | None): Arbitrary metadata. Defaults to None.\n    \"\"\"\n\n    headers: list[str] | None\n    rows: list[list[str]]\n    alignments: list[AlignmentType] | None = None\n    name: str | None = None\n    description: str | None = None\n    metadata: dict[str, Any] | None = None\n    start_line: int | None = None\n    end_line: int | None = None\n\n    def __post_init__(self):\n        if self.metadata is None:\n            # Hack to allow default value for mutable type in frozen dataclass\n            object.__setattr__(self, \"metadata\", {})\n\n    @property\n    def json(self) -&gt; TableJSON:\n        \"\"\"\n        Returns a JSON-compatible dictionary representation of the table.\n\n        Returns:\n            TableJSON: A dictionary containing the table data.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"headers\": self.headers,\n            \"rows\": self.rows,\n            \"metadata\": self.metadata if self.metadata is not None else {},\n            \"start_line\": self.start_line,\n            \"end_line\": self.end_line,\n            \"alignments\": self.alignments,\n        }\n\n    def to_models(\n        self,\n        schema_cls: type[T],\n        conversion_schema: ConversionSchema = DEFAULT_CONVERSION_SCHEMA,\n    ) -&gt; list[T]:\n        \"\"\"\n        Converts the table rows into a list of dataclass instances, performing validation and type conversion.\n\n        Args:\n            schema_cls (type[T]): The dataclass type to validate against.\n            conversion_schema (ConversionSchema, optional): Configuration for type conversion.\n\n        Returns:\n            list[T]: A list of validated dataclass instances.\n\n        Raises:\n            ValueError: If schema_cls is not a dataclass.\n            TableValidationError: If validation fails for any row or if the table has no headers.\n        \"\"\"\n        return validate_table(self, schema_cls, conversion_schema)\n\n    def to_markdown(self, schema: ParsingSchema = DEFAULT_SCHEMA) -&gt; str:\n        \"\"\"\n        Generates a Markdown string representation of the table.\n\n        Args:\n            schema (ParsingSchema, optional): Configuration for formatting.\n\n        Returns:\n            str: The Markdown string.\n        \"\"\"\n        return generate_table_markdown(self, schema)\n\n    def update_cell(self, row_idx: int, col_idx: int, value: str) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the specified cell updated.\n        \"\"\"\n        # Handle header update\n        if row_idx == -1:\n            if self.headers is None:\n                # Determine width from rows if possible, or start fresh\n                width = len(self.rows[0]) if self.rows else (col_idx + 1)\n                new_headers = [\"\"] * width\n                # Ensure width enough\n                if col_idx &gt;= len(new_headers):\n                    new_headers.extend([\"\"] * (col_idx - len(new_headers) + 1))\n            else:\n                new_headers = list(self.headers)\n                if col_idx &gt;= len(new_headers):\n                    new_headers.extend([\"\"] * (col_idx - len(new_headers) + 1))\n\n            # Update alignments if headers grew\n            new_alignments = list(self.alignments) if self.alignments else []\n            if len(new_headers) &gt; len(new_alignments):\n                # Fill with default/None up to new width\n                # But we only need as many alignments as columns.\n                # If alignments is None, it stays None?\n                # Ideally if we start tracking alignments, we should init it?\n                # If self.alignments was None, we might keep it None unless explicitly set?\n                # Consistent behavior: If alignments is NOT None, expand it.\n                if self.alignments is not None:\n                    # Cast or explicit type check might be needed for strict type checkers with literals\n                    # Using a typed list to satisfy invariant list[AlignmentType]\n                    extension: list[AlignmentType] = [\"default\"] * (\n                        len(new_headers) - len(new_alignments)\n                    )\n                    new_alignments.extend(extension)\n\n            final_alignments = new_alignments if self.alignments is not None else None\n\n            new_headers[col_idx] = value\n\n            return replace(self, headers=new_headers, alignments=final_alignments)\n\n        # Handle Body update\n        # 1. Ensure row exists\n        new_rows = [list(r) for r in self.rows]\n\n        # Grow rows if needed\n        if row_idx &gt;= len(new_rows):\n            # Calculate width\n            width = (\n                len(self.headers)\n                if self.headers\n                else (len(new_rows[0]) if new_rows else 0)\n            )\n            if width == 0:\n                width = col_idx + 1  # At least cover the new cell\n\n            rows_to_add = row_idx - len(new_rows) + 1\n            for _ in range(rows_to_add):\n                new_rows.append([\"\"] * width)\n\n        # If columns expanded due to row update, we might need to expand alignments too\n        current_width = len(new_rows[0]) if new_rows else 0\n        if col_idx &gt;= current_width:\n            # This means we are expanding columns\n            if self.alignments is not None:\n                width_needed = col_idx + 1\n                current_align_len = len(self.alignments)\n                if width_needed &gt; current_align_len:\n                    new_alignments = list(self.alignments)\n                    extension: list[AlignmentType] = [\"default\"] * (\n                        width_needed - current_align_len\n                    )\n                    new_alignments.extend(extension)\n                    return replace(\n                        self,\n                        rows=self._update_rows_cell(new_rows, row_idx, col_idx, value),\n                        alignments=new_alignments,\n                    )\n\n        return replace(\n            self, rows=self._update_rows_cell(new_rows, row_idx, col_idx, value)\n        )\n\n    def _update_rows_cell(self, new_rows, row_idx, col_idx, value):\n        target_row = new_rows[row_idx]\n        if col_idx &gt;= len(target_row):\n            target_row.extend([\"\"] * (col_idx - len(target_row) + 1))\n        target_row[col_idx] = value\n        return new_rows\n\n    def delete_row(self, row_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the row at index removed.\n        \"\"\"\n        new_rows = [list(r) for r in self.rows]\n        if 0 &lt;= row_idx &lt; len(new_rows):\n            new_rows.pop(row_idx)\n        return replace(self, rows=new_rows)\n\n    def delete_column(self, col_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the column at index removed.\n        \"\"\"\n        new_headers = list(self.headers) if self.headers else None\n        if new_headers and 0 &lt;= col_idx &lt; len(new_headers):\n            new_headers.pop(col_idx)\n\n        new_rows = []\n        for row in self.rows:\n            new_row = list(row)\n            if 0 &lt;= col_idx &lt; len(new_row):\n                new_row.pop(col_idx)\n            new_rows.append(new_row)\n\n        new_alignments = None\n        if self.alignments is not None:\n            new_alignments = list(self.alignments)\n            if 0 &lt;= col_idx &lt; len(new_alignments):\n                new_alignments.pop(col_idx)\n\n        return replace(\n            self, headers=new_headers, rows=new_rows, alignments=new_alignments\n        )\n\n    def clear_column_data(self, col_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with data in the specified column cleared (set to empty string),\n        but headers and column structure preserved.\n        \"\"\"\n        # Headers remain unchanged\n\n        new_rows = []\n        for row in self.rows:\n            new_row = list(row)\n            if 0 &lt;= col_idx &lt; len(new_row):\n                new_row[col_idx] = \"\"\n            new_rows.append(new_row)\n\n        return replace(self, rows=new_rows)\n\n    def insert_row(self, row_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with an empty row inserted at row_idx.\n        Subsequent rows are shifted down.\n        \"\"\"\n        new_rows = [list(r) for r in self.rows]\n\n        # Determine width\n        width = (\n            len(self.headers) if self.headers else (len(new_rows[0]) if new_rows else 0)\n        )\n        if width == 0:\n            width = 1  # Default to 1 column if table is empty\n\n        new_row = [\"\"] * width\n\n        if row_idx &lt; 0:\n            row_idx = 0\n        if row_idx &gt; len(new_rows):\n            row_idx = len(new_rows)\n\n        new_rows.insert(row_idx, new_row)\n        return replace(self, rows=new_rows)\n\n    def insert_column(self, col_idx: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with an empty column inserted at col_idx.\n        Subsequent columns are shifted right.\n        \"\"\"\n        new_headers = list(self.headers) if self.headers else None\n\n        if new_headers:\n            if col_idx &lt; 0:\n                col_idx = 0\n            if col_idx &gt; len(new_headers):\n                col_idx = len(new_headers)\n            new_headers.insert(col_idx, \"\")\n\n        new_alignments = None\n        if self.alignments is not None:\n            new_alignments = list(self.alignments)\n            # Pad if needed before insertion?\n            if col_idx &gt; len(new_alignments):\n                extension: list[AlignmentType] = [\"default\"] * (\n                    col_idx - len(new_alignments)\n                )\n                new_alignments.extend(extension)\n            new_alignments.insert(col_idx, \"default\")  # Default alignment\n\n        new_rows = []\n        for row in self.rows:\n            new_row = list(row)\n            # Ensure row is long enough before insertion logic?\n            # Or just insert.\n            # If col_idx is way past end, we might need padding?\n            # Standard list.insert handles index &gt; len -&gt; append.\n            current_len = len(new_row)\n            target_idx = col_idx\n            if target_idx &gt; current_len:\n                # Pad up to target\n                new_row.extend([\"\"] * (target_idx - current_len))\n                target_idx = len(new_row)  # Append\n\n            new_row.insert(target_idx, \"\")\n            new_rows.append(new_row)\n\n        return replace(\n            self, headers=new_headers, rows=new_rows, alignments=new_alignments\n        )\n\n    def rename(self, new_name: str) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the name changed.\n        \"\"\"\n        return replace(self, name=new_name)\n\n    def move_row(self, from_index: int, to_index: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the row moved from from_index to to_index.\n        \"\"\"\n        if from_index &lt; 0 or from_index &gt;= len(self.rows):\n            raise IndexError(\"from_index out of range\")\n        if to_index &lt; 0 or to_index &gt;= len(self.rows):\n            raise IndexError(\"to_index out of range\")\n\n        new_rows = [list(r) for r in self.rows]\n        row = new_rows.pop(from_index)\n        new_rows.insert(to_index, row)\n        return replace(self, rows=new_rows)\n\n    def move_column(self, from_index: int, to_index: int) -&gt; \"Table\":\n        \"\"\"\n        Return a new Table with the column moved from from_index to to_index.\n        \"\"\"\n        # Determine width from headers or first row\n        width = (\n            len(self.headers)\n            if self.headers\n            else (len(self.rows[0]) if self.rows else 0)\n        )\n        if from_index &lt; 0 or from_index &gt;= width:\n            raise IndexError(\"from_index out of range\")\n        if to_index &lt; 0 or to_index &gt;= width:\n            raise IndexError(\"to_index out of range\")\n\n        # Move header\n        new_headers = None\n        if self.headers:\n            new_headers = list(self.headers)\n            header = new_headers.pop(from_index)\n            new_headers.insert(to_index, header)\n\n        # Move alignments\n        new_alignments = None\n        if self.alignments:\n            new_alignments = list(self.alignments)\n            if from_index &lt; len(new_alignments):\n                alignment = new_alignments.pop(from_index)\n                new_alignments.insert(to_index, alignment)\n\n        # Move data in each row\n        new_rows = []\n        for row in self.rows:\n            new_row = list(row)\n            if from_index &lt; len(new_row):\n                cell = new_row.pop(from_index)\n                new_row.insert(to_index, cell)\n            new_rows.append(new_row)\n\n        return replace(\n            self, headers=new_headers, rows=new_rows, alignments=new_alignments\n        )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.json","title":"<code>json</code>  <code>property</code>","text":"<p>Returns a JSON-compatible dictionary representation of the table.</p> <p>Returns:</p> Name Type Description <code>TableJSON</code> <code>TableJSON</code> <p>A dictionary containing the table data.</p>"},{"location":"api/#md_spreadsheet_parser.models.Table.clear_column_data","title":"<code>clear_column_data(col_idx)</code>","text":"<p>Return a new Table with data in the specified column cleared (set to empty string), but headers and column structure preserved.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def clear_column_data(self, col_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with data in the specified column cleared (set to empty string),\n    but headers and column structure preserved.\n    \"\"\"\n    # Headers remain unchanged\n\n    new_rows = []\n    for row in self.rows:\n        new_row = list(row)\n        if 0 &lt;= col_idx &lt; len(new_row):\n            new_row[col_idx] = \"\"\n        new_rows.append(new_row)\n\n    return replace(self, rows=new_rows)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.delete_column","title":"<code>delete_column(col_idx)</code>","text":"<p>Return a new Table with the column at index removed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def delete_column(self, col_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the column at index removed.\n    \"\"\"\n    new_headers = list(self.headers) if self.headers else None\n    if new_headers and 0 &lt;= col_idx &lt; len(new_headers):\n        new_headers.pop(col_idx)\n\n    new_rows = []\n    for row in self.rows:\n        new_row = list(row)\n        if 0 &lt;= col_idx &lt; len(new_row):\n            new_row.pop(col_idx)\n        new_rows.append(new_row)\n\n    new_alignments = None\n    if self.alignments is not None:\n        new_alignments = list(self.alignments)\n        if 0 &lt;= col_idx &lt; len(new_alignments):\n            new_alignments.pop(col_idx)\n\n    return replace(\n        self, headers=new_headers, rows=new_rows, alignments=new_alignments\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.delete_row","title":"<code>delete_row(row_idx)</code>","text":"<p>Return a new Table with the row at index removed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def delete_row(self, row_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the row at index removed.\n    \"\"\"\n    new_rows = [list(r) for r in self.rows]\n    if 0 &lt;= row_idx &lt; len(new_rows):\n        new_rows.pop(row_idx)\n    return replace(self, rows=new_rows)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.insert_column","title":"<code>insert_column(col_idx)</code>","text":"<p>Return a new Table with an empty column inserted at col_idx. Subsequent columns are shifted right.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def insert_column(self, col_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with an empty column inserted at col_idx.\n    Subsequent columns are shifted right.\n    \"\"\"\n    new_headers = list(self.headers) if self.headers else None\n\n    if new_headers:\n        if col_idx &lt; 0:\n            col_idx = 0\n        if col_idx &gt; len(new_headers):\n            col_idx = len(new_headers)\n        new_headers.insert(col_idx, \"\")\n\n    new_alignments = None\n    if self.alignments is not None:\n        new_alignments = list(self.alignments)\n        # Pad if needed before insertion?\n        if col_idx &gt; len(new_alignments):\n            extension: list[AlignmentType] = [\"default\"] * (\n                col_idx - len(new_alignments)\n            )\n            new_alignments.extend(extension)\n        new_alignments.insert(col_idx, \"default\")  # Default alignment\n\n    new_rows = []\n    for row in self.rows:\n        new_row = list(row)\n        # Ensure row is long enough before insertion logic?\n        # Or just insert.\n        # If col_idx is way past end, we might need padding?\n        # Standard list.insert handles index &gt; len -&gt; append.\n        current_len = len(new_row)\n        target_idx = col_idx\n        if target_idx &gt; current_len:\n            # Pad up to target\n            new_row.extend([\"\"] * (target_idx - current_len))\n            target_idx = len(new_row)  # Append\n\n        new_row.insert(target_idx, \"\")\n        new_rows.append(new_row)\n\n    return replace(\n        self, headers=new_headers, rows=new_rows, alignments=new_alignments\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.insert_row","title":"<code>insert_row(row_idx)</code>","text":"<p>Return a new Table with an empty row inserted at row_idx. Subsequent rows are shifted down.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def insert_row(self, row_idx: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with an empty row inserted at row_idx.\n    Subsequent rows are shifted down.\n    \"\"\"\n    new_rows = [list(r) for r in self.rows]\n\n    # Determine width\n    width = (\n        len(self.headers) if self.headers else (len(new_rows[0]) if new_rows else 0)\n    )\n    if width == 0:\n        width = 1  # Default to 1 column if table is empty\n\n    new_row = [\"\"] * width\n\n    if row_idx &lt; 0:\n        row_idx = 0\n    if row_idx &gt; len(new_rows):\n        row_idx = len(new_rows)\n\n    new_rows.insert(row_idx, new_row)\n    return replace(self, rows=new_rows)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.move_column","title":"<code>move_column(from_index, to_index)</code>","text":"<p>Return a new Table with the column moved from from_index to to_index.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def move_column(self, from_index: int, to_index: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the column moved from from_index to to_index.\n    \"\"\"\n    # Determine width from headers or first row\n    width = (\n        len(self.headers)\n        if self.headers\n        else (len(self.rows[0]) if self.rows else 0)\n    )\n    if from_index &lt; 0 or from_index &gt;= width:\n        raise IndexError(\"from_index out of range\")\n    if to_index &lt; 0 or to_index &gt;= width:\n        raise IndexError(\"to_index out of range\")\n\n    # Move header\n    new_headers = None\n    if self.headers:\n        new_headers = list(self.headers)\n        header = new_headers.pop(from_index)\n        new_headers.insert(to_index, header)\n\n    # Move alignments\n    new_alignments = None\n    if self.alignments:\n        new_alignments = list(self.alignments)\n        if from_index &lt; len(new_alignments):\n            alignment = new_alignments.pop(from_index)\n            new_alignments.insert(to_index, alignment)\n\n    # Move data in each row\n    new_rows = []\n    for row in self.rows:\n        new_row = list(row)\n        if from_index &lt; len(new_row):\n            cell = new_row.pop(from_index)\n            new_row.insert(to_index, cell)\n        new_rows.append(new_row)\n\n    return replace(\n        self, headers=new_headers, rows=new_rows, alignments=new_alignments\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.move_row","title":"<code>move_row(from_index, to_index)</code>","text":"<p>Return a new Table with the row moved from from_index to to_index.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def move_row(self, from_index: int, to_index: int) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the row moved from from_index to to_index.\n    \"\"\"\n    if from_index &lt; 0 or from_index &gt;= len(self.rows):\n        raise IndexError(\"from_index out of range\")\n    if to_index &lt; 0 or to_index &gt;= len(self.rows):\n        raise IndexError(\"to_index out of range\")\n\n    new_rows = [list(r) for r in self.rows]\n    row = new_rows.pop(from_index)\n    new_rows.insert(to_index, row)\n    return replace(self, rows=new_rows)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.rename","title":"<code>rename(new_name)</code>","text":"<p>Return a new Table with the name changed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def rename(self, new_name: str) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the name changed.\n    \"\"\"\n    return replace(self, name=new_name)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.to_markdown","title":"<code>to_markdown(schema=DEFAULT_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the table.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def to_markdown(self, schema: ParsingSchema = DEFAULT_SCHEMA) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the table.\n\n    Args:\n        schema (ParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    return generate_table_markdown(self, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.to_models","title":"<code>to_models(schema_cls, conversion_schema=DEFAULT_CONVERSION_SCHEMA)</code>","text":"<p>Converts the table rows into a list of dataclass instances, performing validation and type conversion.</p> <p>Parameters:</p> Name Type Description Default <code>schema_cls</code> <code>type[T]</code> <p>The dataclass type to validate against.</p> required <code>conversion_schema</code> <code>ConversionSchema</code> <p>Configuration for type conversion.</p> <code>DEFAULT_CONVERSION_SCHEMA</code> <p>Returns:</p> Type Description <code>list[T]</code> <p>list[T]: A list of validated dataclass instances.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If schema_cls is not a dataclass.</p> <code>TableValidationError</code> <p>If validation fails for any row or if the table has no headers.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def to_models(\n    self,\n    schema_cls: type[T],\n    conversion_schema: ConversionSchema = DEFAULT_CONVERSION_SCHEMA,\n) -&gt; list[T]:\n    \"\"\"\n    Converts the table rows into a list of dataclass instances, performing validation and type conversion.\n\n    Args:\n        schema_cls (type[T]): The dataclass type to validate against.\n        conversion_schema (ConversionSchema, optional): Configuration for type conversion.\n\n    Returns:\n        list[T]: A list of validated dataclass instances.\n\n    Raises:\n        ValueError: If schema_cls is not a dataclass.\n        TableValidationError: If validation fails for any row or if the table has no headers.\n    \"\"\"\n    return validate_table(self, schema_cls, conversion_schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Table.update_cell","title":"<code>update_cell(row_idx, col_idx, value)</code>","text":"<p>Return a new Table with the specified cell updated.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def update_cell(self, row_idx: int, col_idx: int, value: str) -&gt; \"Table\":\n    \"\"\"\n    Return a new Table with the specified cell updated.\n    \"\"\"\n    # Handle header update\n    if row_idx == -1:\n        if self.headers is None:\n            # Determine width from rows if possible, or start fresh\n            width = len(self.rows[0]) if self.rows else (col_idx + 1)\n            new_headers = [\"\"] * width\n            # Ensure width enough\n            if col_idx &gt;= len(new_headers):\n                new_headers.extend([\"\"] * (col_idx - len(new_headers) + 1))\n        else:\n            new_headers = list(self.headers)\n            if col_idx &gt;= len(new_headers):\n                new_headers.extend([\"\"] * (col_idx - len(new_headers) + 1))\n\n        # Update alignments if headers grew\n        new_alignments = list(self.alignments) if self.alignments else []\n        if len(new_headers) &gt; len(new_alignments):\n            # Fill with default/None up to new width\n            # But we only need as many alignments as columns.\n            # If alignments is None, it stays None?\n            # Ideally if we start tracking alignments, we should init it?\n            # If self.alignments was None, we might keep it None unless explicitly set?\n            # Consistent behavior: If alignments is NOT None, expand it.\n            if self.alignments is not None:\n                # Cast or explicit type check might be needed for strict type checkers with literals\n                # Using a typed list to satisfy invariant list[AlignmentType]\n                extension: list[AlignmentType] = [\"default\"] * (\n                    len(new_headers) - len(new_alignments)\n                )\n                new_alignments.extend(extension)\n\n        final_alignments = new_alignments if self.alignments is not None else None\n\n        new_headers[col_idx] = value\n\n        return replace(self, headers=new_headers, alignments=final_alignments)\n\n    # Handle Body update\n    # 1. Ensure row exists\n    new_rows = [list(r) for r in self.rows]\n\n    # Grow rows if needed\n    if row_idx &gt;= len(new_rows):\n        # Calculate width\n        width = (\n            len(self.headers)\n            if self.headers\n            else (len(new_rows[0]) if new_rows else 0)\n        )\n        if width == 0:\n            width = col_idx + 1  # At least cover the new cell\n\n        rows_to_add = row_idx - len(new_rows) + 1\n        for _ in range(rows_to_add):\n            new_rows.append([\"\"] * width)\n\n    # If columns expanded due to row update, we might need to expand alignments too\n    current_width = len(new_rows[0]) if new_rows else 0\n    if col_idx &gt;= current_width:\n        # This means we are expanding columns\n        if self.alignments is not None:\n            width_needed = col_idx + 1\n            current_align_len = len(self.alignments)\n            if width_needed &gt; current_align_len:\n                new_alignments = list(self.alignments)\n                extension: list[AlignmentType] = [\"default\"] * (\n                    width_needed - current_align_len\n                )\n                new_alignments.extend(extension)\n                return replace(\n                    self,\n                    rows=self._update_rows_cell(new_rows, row_idx, col_idx, value),\n                    alignments=new_alignments,\n                )\n\n    return replace(\n        self, rows=self._update_rows_cell(new_rows, row_idx, col_idx, value)\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.TableJSON","title":"<code>TableJSON</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>JSON-compatible dictionary representation of a Table.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>class TableJSON(TypedDict):\n    \"\"\"\n    JSON-compatible dictionary representation of a Table.\n    \"\"\"\n\n    name: str | None\n    description: str | None\n    headers: list[str] | None\n    rows: list[list[str]]\n    metadata: dict[str, Any]\n    start_line: int | None\n    end_line: int | None\n    alignments: list[AlignmentType] | None\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Workbook","title":"<code>Workbook</code>  <code>dataclass</code>","text":"<p>Represents a collection of sheets (multi-table output).</p> <p>Attributes:</p> Name Type Description <code>sheets</code> <code>list[Sheet]</code> <p>List of sheets in the workbook.</p> <code>name</code> <code>str</code> <p>Name of the workbook (extracted from root marker). Defaults to \"Workbook\".</p> <code>start_line</code> <code>int | None</code> <p>0-indexed line number where workbook header starts. None if not detected.</p> <code>end_line</code> <code>int | None</code> <p>0-indexed line number where workbook section ends. None if not detected.</p> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Arbitrary metadata. Defaults to None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>@dataclass(frozen=True)\nclass Workbook:\n    \"\"\"\n    Represents a collection of sheets (multi-table output).\n\n    Attributes:\n        sheets (list[Sheet]): List of sheets in the workbook.\n        name (str): Name of the workbook (extracted from root marker). Defaults to \"Workbook\".\n        start_line (int | None): 0-indexed line number where workbook header starts. None if not detected.\n        end_line (int | None): 0-indexed line number where workbook section ends. None if not detected.\n        metadata (dict[str, Any] | None): Arbitrary metadata. Defaults to None.\n    \"\"\"\n\n    sheets: list[Sheet]\n    name: str = \"Workbook\"\n    start_line: int | None = None\n    end_line: int | None = None\n    metadata: dict[str, Any] | None = None\n    root_content: str | None = None\n\n    def __post_init__(self):\n        if self.metadata is None:\n            # Hack to allow default value for mutable type in frozen dataclass\n            object.__setattr__(self, \"metadata\", {})\n\n    @property\n    def json(self) -&gt; WorkbookJSON:\n        \"\"\"\n        Returns a JSON-compatible dictionary representation of the workbook.\n\n        Returns:\n            WorkbookJSON: A dictionary containing the workbook data.\n        \"\"\"\n        result: WorkbookJSON = {\n            \"name\": self.name,\n            \"sheets\": [s.json for s in self.sheets],\n            \"metadata\": self.metadata if self.metadata is not None else {},\n        }\n        if self.start_line is not None:\n            result[\"startLine\"] = self.start_line\n        if self.end_line is not None:\n            result[\"endLine\"] = self.end_line\n        if self.root_content is not None:\n            result[\"rootContent\"] = self.root_content  # type: ignore[typeddict-item]\n        return result\n\n    def get_sheet(self, name: str) -&gt; Sheet | None:\n        \"\"\"\n        Retrieve a sheet by its name.\n\n        Args:\n            name (str): The name of the sheet to retrieve.\n\n        Returns:\n            Sheet | None: The sheet object if found, otherwise None.\n        \"\"\"\n        for sheet in self.sheets:\n            if sheet.name == name:\n                return sheet\n        return None\n\n    def to_markdown(\n        self, schema: MultiTableParsingSchema = DEFAULT_MULTI_TABLE_SCHEMA\n    ) -&gt; str:\n        \"\"\"\n        Generates a Markdown string representation of the workbook.\n\n        Args:\n            schema (MultiTableParsingSchema, optional): Configuration for formatting.\n\n        Returns:\n            str: The Markdown string.\n        \"\"\"\n        return generate_workbook_markdown(self, schema)\n\n    def add_sheet(self, name: str) -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with a new sheet added.\n        \"\"\"\n        # Create new sheet with one empty table as default\n        new_table = Table(headers=[\"A\", \"B\", \"C\"], rows=[[\"\", \"\", \"\"]])\n        new_sheet = Sheet(name=name, tables=[new_table])\n\n        new_sheets = list(self.sheets)\n        new_sheets.append(new_sheet)\n\n        return replace(self, sheets=new_sheets)\n\n    def delete_sheet(self, index: int) -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with the sheet at index removed.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.sheets):\n            raise IndexError(\"Sheet index out of range\")\n\n        new_sheets = list(self.sheets)\n        new_sheets.pop(index)\n\n        return replace(self, sheets=new_sheets)\n\n    def move_sheet(self, from_index: int, to_index: int) -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with the sheet moved from from_index to to_index.\n        \"\"\"\n        if from_index &lt; 0 or from_index &gt;= len(self.sheets):\n            raise IndexError(\"from_index out of range\")\n        if to_index &lt; 0 or to_index &gt;= len(self.sheets):\n            raise IndexError(\"to_index out of range\")\n\n        new_sheets = list(self.sheets)\n        sheet = new_sheets.pop(from_index)\n        new_sheets.insert(to_index, sheet)\n\n        return replace(self, sheets=new_sheets)\n\n    def replace_sheet(self, index: int, sheet: \"Sheet\") -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with the sheet at index replaced.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.sheets):\n            raise IndexError(\"Sheet index out of range\")\n\n        new_sheets = list(self.sheets)\n        new_sheets[index] = sheet\n\n        return replace(self, sheets=new_sheets)\n\n    def rename_sheet(self, index: int, new_name: str) -&gt; \"Workbook\":\n        \"\"\"\n        Return a new Workbook with the sheet at index renamed.\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.sheets):\n            raise IndexError(\"Sheet index out of range\")\n\n        old_sheet = self.sheets[index]\n        new_sheet = replace(old_sheet, name=new_name)\n\n        new_sheets = list(self.sheets)\n        new_sheets[index] = new_sheet\n\n        return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Workbook.json","title":"<code>json</code>  <code>property</code>","text":"<p>Returns a JSON-compatible dictionary representation of the workbook.</p> <p>Returns:</p> Name Type Description <code>WorkbookJSON</code> <code>WorkbookJSON</code> <p>A dictionary containing the workbook data.</p>"},{"location":"api/#md_spreadsheet_parser.models.Workbook.add_sheet","title":"<code>add_sheet(name)</code>","text":"<p>Return a new Workbook with a new sheet added.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def add_sheet(self, name: str) -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with a new sheet added.\n    \"\"\"\n    # Create new sheet with one empty table as default\n    new_table = Table(headers=[\"A\", \"B\", \"C\"], rows=[[\"\", \"\", \"\"]])\n    new_sheet = Sheet(name=name, tables=[new_table])\n\n    new_sheets = list(self.sheets)\n    new_sheets.append(new_sheet)\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Workbook.delete_sheet","title":"<code>delete_sheet(index)</code>","text":"<p>Return a new Workbook with the sheet at index removed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def delete_sheet(self, index: int) -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with the sheet at index removed.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.sheets):\n        raise IndexError(\"Sheet index out of range\")\n\n    new_sheets = list(self.sheets)\n    new_sheets.pop(index)\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Workbook.get_sheet","title":"<code>get_sheet(name)</code>","text":"<p>Retrieve a sheet by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the sheet to retrieve.</p> required <p>Returns:</p> Type Description <code>Sheet | None</code> <p>Sheet | None: The sheet object if found, otherwise None.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def get_sheet(self, name: str) -&gt; Sheet | None:\n    \"\"\"\n    Retrieve a sheet by its name.\n\n    Args:\n        name (str): The name of the sheet to retrieve.\n\n    Returns:\n        Sheet | None: The sheet object if found, otherwise None.\n    \"\"\"\n    for sheet in self.sheets:\n        if sheet.name == name:\n            return sheet\n    return None\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Workbook.move_sheet","title":"<code>move_sheet(from_index, to_index)</code>","text":"<p>Return a new Workbook with the sheet moved from from_index to to_index.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def move_sheet(self, from_index: int, to_index: int) -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with the sheet moved from from_index to to_index.\n    \"\"\"\n    if from_index &lt; 0 or from_index &gt;= len(self.sheets):\n        raise IndexError(\"from_index out of range\")\n    if to_index &lt; 0 or to_index &gt;= len(self.sheets):\n        raise IndexError(\"to_index out of range\")\n\n    new_sheets = list(self.sheets)\n    sheet = new_sheets.pop(from_index)\n    new_sheets.insert(to_index, sheet)\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Workbook.rename_sheet","title":"<code>rename_sheet(index, new_name)</code>","text":"<p>Return a new Workbook with the sheet at index renamed.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def rename_sheet(self, index: int, new_name: str) -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with the sheet at index renamed.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.sheets):\n        raise IndexError(\"Sheet index out of range\")\n\n    old_sheet = self.sheets[index]\n    new_sheet = replace(old_sheet, name=new_name)\n\n    new_sheets = list(self.sheets)\n    new_sheets[index] = new_sheet\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Workbook.replace_sheet","title":"<code>replace_sheet(index, sheet)</code>","text":"<p>Return a new Workbook with the sheet at index replaced.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def replace_sheet(self, index: int, sheet: \"Sheet\") -&gt; \"Workbook\":\n    \"\"\"\n    Return a new Workbook with the sheet at index replaced.\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.sheets):\n        raise IndexError(\"Sheet index out of range\")\n\n    new_sheets = list(self.sheets)\n    new_sheets[index] = sheet\n\n    return replace(self, sheets=new_sheets)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.Workbook.to_markdown","title":"<code>to_markdown(schema=DEFAULT_MULTI_TABLE_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the workbook.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>MultiTableParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_MULTI_TABLE_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>def to_markdown(\n    self, schema: MultiTableParsingSchema = DEFAULT_MULTI_TABLE_SCHEMA\n) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the workbook.\n\n    Args:\n        schema (MultiTableParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    return generate_workbook_markdown(self, schema)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.models.WorkbookJSON","title":"<code>WorkbookJSON</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>JSON-compatible dictionary representation of a Workbook.</p> Source code in <code>src/md_spreadsheet_parser/models.py</code> <pre><code>class WorkbookJSON(TypedDict):\n    \"\"\"\n    JSON-compatible dictionary representation of a Workbook.\n    \"\"\"\n\n    name: str\n    sheets: list[SheetJSON]\n    metadata: dict[str, Any]\n    startLine: NotRequired[int | None]\n    endLine: NotRequired[int | None]\n    rootContent: NotRequired[str | None]\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.validation","title":"<code>md_spreadsheet_parser.validation</code>","text":""},{"location":"api/#md_spreadsheet_parser.validation.TableValidationError","title":"<code>TableValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when table validation fails. Contains a list of errors found during validation.</p> Source code in <code>src/md_spreadsheet_parser/validation.py</code> <pre><code>class TableValidationError(Exception):\n    \"\"\"\n    Exception raised when table validation fails.\n    Contains a list of errors found during validation.\n    \"\"\"\n\n    def __init__(self, errors: list[str]):\n        self.errors = errors\n        super().__init__(\n            f\"Validation failed with {len(errors)} errors:\\n\" + \"\\n\".join(errors)\n        )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.validation.validate_table","title":"<code>validate_table(table, schema_cls, conversion_schema=DEFAULT_CONVERSION_SCHEMA)</code>","text":"<p>Validates a Table object against a dataclass OR Pydantic schema.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>The Table object to validate.</p> required <code>schema_cls</code> <code>Type[T]</code> <p>The dataclass or Pydantic model type to validate against.</p> required <code>conversion_schema</code> <code>ConversionSchema</code> <p>Configuration for type conversion.</p> <code>DEFAULT_CONVERSION_SCHEMA</code> <p>Returns:</p> Type Description <code>list[T]</code> <p>list[T]: A list of validated instances.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If schema_cls is not a valid schema.</p> <code>TableValidationError</code> <p>If validation fails.</p> Source code in <code>src/md_spreadsheet_parser/validation.py</code> <pre><code>def validate_table(\n    table: \"Table\",\n    schema_cls: Type[T],\n    conversion_schema: ConversionSchema = DEFAULT_CONVERSION_SCHEMA,\n) -&gt; list[T]:\n    \"\"\"\n    Validates a Table object against a dataclass OR Pydantic schema.\n\n    Args:\n        table: The Table object to validate.\n        schema_cls: The dataclass or Pydantic model type to validate against.\n        conversion_schema: Configuration for type conversion.\n\n    Returns:\n        list[T]: A list of validated instances.\n\n    Raises:\n        ValueError: If schema_cls is not a valid schema.\n        TableValidationError: If validation fails.\n    \"\"\"\n    # Check for Pydantic Model\n    if HAS_PYDANTIC and BaseModel and issubclass(schema_cls, BaseModel):\n        if not table.headers:\n            raise TableValidationError([\"Table has no headers\"])\n        # Import adapter lazily to avoid unused imports when pydantic is not used\n        # (though we checked HAS_PYDANTIC so it exists)\n        from .pydantic_adapter import validate_table_pydantic\n\n        return validate_table_pydantic(table, schema_cls, conversion_schema)  # type: ignore\n\n    # Check for Dataclass\n    if is_dataclass(schema_cls):\n        if not table.headers:\n            raise TableValidationError([\"Table has no headers\"])\n        return _validate_table_dataclass(table, schema_cls, conversion_schema)\n\n    # Check for TypedDict\n    if is_typeddict(schema_cls):\n        if not table.headers:\n            raise TableValidationError([\"Table has no headers\"])\n        return _validate_table_typeddict(table, schema_cls, conversion_schema)\n\n    # Check for simple dict\n    # We compare schema_cls against dict type\n    if schema_cls is dict:\n        if not table.headers:\n            raise TableValidationError([\"Table has no headers\"])\n        return _validate_table_dict(table, conversion_schema)  # type: ignore\n\n    raise ValueError(\n        f\"{schema_cls} must be a dataclass, Pydantic model, TypedDict, or dict\"\n    )\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.generator","title":"<code>md_spreadsheet_parser.generator</code>","text":""},{"location":"api/#md_spreadsheet_parser.generator.generate_sheet_markdown","title":"<code>generate_sheet_markdown(sheet, schema=DEFAULT_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the sheet.</p> <p>For doc sheets (type=\"doc\"), outputs the content directly. For table sheets (type=\"table\"), outputs table markdown.</p> <p>Parameters:</p> Name Type Description Default <code>sheet</code> <code>Sheet</code> <p>The Sheet object.</p> required <code>schema</code> <code>ParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/generator.py</code> <pre><code>def generate_sheet_markdown(\n    sheet: \"Sheet\", schema: ParsingSchema = DEFAULT_SCHEMA\n) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the sheet.\n\n    For doc sheets (type=\"doc\"), outputs the content directly.\n    For table sheets (type=\"table\"), outputs table markdown.\n\n    Args:\n        sheet: The Sheet object.\n        schema (ParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    lines = []\n\n    if isinstance(schema, MultiTableParsingSchema):\n        sheet_level = schema.sheet_header_level or 2\n        lines.append(f\"{'#' * sheet_level} {sheet.name}\")\n        lines.append(\"\")\n\n    # For doc sheets, output content directly\n    if sheet.sheet_type == \"doc\" and sheet.content is not None:\n        lines.append(sheet.content)\n    else:\n        # Table sheet: output tables\n        for i, table in enumerate(sheet.tables):\n            lines.append(generate_table_markdown(table, schema))\n            if i &lt; len(sheet.tables) - 1:\n                lines.append(\"\")  # Empty line between tables\n\n    # Append Sheet Metadata if present (at the end)\n    if isinstance(schema, MultiTableParsingSchema) and sheet.metadata:\n        lines.append(\"\")\n        metadata_json = json.dumps(sheet.metadata, ensure_ascii=False)\n        comment = f\"&lt;!-- md-spreadsheet-sheet-metadata: {metadata_json} --&gt;\"\n        lines.append(comment)\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.generator.generate_table_markdown","title":"<code>generate_table_markdown(table, schema=DEFAULT_SCHEMA)</code>","text":"<p>Generates a Markdown string representation of the table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>The Table object.</p> required <code>schema</code> <code>ParsingSchema</code> <p>Configuration for formatting.</p> <code>DEFAULT_SCHEMA</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/generator.py</code> <pre><code>def generate_table_markdown(\n    table: \"Table\", schema: ParsingSchema = DEFAULT_SCHEMA\n) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the table.\n\n    Args:\n        table: The Table object.\n        schema (ParsingSchema, optional): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    lines = []\n\n    # Handle metadata (name and description) if MultiTableParsingSchema\n    if isinstance(schema, MultiTableParsingSchema):\n        table_level = schema.table_header_level\n        if table.name and table_level is not None:\n            lines.append(f\"{'#' * table_level} {table.name}\")\n            lines.append(\"\")  # Empty line after name\n\n        if table.description and schema.capture_description:\n            lines.append(table.description)\n            lines.append(\"\")  # Empty line after description\n\n    # Build table\n\n    sep = f\" {schema.column_separator or '|'} \"\n\n    def _prepare_cell(cell: str) -&gt; str:\n        \"\"\"Prepare cell for markdown generation.\"\"\"\n        if schema.convert_br_to_newline and \"\\n\" in cell:\n            return cell.replace(\"\\n\", \"&lt;br&gt;\")\n        return cell\n\n    # Headers\n    if table.headers:\n        # Add outer pipes if required\n        processed_headers = [_prepare_cell(h) for h in table.headers]\n        header_row = sep.join(processed_headers)\n        if schema.require_outer_pipes:\n            header_row = f\"{schema.column_separator or '|'} {header_row} {schema.column_separator or '|'}\"\n        lines.append(header_row)\n\n        # Separator row\n        separator_cells = []\n        separator_char = schema.header_separator_char or \"-\"\n        for i, _ in enumerate(table.headers):\n            alignment = \"default\"\n            if table.alignments and i &lt; len(table.alignments):\n                # Ensure we handle potentially None values if list has gaps (unlikely by design but safe)\n                alignment = table.alignments[i] or \"default\"\n\n            # Construct separator cell based on alignment\n            # Use 3 hyphens as base\n            if alignment == \"left\":\n                cell = \":\" + separator_char * 3\n            elif alignment == \"right\":\n                cell = separator_char * 3 + \":\"\n            elif alignment == \"center\":\n                cell = \":\" + separator_char * 3 + \":\"\n            else:\n                # default\n                cell = separator_char * 3\n\n            separator_cells.append(cell)\n\n        separator_row = sep.join(separator_cells)\n        if schema.require_outer_pipes:\n            separator_row = f\"{schema.column_separator or '|'} {separator_row} {schema.column_separator or '|'}\"\n        lines.append(separator_row)\n\n    # Rows\n    for row in table.rows:\n        processed_row = [_prepare_cell(cell) for cell in row]\n        row_str = sep.join(processed_row)\n        if schema.require_outer_pipes:\n            row_str = f\"{schema.column_separator or '|'} {row_str} {schema.column_separator or '|'}\"\n        lines.append(row_str)\n\n    # Append Metadata if present\n    if table.metadata and \"visual\" in table.metadata:\n        metadata_json = json.dumps(table.metadata[\"visual\"], ensure_ascii=False)\n        comment = f\"&lt;!-- md-spreadsheet-table-metadata: {metadata_json} --&gt;\"\n        lines.append(\"\")\n        lines.append(comment)\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/#md_spreadsheet_parser.generator.generate_workbook_markdown","title":"<code>generate_workbook_markdown(workbook, schema)</code>","text":"<p>Generates a Markdown string representation of the workbook.</p> <p>Parameters:</p> Name Type Description Default <code>workbook</code> <code>Workbook</code> <p>The Workbook object.</p> required <code>schema</code> <code>MultiTableParsingSchema</code> <p>Configuration for formatting.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Markdown string.</p> Source code in <code>src/md_spreadsheet_parser/generator.py</code> <pre><code>def generate_workbook_markdown(\n    workbook: \"Workbook\", schema: MultiTableParsingSchema\n) -&gt; str:\n    \"\"\"\n    Generates a Markdown string representation of the workbook.\n\n    Args:\n        workbook: The Workbook object.\n        schema (MultiTableParsingSchema): Configuration for formatting.\n\n    Returns:\n        str: The Markdown string.\n    \"\"\"\n    lines = []\n    metadata = workbook.metadata or {}\n    is_frontmatter = metadata.get(\"header_type\") == \"frontmatter\"\n\n    if is_frontmatter:\n        # Output YAML frontmatter block\n        frontmatter_data = metadata.get(\"frontmatter\", {})\n        if frontmatter_data:\n            lines.append(generate_yaml_frontmatter(frontmatter_data))\n            lines.append(\"\")\n    elif schema.root_marker:\n        lines.append(schema.root_marker)\n        lines.append(\"\")\n    else:\n        # Default: generate root marker from workbook name\n        root_marker_level = (\n            schema.sheet_header_level - 1 if schema.sheet_header_level else 1\n        )\n        lines.append(f\"{'#' * root_marker_level} {workbook.name}\")\n        lines.append(\"\")\n\n    if workbook.root_content:\n        lines.append(workbook.root_content)\n        lines.append(\"\")\n\n    for i, sheet in enumerate(workbook.sheets):\n        lines.append(generate_sheet_markdown(sheet, schema))\n        if i &lt; len(workbook.sheets) - 1:\n            lines.append(\"\")  # Empty line between sheets\n\n    # Append Workbook Metadata if present (excluding internal keys)\n    comment_metadata = {\n        k: v for k, v in metadata.items() if k not in _METADATA_INTERNAL_KEYS\n    }\n    if comment_metadata:\n        # Ensure separation from last sheet\n        if lines and lines[-1] != \"\":\n            lines.append(\"\")\n\n        metadata_json = json.dumps(comment_metadata, ensure_ascii=False)\n        comment = f\"&lt;!-- md-spreadsheet-workbook-metadata: {metadata_json} --&gt;\"\n        lines.append(comment)\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"changes/archive/0.3.1/add-ci-pipeline.feature/","title":"Add ci pipeline.feature","text":""},{"location":"changes/archive/0.3.1/add-ci-pipeline.feature/#cicd-implementation","title":"CI/CD Implementation","text":"<ul> <li>Added: GitHub Actions workflow (<code>.github/workflows/tests.yml</code>) to run unit tests (<code>pytest</code>) for <code>md-spreadsheet-parser</code> on push and pull request.</li> <li>Added: Build status badge to <code>md-spreadsheet-parser/README.md</code>.</li> </ul>"},{"location":"changes/archive/0.3.1/fix-ci-paths.fix/","title":"Fix ci paths.fix","text":""},{"location":"changes/archive/0.3.1/fix-ci-paths.fix/#fix-cicd-workflow","title":"Fix CI/CD Workflow","text":"<ul> <li>Fixed: Corrected <code>paths</code> and <code>working-directory</code> configuration in GitHub Actions workflow to run properly in the <code>md-spreadsheet-parser</code> repository root.</li> </ul>"},{"location":"changes/archive/0.3.2/quickstart.docs/","title":"Quickstart.docs","text":""},{"location":"changes/archive/0.3.2/quickstart.docs/#added-cookbook","title":"Added Cookbook","text":"<p>Added a new <code>COOKBOOK.md</code> file with recipes for common tasks: - Fast installation - Reading tables from files (one-liner) - Pandas integration (DataFrame &lt;-&gt; Markdown &lt;-&gt; Excel/TSV) - Programmatic Editing (Excel-like calculations) - Code Formatting &amp; Linting for tables - JSON Conversion - Simple Type-Safe Validation examples</p> <p>Also added a prominent link to the guide at the top of <code>README.md</code>.</p>"},{"location":"changes/archive/0.3.3/cookbook-docs.docs/","title":"Cookbook docs.docs","text":""},{"location":"changes/archive/0.3.3/cookbook-docs.docs/#added-cookbook-to-documentation","title":"Added Cookbook to Documentation","text":"<p>Integrated the new <code>COOKBOOK.md</code> into the MkDocs site navigation for better accessibility.</p>"},{"location":"changes/archive/0.3.3/pypi-links.fix/","title":"Pypi links.fix","text":""},{"location":"changes/archive/0.3.3/pypi-links.fix/#fixed-docs-links-for-pypi","title":"Fixed Docs Links for PyPI","text":"<p>Updated <code>README.md</code> to use absolute GitHub URLs for the Cookbook and License. This ensures links work correctly when viewed on the PyPI project page (which does not host the relative files).</p>"},{"location":"changes/archive/0.4.0/parser-fix-code-blocks.fix/","title":"Parser fix code blocks.fix","text":"<p>Fix bug where headers in markdown code blocks were incorrectly interpreted as document structure (e.g., <code># Tables</code> or <code>## Sheet 1</code> inside a code block). The parser now correctly ignores any headers inside fenced code blocks.</p>"},{"location":"changes/archive/0.4.1/pypi-description.docs/","title":"Pypi description.docs","text":"<p>Update PyPI package description to highlight zero-dependency parsing and Excel conversion features.</p>"},{"location":"changes/archive/0.4.2/pypi-keywords.docs/","title":"Pypi keywords.docs","text":"<p>Update PyPI package keywords to improve discoverability for Excel-related and zero-dependency use cases.</p>"},{"location":"changes/archive/0.4.3/readme_feedback.docs/","title":"Readme feedback.docs","text":"<p>Updated README.md to highlight suitability for AWS Lambda (Zero Dependency) and the \"Markdown as Database\" concept based on user feedback.</p>"},{"location":"changes/archive/0.4.3/sitemap-config.docs/","title":"Sitemap config.docs","text":"<p>Added <code>mkdocs-git-revision-date-localized-plugin</code> to generate accurate <code>lastmod</code> dates in <code>sitemap.xml</code> for better SEO and Google Search Console integration.</p>"},{"location":"changes/archive/0.5.0/gfm_alignment.feature/","title":"Gfm alignment.feature","text":"<p>Implemented support for GitHub Flavored Markdown (GFM) table alignment syntax (e.g. <code>| :--- | :---: | ---: |</code>). The <code>Table</code> model now has an <code>alignments</code> attribute, and the parser/generator preserves this information during round-trip operations.</p>"},{"location":"changes/archive/0.5.0/gfm_pipe_in_code.fix/","title":"Gfm pipe in code.fix","text":"<p>Implemented compliant GFM pipe handling. The parser now correctly treats pipes inside inline code blocks (e.g., <code>`|`</code>) as literal text rather than column separators. This involved replacing the internal regex-based row splitter with a new state-aware parsing logic.</p>"},{"location":"changes/archive/0.5.1/changelog_refactor.docs/","title":"Changelog refactor.docs","text":"<p>Refactored <code>CHANGELOG.md</code> to point to GitHub Releases and added the \"Changelog\" link to PyPI metadata in <code>pyproject.toml</code>.</p>"},{"location":"changes/archive/0.6.0/excel-parsing.feature/","title":"Excel parsing.feature","text":"<p>Add Excel parsing support with merged cell handling</p> <p>New functions: - <code>parse_excel()</code>: Parse Excel data from Worksheet, TSV/CSV string, or 2D array - <code>parse_excel_text()</code>: Core function for processing 2D string arrays</p> <p>Features: - Forward-fill for merged header cells - 2-row header flattening (\"Parent - Child\" format) - Auto-detect openpyxl.Worksheet if installed</p>"},{"location":"changes/archive/0.6.0/pyodide-precompilation.feature/","title":"Pyodide precompilation.feature","text":"<p>Added a script <code>scripts/build_pyc_wheel.py</code> to generate optimized wheels containing pre-compiled bytecode (<code>.pyc</code> only) for faster loading in Pyodide environments (specifically for the VS Code extension).</p>"},{"location":"changes/archive/0.7.0/excel-parsing-fixes.fix/","title":"Excel parsing fixes.fix","text":""},{"location":"changes/archive/0.7.0/excel-parsing-fixes.fix/#excel-parsing-improvements","title":"Excel Parsing Improvements","text":"<ul> <li>Fix: Improved hierarchical header flattening for vertically merged cells (e.g., prohibiting trailing separators like <code>Status -</code>).</li> <li>Enhancement: Cleaner string conversion for Excel numbers; integer-floats (e.g., <code>1.0</code>) are now automatically converted to valid integers (<code>\"1\"</code>) instead of preserving the decimal (<code>\"1.0\"</code>).</li> </ul>"},{"location":"changes/archive/0.7.0/workbook-metadata.feature/","title":"Workbook metadata.feature","text":""},{"location":"changes/archive/0.7.0/workbook-metadata.feature/#workbook-metadata-support","title":"Workbook Metadata Support","text":"<p>Added <code>metadata</code> field to the <code>Workbook</code> model, allowing arbitrary data storage at the workbook level. This aligns the <code>Workbook</code> model with <code>Sheet</code> and <code>Table</code> models.</p> <pre><code>wb = Workbook(sheets=[], metadata={\"author\": \"Alice\"})\n# Metadata is persisted at the end of the file:\n# &lt;!-- md-spreadsheet-workbook-metadata: {\"author\": \"Alice\"} --&gt;\n</code></pre>"},{"location":"changes/archive/0.7.1/metadata-location.fix/","title":"Metadata location.fix","text":""},{"location":"changes/archive/0.7.1/metadata-location.fix/#workbook-metadata-location","title":"Workbook Metadata Location","text":"<ul> <li>Fix: Relaxed the location requirement for Workbook metadata. It can now appear anywhere in the file (e.g., before additional documentation sections), not just at the strictly last non-empty line.</li> </ul>"},{"location":"changes/archive/0.7.2/github-actions-pypi.feature/","title":"Github actions pypi.feature","text":"<p>Add GitHub Actions workflows for PyPI and TestPyPI publishing.</p>"},{"location":"changes/archive/0.8.0/metadata-rename.breaking/","title":"Metadata rename.breaking","text":""},{"location":"changes/archive/0.8.0/metadata-rename.breaking/#metadata-tag-update-breaking","title":"Metadata Tag Update (Breaking)","text":"<ul> <li>BREAKING: Renamed <code>&lt;!-- md-spreadsheet-metadata: ... --&gt;</code> to <code>&lt;!-- md-spreadsheet-table-metadata: ... --&gt;</code> for consistency.</li> <li>Backward compatibility for the old tag has been dropped. Existing files with the old tag will still be parsed as tables, but the visual metadata (column widths, validation, etc.) will be ignored until manually updated.</li> </ul>"},{"location":"changes/archive/0.8.0/security-policy.docs/","title":"Security policy.docs","text":"<p>Added SECURITY.md with reporting instructions.</p>"},{"location":"changes/archive/0.8.1/i18n-support.feature/","title":"i18n support and Japanese documentation","text":"<p>Added Japanese translation for <code>README.md</code> and <code>COOKBOOK.md</code>. Configured <code>mkdocs-static-i18n</code> to support bilingual documentation (English/Japanese). Added language switcher with globe icon to the documentation site.</p>"},{"location":"changes/archive/0.8.1/root-marker-test.chore/","title":"Root marker test.chore","text":""},{"location":"changes/archive/0.8.1/root-marker-test.chore/#tests","title":"Tests","text":"<ul> <li>Added robustness test <code>test_root_marker_robustness.py</code> to verify behavior when <code># Tables</code> root marker is missing.</li> </ul>"},{"location":"changes/archive/1.0.0/peng-sheets-release.docs/","title":"Peng sheets release.docs","text":"<p>Documentation: Added announcement for the official VS Code Extension PengSheets release.</p>"},{"location":"changes/archive/1.0.0/readme-translation.docs/","title":"Readme translation.docs","text":"<p>Complete README.ja.md translation and update metadata tag example in README.md.</p>"},{"location":"changes/archive/1.0.0/remove-roadmap.docs/","title":"Remove roadmap.docs","text":"<p>Remove outdated roadmap and features section from READMEs.</p>"},{"location":"changes/archive/1.0.1/update-dev-status.chore/","title":"Update dev status.chore","text":"<p>Metadata: Updated PyPI Development Status to Production/Stable.</p>"},{"location":"changes/archive/1.1.0/fix-metadata-tag.fix/","title":"Fix table metadata tag recognition","text":"<p>Fixed a bug in <code>parsing.py</code> where the parser was incorrectly looking for <code>&lt;!-- md-spreadsheet-metadata: ... --&gt;</code> instead of <code>&lt;!-- md-spreadsheet-table-metadata: ... --&gt;</code> when extracting tables from blocks. This ensures consistency with the generator and specification.</p>"},{"location":"changes/archive/1.1.0/npm-package-support.feature/","title":"Npm package support.feature","text":""},{"location":"changes/archive/1.1.0/npm-package-support.feature/#npm-package-support-wasmpython-bridge","title":"NPM Package Support (WASM/Python Bridge)","text":"<p>Introduced comprehensive support for building an NPM package (<code>md-spreadsheet-parser</code>) powered by the Python core via WebAssembly (WASM).</p> <ul> <li>WASM Compilation: Uses <code>componentize-py</code> to compile the Python library into a WASM Component, enabling usage in Node.js environments.</li> <li>TypeScript Wrappers: Automatically generates high-fidelity TypeScript class wrappers that mirror the Python object model (API Parity).<ul> <li>Python <code>Table</code>, <code>Workbook</code>, <code>Sheet</code> classes are fully exposed in TypeScript.</li> <li>Methods like <code>toMarkdown</code>, <code>updateCell</code>, and <code>addSheet</code> are available directly on TypeScript objects.</li> </ul> </li> <li>Seamless Integration:<ul> <li>JSON Marshalling: Metadata dictionaries are automatically handled (serialized/deserialized) across the boundary.</li> <li>Optional Arguments: Python default arguments are correctly mapped to optional TypeScript parameters (e.g., <code>schema?</code>).</li> <li>Client-Side Mapping: <code>Table.toModels</code> supports passing browser-side schema classes or Zod-like validators.</li> </ul> </li> <li>Verification: Added a robust verification environment (<code>verification-env</code>) ensuring cross-language compatibility.</li> </ul>"},{"location":"changes/archive/1.1.0/update-dev-status.chore/","title":"Update dev status.chore","text":"<p>Metadata: Updated PyPI Development Status to Production/Stable.</p>"},{"location":"changes/archive/1.1.1/npm-trusted-publishing.chore/","title":"Npm trusted publishing.chore","text":"<p>Update NPM publishing workflow to use Trusted Publishing (OIDC) instead of secret tokens.</p>"},{"location":"changes/archive/1.1.10/nested-model-wrapper.fix/","title":"Nested model wrapper.fix","text":"<p>Fixed nested models in NPM package constructors to properly wrap child elements.</p> <ul> <li>Sheet constructor now wraps tables array items as Table instances</li> <li>Workbook constructor now wraps sheets array items as Sheet instances</li> <li>This ensures <code>json</code> getter recursively returns objects with proper metadata types</li> <li>Previously, nested metadata was returned as strings instead of objects</li> </ul>"},{"location":"changes/archive/1.1.11/fix-npm-metadata-hydration.fix/","title":"Fix npm metadata hydration.fix","text":"<p>Fixed <code>Object.assign(this, res)</code> usage in NPM package causing <code>metadata</code> to remain as a JSON string.</p> <p>The TypeScript wrapper generator (<code>scripts/generate_wit.py</code>) now produces proper hydration code that reconstructs objects via the constructor, ensuring: - <code>metadata</code> is parsed from JSON string to <code>Record&lt;string, any&gt;</code> (matching Python's <code>dict[str, any]</code>) - Nested models (e.g., <code>Sheet</code> within <code>Workbook</code>, <code>Table</code> within <code>Sheet</code>) are properly instantiated as class instances</p>"},{"location":"changes/archive/1.1.2/shim-dependency.fix/","title":"Shim dependency.fix","text":"<p>Move <code>@bytecodealliance/preview2-shim</code> to <code>dependencies</code> to ensure it is available at runtime. This fixes <code>ERR_MODULE_NOT_FOUND</code> when using the package in a fresh environment.</p>"},{"location":"changes/archive/1.1.3/npm-wrapper-fix.fix/","title":"Npm wrapper fix.fix","text":"<p>Fixed a critical bug in the NPM package where <code>Workbook.getSheet()</code> and <code>Sheet.getTable()</code> returned plain objects instead of class instances. Now verifies that proper <code>Sheet</code> and <code>Table</code> instances are returned, restoring API compatibility. Also fixed an issue where optional return types (like <code>optional&lt;Sheet&gt;</code>) were not correctly handled in the wrapper.</p>"},{"location":"changes/archive/1.1.4/wasi-file-access.fix/","title":"Fix WASI File Access","text":"<p>Fixed an issue where <code>parseWorkbookFromFile</code> failed with <code>FileNotFoundError</code> in the NPM package environment.</p> <ul> <li>Configured WASI preopens to map the system root (e.g., <code>/</code> on macOS, <code>C:\\</code> on Windows) to the Guest root.</li> <li>Implemented <code>resolveToVirtualPath</code> to automatically resolve relative paths against the Host's CWD and absolute paths against the system root.</li> <li><code>parseWorkbookFromFile</code> now correctly handles both relative and absolute paths in Node.js environments.</li> </ul>"},{"location":"changes/archive/1.1.5/npm-bundle-size.fix/","title":"Npm bundle size.fix","text":"<p>Reduced NPM package size by excluding redundant intermediate WASM files.</p>"},{"location":"changes/archive/1.1.6/workbook-optional-schema.fix/","title":"Workbook optional schema.fix","text":"<p>Fixed <code>Workbook.to_markdown()</code> to accept an optional <code>schema</code> argument, defaulting to a standard <code>MultiTableParsingSchema</code>. This aligns the API with <code>Sheet.to_markdown()</code> and <code>Table.to_markdown()</code>.</p>"},{"location":"changes/archive/1.1.7/browser-compatibility.feature/","title":"Browser compatibility.feature","text":"<p>NPM package now builds and works correctly in browser environments (Vite, Webpack, etc.).</p> <ul> <li>Core APIs (<code>parseTable</code>, <code>parseWorkbook</code>, <code>scanTables</code>, etc.) work seamlessly in both Node.js and browser environments</li> <li>File-based APIs (<code>parseTableFromFile</code>, <code>parseWorkbookFromFile</code>, <code>scanTablesFromFile</code>) are now async functions that:</li> <li>Work correctly in Node.js with lazy WASI filesystem initialization</li> <li>Throw a clear error message in browser environments with guidance to use string-based alternatives</li> <li>Fixed <code>_addPreopen is not exported</code> error when using Vite or other browser bundlers</li> </ul>"},{"location":"changes/archive/1.1.8/wasm-fetch-path-fix.fix/","title":"Wasm fetch path fix.fix","text":"<p>Fixed WASM loading in Vite dev mode by using <code>import.meta.url</code> for proper path resolution.</p> <ul> <li>Modified build script to post-process JCO transpile output</li> <li>Replaced relative path <code>fetch('./parser.core.wasm')</code> with <code>fetch(new URL('./parser.core.wasm', import.meta.url))</code></li> <li>This ensures WASM files are correctly resolved in both bundled and development environments</li> </ul>"},{"location":"changes/archive/1.1.9/json-getter.feature/","title":"Json getter.feature","text":"<p>Added <code>json</code> getter to Table, Sheet, and Workbook classes in the NPM package.</p> <ul> <li>The <code>json</code> getter mirrors Python's <code>.json</code> property</li> <li>Returns a JSON-compatible plain object representation</li> <li>Recursively converts nested models (e.g., Sheet.json includes all tables.json)</li> </ul>"},{"location":"changes/archive/1.2.0/model-operations.feature/","title":"Model operations.feature","text":"<p>Added consistent CRUD operation methods to Workbook, Sheet, and Table models:</p> <p>Workbook: - <code>move_sheet(from_index, to_index)</code> - reorder sheets - <code>replace_sheet(index, sheet)</code> - replace sheet at index - <code>rename_sheet(index, new_name)</code> - rename sheet at index</p> <p>Sheet: - <code>rename(new_name)</code> - rename the sheet - <code>add_table(name?)</code> - append a new empty table - <code>delete_table(index)</code> - remove table at index - <code>replace_table(index, table)</code> - replace table at index - <code>move_table(from_index, to_index)</code> - reorder tables</p> <p>Table: - <code>rename(new_name)</code> - rename the table - <code>move_row(from_index, to_index)</code> - reorder rows - <code>move_column(from_index, to_index)</code> - reorder columns</p>"},{"location":"changes/archive/1.2.0/npm-e2e-tests.feature/","title":"Npm e2e tests.feature","text":"<p>Added comprehensive E2E tests for NPM package (118 test cases) covering parseTable, parseWorkbook, scanTables, Table/Sheet/Workbook methods, deep metadata type verification, toModels with Plain Object and Zod schemas, and mutation API return values. Also improved .gitignore documentation, fixed verify_api_coverage.py, and added Limitations section to README documenting parseExcel unavailability.</p>"},{"location":"changes/archive/1.2.0/npm-test-restructuring.feature/","title":"Npm test restructuring.feature","text":""},{"location":"changes/archive/1.2.0/npm-test-restructuring.feature/#npm-package-e2e-test-restructuring-and-coverage-expansion","title":"NPM Package E2E Test Restructuring and Coverage Expansion","text":"<p>Comprehensive improvements to the NPM package testing infrastructure:</p>"},{"location":"changes/archive/1.2.0/npm-test-restructuring.feature/#test-restructuring","title":"Test Restructuring","text":"<ul> <li>Migrated from monolithic <code>scripts/test.mjs</code> to modular <code>tests/</code> directory</li> <li>Split tests into dedicated files: <code>parsing.test.mjs</code>, <code>table.test.mjs</code>, <code>sheet.test.mjs</code>, <code>workbook.test.mjs</code>, <code>tomodels.test.mjs</code></li> <li>Added shared <code>helpers.mjs</code> with assertion utilities and <code>runner.mjs</code> test orchestrator</li> </ul>"},{"location":"changes/archive/1.2.0/npm-test-restructuring.feature/#api-improvements","title":"API Improvements","text":"<ul> <li><code>replaceTable</code> and <code>replaceSheet</code> now auto-convert model instances to DTO (no explicit <code>.toDTO()</code> required)</li> <li>Full API parity with Python: users can pass <code>Table</code>/<code>Sheet</code> instances directly</li> </ul>"},{"location":"changes/archive/1.2.0/npm-test-restructuring.feature/#test-coverage-expansion-204-235-assertions","title":"Test Coverage Expansion (204 \u2192 235 assertions)","text":"<ul> <li>Added tests for: <code>deleteRow</code>, <code>deleteColumn</code>, <code>insertRow</code>, <code>insertColumn</code>, <code>clearColumnData</code></li> <li>Added <code>Sheet.getTable</code> tests</li> <li>Added <code>parseTableFromFile</code>, <code>parseWorkbookFromFile</code>, <code>scanTablesFromFile</code> function verification</li> </ul>"},{"location":"changes/archive/1.2.0/npm-test-restructuring.feature/#documentation","title":"Documentation","text":"<ul> <li>Created <code>DEVELOPMENT.md</code> documenting the Python-to-NPM workflow</li> </ul>"},{"location":"changes/archive/1.2.1/unicode-json.fix/","title":"Unicode json.fix","text":"<p>Ensure JSON output for CLI and metadata uses Unicode characters instead of escape sequences (e.g. Japanese).</p>"},{"location":"changes/archive/1.2.2/readme-updates.docs/","title":"Readme updates.docs","text":"<ul> <li>Core: Added PengSheets announcement to <code>README.md</code> and <code>README.ja.md</code>.</li> <li>Core: Fixed invalid <code>update_table_metadata</code> example in <code>README.md</code>.</li> <li>NPM: Added <code>packages/npm/README.ja.md</code> (Japanese translation).</li> <li>NPM: Updated logic parity claims and Excel limitations text.</li> </ul>"},{"location":"changes/archive/1.3.0/1.feature/","title":"1.feature","text":"<p>Add flexible workbook detection and doc sheet support.</p> <p>Workbook Auto-Detection (<code>root_marker=None</code>): - Single H1 header is auto-detected as workbook root - H1 containing <code>&lt;!-- md-spreadsheet- ... --&gt;</code> metadata comment is detected - Fallback search for <code># Tables</code> or <code># Workbook</code> - Sheet/table header levels auto-calculated from workbook level</p> <p>New Sheet Fields: - <code>Sheet.type</code>: <code>\"table\"</code> or <code>\"doc\"</code> - <code>Sheet.content</code>: Raw markdown for doc sheets</p> <p>New Workbook Fields: - <code>Workbook.name</code>: Extracted from detected root marker - <code>Workbook.root_content</code>: Captures content between workbook header and first sheet header</p> <p>Backward Compatibility: - Explicit <code>root_marker</code> preserves existing behavior - <code>table_header_level=None</code> with explicit root still means \"no table headers\"</p>"},{"location":"changes/archive/1.4.0/5.feature/","title":"5.feature","text":"<p>Supports YAML Frontmatter block parsing and Multi-H1 routing. Additionally, introduces GFM Task List items (<code>[ ]</code> / <code>[x]</code>) to boolean conversion mapping in <code>ConversionSchema</code>.</p>"},{"location":"changes/archive/1.4.1/8.fix/","title":"8.fix","text":"<p>YAML frontmatter is now preserved during round-trip (parse \u2192 generate \u2192 re-parse). Frontmatter data is stored in <code>metadata[\"frontmatter\"]</code> sub-dict with <code>metadata[\"header_type\"]</code> set to <code>\"frontmatter\"</code>, enabling accurate regeneration of the original format.</p>"},{"location":"changes/archive/1.4.2/5.fix/","title":"5.fix","text":"<p>When YAML frontmatter has a <code>title</code> AND actual H1 headers exist in the document, the frontmatter is now treated as a Document section instead of the workbook root. The H1 header is used for workbook auto-detection as usual. Previously, frontmatter <code>title</code> unconditionally preempted H1 auto-detection, causing 0 sheets to be parsed when both coexisted.</p>"},{"location":"ja/","title":"Markdown Spreadsheet Parser","text":"<p> Markdown\u30c6\u30fc\u30d6\u30eb\u64cd\u4f5c\u306b\u7279\u5316\u3057\u305fPython\u30e9\u30a4\u30d6\u30e9\u30ea\u3002Excel\u304b\u3089Markdown\u3078\u306e\u5909\u63db\u3001\u30c6\u30fc\u30d6\u30eb\u306e\u89e3\u6790\u3001\u578b\u5b89\u5168\u306a\u691c\u8a3c\u306a\u3069\u3002\u5805\u7262\u3067\u4f9d\u5b58\u95a2\u4fc2\u30bc\u30ed </p> <p>md-spreadsheet-parser \u306f\u3001Markdown\u306e\u30c6\u30fc\u30d6\u30eb\u3092\u5358\u306a\u308b\u30c6\u30ad\u30b9\u30c8\u304b\u3089\u30d5\u30a1\u30fc\u30b9\u30c8\u30af\u30e9\u30b9\u306e\u30c7\u30fc\u30bf\u69cb\u9020\u3078\u3068\u6607\u83ef\u3055\u305b\u307e\u3059\u3002\u30b9\u30d7\u30ec\u30c3\u30c9\u30b7\u30fc\u30c8\u306e\u624b\u8efd\u3055\u3068Python\u306e\u5f37\u529b\u3055\u3092\u517c\u306d\u5099\u3048\u3001\u6b63\u78ba\u304b\u3064\u4f9d\u5b58\u95a2\u4fc2\u30bc\u30ed\u306e\u30a8\u30f3\u30b8\u30f3\u3067\u30c6\u30fc\u30d6\u30eb\u306e\u89e3\u6790\u3001\u691c\u8a3c\u3001\u64cd\u4f5c\u3092\u5b9f\u73fe\u3057\u307e\u3059\u3002</p> <p>\ud83c\udf89 \u516c\u5f0fGUI\u30a8\u30c7\u30a3\u30bf\u304c\u767b\u5834: PengSheets</p> <p>\u3053\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30d1\u30ef\u30fc\u3092\u305d\u306e\u307e\u307e\u306b\u3001VS Code\u4e0a\u3067Excel\u30e9\u30a4\u30af\u306a\u64cd\u4f5c\u611f\u3092\u5b9f\u73fe\u3057\u307e\u3057\u305f\u3002\u30bd\u30fc\u30c8\u3001\u30d5\u30a3\u30eb\u30bf\u3001\u5feb\u9069\u306a\u30ca\u30d3\u30b2\u30fc\u30b7\u30e7\u30f3\u306a\u3069\u3092GUI\u3067\u76f4\u611f\u7684\u306b\u6271\u3048\u307e\u3059\u3002</p> <p></p> <p>\ud83d\ude80 \u3059\u3050\u306b\u4f7f\u3044\u305f\u3044\u3067\u3059\u304b\uff1f Cookbook \u306b\u306f\u3001\u30b3\u30d4\u30fc\uff06\u30da\u30fc\u30b9\u30c8\u3067\u4f7f\u3048\u308b\u30ec\u30b7\u30d4\uff08Excel\u5909\u63db\u3001Pandas\u9023\u643a\u3001Markdown\u30c6\u30fc\u30d6\u30eb\u64cd\u4f5c\u306a\u3069\uff09\u304c\u6e80\u8f09\u3067\u3059\u3002</p>"},{"location":"ja/#_1","title":"\u76ee\u6b21","text":"<ul> <li>\u6a5f\u80fd</li> <li>\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb</li> <li>\u4f7f\u3044\u65b9<ul> <li>1. \u57fa\u672c\u7684\u306a\u89e3\u6790</li> <li>YAML\u30d5\u30ed\u30f3\u30c8\u30de\u30bf\u30fc\u3068\u30e1\u30bf\u30c7\u30fc\u30bf</li> <li>GFM\u6a5f\u80fd\u306e\u30b5\u30dd\u30fc\u30c8</li> <li>2. \u578b\u5b89\u5168\u306a\u691c\u8a3c<ul> <li>Pydantic\u9023\u643a</li> </ul> </li> <li>3. JSON\u3068\u8f9e\u66f8\u3078\u306e\u5909\u63db</li> <li>4. Pandas\u9023\u643a\u3068\u30a8\u30af\u30b9\u30dd\u30fc\u30c8</li> <li>5. Excel\u30a4\u30f3\u30dd\u30fc\u30c8</li> <li>6. Markdown\u751f\u6210</li> <li>7. \u9ad8\u5ea6\u306a\u6a5f\u80fd</li> <li>8. \u9ad8\u5ea6\u306a\u578b\u5909\u63db</li> <li>9. \u5805\u7262\u6027</li> <li>10. \u30bb\u30eb\u5185\u6539\u884c\u306e\u30b5\u30dd\u30fc\u30c8</li> <li>11. \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3</li> <li>12. \u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u3088\u308b\u64cd\u4f5c</li> <li>13. \u30d3\u30b8\u30e5\u30a2\u30eb\u30e1\u30bf\u30c7\u30fc\u30bf\u306e\u6c38\u7d9a\u5316</li> <li>\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9 (CLI)</li> </ul> </li> <li>\u8a2d\u5b9a</li> <li>\u30a8\u30b3\u30b7\u30b9\u30c6\u30e0</li> <li>\u30e9\u30a4\u30bb\u30f3\u30b9</li> </ul>"},{"location":"ja/#_2","title":"\u6a5f\u80fd","text":"<ul> <li>\u7d14\u7c8b\u306aPython\u3068\u4f9d\u5b58\u95a2\u4fc2\u30bc\u30ed: \u8efd\u91cf\u3067\u30dd\u30fc\u30bf\u30d6\u30eb\u3067\u3059\u3002AWS Lambda Layers \u3084\u5236\u7d04\u306e\u3042\u308b\u74b0\u5883\u306b\u6700\u9069\u3067\u3059\u3002WebAssembly (Pyodide) \u3092\u542b\u3080\u3001Python\u304c\u52d5\u4f5c\u3059\u308b\u5834\u6240\u306a\u3089\u3069\u3053\u3067\u3082\u52d5\u4f5c\u3057\u307e\u3059\u3002</li> <li>\u578b\u5b89\u5168\u306a\u691c\u8a3c: \u30eb\u30fc\u30ba\u306aMarkdown\u30c6\u30fc\u30d6\u30eb\u3092\u3001\u81ea\u52d5\u578b\u5909\u63db\u3092\u542b\u3080\u5f37\u529b\u306b\u578b\u4ed8\u3051\u3055\u308c\u305fPython\u306e <code>dataclasses</code> \u306b\u5909\u63db\u3057\u307e\u3059\u3002\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u53ef\u80fd\u306a\u30d6\u30fc\u30eb\u5024\u30ed\u30b8\u30c3\u30af (I18N) \u3084\u30ab\u30b9\u30bf\u30e0\u578b\u30b3\u30f3\u30d0\u30fc\u30bf\u3082\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059\u3002</li> <li>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3068\u3057\u3066\u306eMarkdown: Markdown\u30d5\u30a1\u30a4\u30eb\u3092Git\u7ba1\u7406\u3055\u308c\u305f\u8a2d\u5b9a\u3084\u30de\u30b9\u30bf\u30fc\u30c7\u30fc\u30bf\u3068\u3057\u3066\u6271\u3048\u307e\u3059\u3002\u30b9\u30ad\u30fc\u30de\u3068\u578b\u3092\u81ea\u52d5\u7684\u306b\u691c\u8a3c\u3057\u3001\u624b\u66f8\u304d\u30c6\u30fc\u30d6\u30eb\u306e\u4eba\u70ba\u7684\u30df\u30b9\u3092\u9632\u304e\u307e\u3059\u3002</li> <li>\u30e9\u30a6\u30f3\u30c9\u30c8\u30ea\u30c3\u30d7\u30b5\u30dd\u30fc\u30c8: \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3078\u306e\u89e3\u6790\u3001\u30c7\u30fc\u30bf\u306e\u5909\u66f4\u3001Markdown\u3078\u306e\u518d\u751f\u6210\u304c\u53ef\u80fd\u3067\u3059\u3002\u30a8\u30c7\u30a3\u30bf\u306e\u5b9f\u88c5\u306b\u6700\u9069\u3067\u3059\u3002</li> <li>GFM\u6e96\u62e0: \u5217\u306e\u914d\u7f6e (<code>:--</code>, <code>:--:</code>, <code>--:</code>) \u3084\u30a4\u30f3\u30e9\u30a4\u30f3\u30b3\u30fc\u30c9\u5185\u306e\u30d1\u30a4\u30d7 (<code>`|`</code>) \u306e\u6b63\u3057\u3044\u51e6\u7406\u306a\u3069\u3001GitHub Flavored Markdown (GFM) \u4ed5\u69d8\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</li> <li>\u5805\u7262\u306a\u89e3\u6790: \u4e0d\u6b63\u306a\u30c6\u30fc\u30d6\u30eb\uff08\u5217\u306e\u6b20\u843d\u3084\u904e\u5270\uff09\u3084\u30a8\u30b9\u30b1\u30fc\u30d7\u6587\u5b57\u3092\u9069\u5207\u306b\u51e6\u7406\u3057\u307e\u3059\u3002</li> <li>\u30de\u30eb\u30c1\u30c6\u30fc\u30d6\u30eb\u30fb\u30ef\u30fc\u30af\u30d6\u30c3\u30af: \u5358\u4e00\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u306e\u8907\u6570\u306e\u30b7\u30fc\u30c8\u3084\u30c6\u30fc\u30d6\u30eb\u306e\u89e3\u6790\u3001\u304a\u3088\u3073\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059\u3002</li> <li>JSON\u3068Dict\u306e\u30b5\u30dd\u30fc\u30c8: \u5217\u30ec\u30d9\u30eb\u306eJSON\u89e3\u6790\u3068\u3001<code>dict</code>/<code>TypedDict</code> \u3078\u306e\u76f4\u63a5\u5909\u63db\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059\u3002</li> <li>Pandas\u9023\u643a: Markdown\u30c6\u30fc\u30d6\u30eb\u304b\u3089DataFrame\u3092\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u4f5c\u6210\u3067\u304d\u307e\u3059\u3002</li> <li>Excel\u30a4\u30f3\u30dd\u30fc\u30c8\u3068\u30c7\u30fc\u30bf\u30af\u30ea\u30fc\u30cb\u30f3\u30b0: Excel/TSV/CSV\u3092Markdown\u306b\u5909\u63db\u3057\u3001\u7d50\u5408\u30bb\u30eb\u3092\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306b\u51e6\u7406\u3057\u307e\u3059\u3002\u968e\u5c64\u30d8\u30c3\u30c0\u30fc\u306e\u30d5\u30e9\u30c3\u30c8\u5316\u3084\u30ae\u30e3\u30c3\u30d7\u306e\u57cb\u3081\u5408\u308f\u305b\u3092\u81ea\u52d5\u7684\u306b\u884c\u3044\u3001\u300c\u6c5a\u3044\u300d\u30b9\u30d7\u30ec\u30c3\u30c9\u30b7\u30fc\u30c8\u3092\u304d\u308c\u3044\u306a\u69cb\u9020\u5316\u30c7\u30fc\u30bf\u306b\u5909\u63db\u3057\u307e\u3059\u3002</li> <li>JSON\u30d5\u30ec\u30f3\u30c9\u30ea\u30fc: \u8f9e\u66f8/JSON\u3078\u306e\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u304c\u5bb9\u6613\u3067\u3001\u4ed6\u306e\u30c4\u30fc\u30eb\u3068\u306e\u9023\u643a\u3082\u7c21\u5358\u3067\u3059\u3002</li> </ul>"},{"location":"ja/#_3","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code>pip install md-spreadsheet-parser\n</code></pre>"},{"location":"ja/#_4","title":"\u4f7f\u3044\u65b9","text":""},{"location":"ja/#1","title":"1. \u57fa\u672c\u7684\u306a\u89e3\u6790","text":"<p>\u5358\u4e00\u306e\u30c6\u30fc\u30d6\u30eb \u6a19\u6e96\u7684\u306aMarkdown\u30c6\u30fc\u30d6\u30eb\u3092\u69cb\u9020\u5316\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u89e3\u6790\u3057\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| Name | Age |\n| --- | --- |\n| Alice | 30 |\n| Bob | 25 |\n\"\"\"\n\nresult = parse_table(markdown)\n\nprint(result.headers)\n# ['Name', 'Age']\n\nprint(result.rows)\n# [['Alice', '30'], ['Bob', '25']]\n</code></pre> <p>\u8907\u6570\u306e\u30c6\u30fc\u30d6\u30eb (\u30ef\u30fc\u30af\u30d6\u30c3\u30af) \u8907\u6570\u306e\u30b7\u30fc\u30c8\uff08\u30bb\u30af\u30b7\u30e7\u30f3\uff09\u3092\u542b\u3080\u30d5\u30a1\u30a4\u30eb\u3092\u89e3\u6790\u3057\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u3001\u5358\u4e00\u306eH1\u30d8\u30c3\u30c0\u30fc (<code># Workbook</code>) \u306a\u3069\u3092\u30eb\u30fc\u30c8\u3068\u3057\u3066\u81ea\u52d5\u691c\u51fa\u3057\u3001\u30b7\u30fc\u30c8\u306e\u30d8\u30c3\u30c0\u30fc\u30ec\u30d9\u30eb\u3092\u81ea\u52d5\u8a08\u7b97\u3057\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import parse_workbook, MultiTableParsingSchema\n\nmarkdown = \"\"\"\n# Workbook\n\n## Users\n| ID | Name |\n| -- | ---- |\n| 1  | Alice|\n\n## Products\n| ID | Item |\n| -- | ---- |\n| A  | Apple|\n\"\"\"\n\n# \u30c7\u30d5\u30a9\u30eb\u30c8\u30b9\u30ad\u30fc\u30de\u3092\u4f7f\u7528\nschema = MultiTableParsingSchema()\nworkbook = parse_workbook(markdown, schema)\n\nfor sheet in workbook.sheets:\n    print(f\"Sheet: {sheet.name}\")\n    for table in sheet.tables:\n        print(table.rows)\n</code></pre> <p>\u30eb\u30c3\u30af\u30a2\u30c3\u30d7API\u3068\u30e1\u30bf\u30c7\u30fc\u30bf \u30b7\u30fc\u30c8\u3084\u30c6\u30fc\u30d6\u30eb\u3092\u540d\u524d\u3067\u76f4\u63a5\u53d6\u5f97\u3057\u3001\u8aac\u660e\u306a\u3069\u306e\u89e3\u6790\u3055\u308c\u305f\u30e1\u30bf\u30c7\u30fc\u30bf\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import parse_workbook\n\nmarkdown = \"\"\"\n# Workbook\n\n## Sales Data\n\n### Q1 Results\nFinancial performance for the first quarter.\n\n| Year | Revenue |\n| ---- | ------- |\n| 2023 | 1000    |\n\"\"\"\n\nworkbook = parse_workbook(markdown)\n\n# \u540d\u524d\u3067\u30a2\u30af\u30bb\u30b9\nsheet = workbook.get_sheet(\"Sales Data\")\nif sheet:\n    # \u540d\u524d\u3067\u30c6\u30fc\u30d6\u30eb\u3092\u53d6\u5f97 (### Header \u304b\u3089)\n    table = sheet.get_table(\"Q1 Results\")\n\n    print(table.description)\n    # \"Financial performance for the first quarter.\"\n\n    print(table.rows)\n    # [['2023', '1000']]\n</code></pre> <p>\u30b7\u30f3\u30d7\u30eb\u306a\u30b9\u30ad\u30e3\u30f3\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9 \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u69cb\u9020\uff08\u30b7\u30fc\u30c8\u3084\u30d8\u30c3\u30c0\u30fc\uff09\u3092\u7121\u8996\u3057\u3066\u3001\u30d5\u30a1\u30a4\u30eb\u5185\u306e \u3059\u3079\u3066\u306e \u30c6\u30fc\u30d6\u30eb\u3092\u62bd\u51fa\u3057\u305f\u3044\u5834\u5408\u306f\u3001<code>scan_tables</code> \u3092\u4f7f\u7528\u3057\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import scan_tables\n\nmarkdown = \"\"\"\n| ID | Name |\n| -- | ---- |\n| 1  | Alice|\n\n... text ...\n\n| ID | Item |\n| -- | ---- |\n| A  | Apple|\n\"\"\"\n\n# \u898b\u3064\u304b\u3063\u305f\u3059\u3079\u3066\u306e\u30c6\u30fc\u30d6\u30eb\u306e\u30d5\u30e9\u30c3\u30c8\u30ea\u30b9\u30c8\u3092\u8fd4\u3059\ntables = scan_tables(markdown)\nprint(len(tables)) # 2\n</code></pre> <p>\u30d5\u30a1\u30a4\u30eb\u8aad\u307f\u8fbc\u307f\u30d8\u30eb\u30d1\u30fc</p> <p>\u5229\u4fbf\u6027\u306e\u305f\u3081\u3001<code>_from_file</code> \u30d0\u30ea\u30a2\u30f3\u30c8\u3092\u4f7f\u7528\u3057\u3066\u3001\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9 (<code>str</code> \u307e\u305f\u306f <code>Path</code>) \u3084\u30d5\u30a1\u30a4\u30eb\u30e9\u30a4\u30af\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304b\u3089\u76f4\u63a5\u89e3\u6790\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>from md_spreadsheet_parser import parse_workbook_from_file\n\n# \u7c21\u5358\u3067\u30af\u30ea\u30fc\u30f3\nworkbook = parse_workbook_from_file(\"data.md\")\n</code></pre> <p>\u5229\u7528\u53ef\u80fd\u306a\u30d8\u30eb\u30d1\u30fc: - <code>parse_table_from_file(path_or_file)</code> - <code>parse_workbook_from_file(path_or_file)</code> - <code>scan_tables_from_file(path_or_file)</code></p>"},{"location":"ja/#yaml","title":"YAML\u30d5\u30ed\u30f3\u30c8\u30de\u30bf\u30fc\u3068\u30e1\u30bf\u30c7\u30fc\u30bf","text":"<p>\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u5148\u982d\u304b\u3089YAML\u30d5\u30ed\u30f3\u30c8\u30de\u30bf\u30fc\u3092\u62bd\u51fa\u3059\u308b\u3053\u3068\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002 \u30d5\u30ed\u30f3\u30c8\u30de\u30bf\u30fc\u306b <code>title</code> \u30d7\u30ed\u30d1\u30c6\u30a3\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u5834\u5408\u3001\u81ea\u52d5\u7684\u306b\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u30d7\u30e9\u30a4\u30de\u30eaH1\u30d8\u30c3\u30c0\u30fc (<code>Workbook.name</code>) \u3068\u3057\u3066\u6271\u308f\u308c\u3001\u305d\u306e\u30ad\u30fc\u306f <code>Workbook.metadata</code> \u306b\u4fdd\u5b58\u3055\u308c\u307e\u3059\u3002<code>title</code> \u3092\u542b\u307e\u306a\u3044\u30d5\u30ed\u30f3\u30c8\u30de\u30bf\u30fc\u306f\u7121\u8996\u3055\u308c\u3001\u30ef\u30fc\u30af\u30d6\u30c3\u30af\u3068\u306f\u898b\u306a\u3055\u308c\u307e\u305b\u3093\u3002</p> <pre><code>markdown = \"\"\"---\ntitle: My Project\nauthor: Alice\n---\n## Sheet 1\n| A |\n|---|\n| 1 |\n\"\"\"\nworkbook = parse_workbook(markdown)\nprint(workbook.name)          # \"My Project\"\nprint(workbook.metadata)      # {\"title\": \"My Project\", \"author\": \"Alice\"}\n</code></pre>"},{"location":"ja/#gfm","title":"GFM\u6a5f\u80fd\u306e\u30b5\u30dd\u30fc\u30c8","text":"<p>\u30d1\u30fc\u30b5\u30fc\u306f\u3001\u30c6\u30fc\u30d6\u30eb\u306b\u95a2\u3059\u308bGitHub Flavored Markdown (GFM) \u4ed5\u69d8\u306b\u53b3\u5bc6\u306b\u6e96\u62e0\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>\u5217\u306e\u914d\u7f6e \u533a\u5207\u308a\u884c\u306e\u914d\u7f6e\u30de\u30fc\u30ab\u30fc\u306f\u89e3\u6790\u3055\u308c\u3001\u4fdd\u6301\u3055\u308c\u307e\u3059\u3002</p> <pre><code>markdown = \"\"\"\n| Left | Center | Right |\n| :--- | :----: | ----: |\n| 1    | 2      | 3     |\n\"\"\"\ntable = parse_table(markdown)\nprint(table.alignments)\n# [\"left\", \"center\", \"right\"]\n</code></pre> <p>\u30b3\u30fc\u30c9\u5185\u306e\u30d1\u30a4\u30d7\u3068\u30a8\u30b9\u30b1\u30fc\u30d7 \u30a4\u30f3\u30e9\u30a4\u30f3\u30b3\u30fc\u30c9\u30d6\u30ed\u30c3\u30af\uff08\u30d0\u30c3\u30af\u30af\u30a9\u30fc\u30c8\uff09\u5185\u306e\u30d1\u30a4\u30d7 <code>|</code> \u3084\u3001<code>\\</code> \u3067\u30a8\u30b9\u30b1\u30fc\u30d7\u3055\u308c\u305f\u30d1\u30a4\u30d7\u306f\u3001\u5217\u533a\u5207\u308a\u3067\u306f\u306a\u304f\u30b3\u30f3\u30c6\u30f3\u30c4\u3068\u3057\u3066\u6b63\u3057\u304f\u6271\u308f\u308c\u307e\u3059\u3002</p> <pre><code>markdown = \"\"\"\n| Code  | Escaped |\n| ----- | ------- |\n| `a|b` | \\|      |\n\"\"\"\ntable = parse_table(markdown)\n# table.rows[0] == [\"`a|b`\", \"|\"]\n</code></pre>"},{"location":"ja/#2","title":"2. \u578b\u5b89\u5168\u306a\u691c\u8a3c (\u63a8\u5968)","text":"<p>\u3053\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u6700\u3082\u5f37\u529b\u306a\u6a5f\u80fd\u306f\u3001<code>dataclasses</code> \u3092\u4f7f\u7528\u3057\u3066\u3001\u30eb\u30fc\u30ba\u306aMarkdown\u30c6\u30fc\u30d6\u30eb\u3092\u5f37\u304f\u578b\u4ed8\u3051\u3055\u308c\u305fPython\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u30c7\u30fc\u30bf\u306e\u59a5\u5f53\u6027\u304c\u4fdd\u8a3c\u3055\u308c\u3001\u6271\u3044\u3084\u3059\u304f\u306a\u308a\u307e\u3059\u3002</p> <pre><code>from dataclasses import dataclass\nfrom md_spreadsheet_parser import parse_table, TableValidationError\n\n@dataclass\nclass User:\n    name: str\n    age: int\n    is_active: bool = True\n\nmarkdown = \"\"\"\n| Name | Age | Is Active |\n|---|---|---|\n| Alice | 30 | yes |\n| Bob | 25 | no |\n\"\"\"\n\ntry:\n    # \u30ef\u30f3\u30b9\u30c6\u30c3\u30d7\u3067\u89e3\u6790\u3068\u691c\u8a3c\n    users = parse_table(markdown).to_models(User)\n\n    for user in users:\n        print(f\"{user.name} is {user.age} years old.\")\n        # Alice is 30 years old.\n        # Bob is 25 years old.\n\nexcept TableValidationError as e:\n    print(e)\n</code></pre> <p>\u6a5f\u80fd: *   \u578b\u5909\u63db: \u6587\u5b57\u5217\u3092\u6a19\u6e96\u7684\u306a\u30eb\u30fc\u30eb\u3067\u81ea\u52d5\u7684\u306b <code>int</code>, <code>float</code>, <code>bool</code> \u306b\u5909\u63db\u3057\u307e\u3059\u3002 *   \u30d6\u30fc\u30eb\u5024\u306e\u51e6\u7406 (\u30c7\u30d5\u30a9\u30eb\u30c8): \u6a19\u6e96\u7684\u306a\u30da\u30a2 <code>true/false</code>, <code>yes/no</code>, <code>on/off</code>, <code>1/0</code>\u3001\u304a\u3088\u3073\u30cd\u30a4\u30c6\u30a3\u30d6\u306eGFM\u30bf\u30b9\u30af\u30ea\u30b9\u30c8 <code>[x]/[ ]</code> \u3092\u5373\u5ea7\u306b\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059\u3002\uff08\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u306b\u3064\u3044\u3066\u306f \u9ad8\u5ea6\u306a\u578b\u5909\u63db \u3092\u53c2\u7167\uff09\u3002 *   \u30aa\u30d7\u30b7\u30e7\u30f3\u30d5\u30a3\u30fc\u30eb\u30c9: \u7a7a\u6587\u5b57\u5217\u3092 <code>None</code> \u306b\u5909\u63db\u3059\u308b\u3053\u3068\u3067 <code>Optional[T]</code> \u3092\u51e6\u7406\u3057\u307e\u3059\u3002 *   \u691c\u8a3c: \u30c7\u30fc\u30bf\u304c\u30b9\u30ad\u30fc\u30de\u306b\u4e00\u81f4\u3057\u306a\u3044\u5834\u5408\u3001\u8a73\u7d30\u306a\u30a8\u30e9\u30fc\u3092\u767a\u751f\u3055\u305b\u307e\u3059\u3002</p>"},{"location":"ja/#pydantic","title":"Pydantic\u9023\u643a","text":"<p>\u3088\u308a\u9ad8\u5ea6\u306a\u691c\u8a3c\uff08\u30e1\u30fc\u30eb\u5f62\u5f0f\u3001\u7bc4\u56f2\u3001\u6b63\u898f\u8868\u73fe\uff09\u3092\u884c\u3046\u306b\u306f\u3001dataclasses\u306e\u4ee3\u308f\u308a\u306b Pydantic \u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002<code>pydantic</code> \u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u3001\u3053\u306e\u6a5f\u80fd\u306f\u81ea\u52d5\u7684\u306b\u6709\u52b9\u306b\u306a\u308a\u307e\u3059\u3002</p> <pre><code>from pydantic import BaseModel, Field, EmailStr\n\nclass User(BaseModel):\n    name: str = Field(alias=\"User Name\")\n    age: int = Field(gt=0)\n    email: EmailStr\n\n# \u81ea\u52d5\u7684\u306bPydantic\u30e2\u30c7\u30eb\u3092\u691c\u51fa\u3057\u3001\u691c\u8a3c\u306b\u4f7f\u7528\u3057\u307e\u3059\nusers = parse_table(markdown).to_models(User)\n</code></pre> <p>\u30d1\u30fc\u30b5\u30fc\u306fPydantic\u306e <code>alias</code> \u3068 <code>Field</code> \u5236\u7d04\u3092\u5c0a\u91cd\u3057\u307e\u3059\u3002</p>"},{"location":"ja/#3-json","title":"3. JSON\u3068\u8f9e\u66f8\u3078\u306e\u5909\u63db","text":"<p>\u5b8c\u5168\u306aDataclass\u3084Pydantic\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9\u3057\u305f\u304f\u306a\u3044\u5834\u5408\u3084\u3001JSON\u6587\u5b57\u5217\u3092\u542b\u3080\u5217\u304c\u3042\u308b\u5834\u5408\u306e\u5bfe\u5fdc\u3067\u3059\u3002</p> <p>\u30b7\u30f3\u30d7\u30eb\u306a\u8f9e\u66f8\u51fa\u529b \u30c6\u30fc\u30d6\u30eb\u3092\u8f9e\u66f8\u306e\u30ea\u30b9\u30c8\u306b\u76f4\u63a5\u5909\u63db\u3057\u307e\u3059\u3002\u30ad\u30fc\u306f\u30d8\u30c3\u30c0\u30fc\u304b\u3089\u6d3e\u751f\u3057\u307e\u3059\u3002</p> <pre><code># list[dict[str, Any]] \u3092\u8fd4\u3057\u307e\u3059 (\u5024\u306f\u751f\u306e\u6587\u5b57\u5217\u3067\u3059)\nrows = parse_table(markdown).to_models(dict)\nprint(rows[0])\n# {'Name': 'Alice', 'Age': '30'}\n</code></pre> <p>TypedDict \u30b5\u30dd\u30fc\u30c8 \u8efd\u91cf\u306a\u578b\u5b89\u5168\u6027\u306e\u305f\u3081\u306b <code>TypedDict</code> \u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\u30d1\u30fc\u30b5\u30fc\u306f\u578b\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3057\u3066\u5024\u3092\u81ea\u52d5\u7684\u306b\u5909\u63db\u3057\u307e\u3059\u3002</p> <pre><code>from typing import TypedDict\n\nclass User(TypedDict):\n    name: str\n    age: int\n    active: bool\n\nrows = parse_table(markdown).to_models(User)\nprint(rows[0])\n# {'name': 'Alice', 'age': 30, 'active': True}\n</code></pre> <p>\u5217\u30ec\u30d9\u30eb\u306eJSON\u89e3\u6790 \u30d5\u30a3\u30fc\u30eb\u30c9\u304c <code>dict</code> \u307e\u305f\u306f <code>list</code> \u3068\u3057\u3066\u578b\u4ed8\u3051\u3055\u308c\u3066\u3044\u308b\u5834\u5408\uff08Dataclass\u307e\u305f\u306fPydantic\u30e2\u30c7\u30eb\u5185\uff09\u3001\u30d1\u30fc\u30b5\u30fc\u306f \u30bb\u30eb\u306e\u5024\u3092\u81ea\u52d5\u7684\u306bJSON\u3068\u3057\u3066\u89e3\u6790 \u3057\u307e\u3059\u3002</p> <pre><code>@dataclass\nclass Config:\n    id: int\n    metadata: dict  # \u30bb\u30eb: '{\"debug\": true}' -&gt; dict\u306b\u89e3\u6790\n    tags: list      # \u30bb\u30eb: '[\"a\", \"b\"]'      -&gt; list\u306b\u89e3\u6790\n\n# Pydantic\u30e2\u30c7\u30eb\u3082Json[]\u30e9\u30c3\u30d1\u30fc\u306a\u3057\u3067\u52d5\u4f5c\u3057\u307e\u3059\nclass ConfigModel(BaseModel):\n    metadata: dict\n</code></pre> <p>\u5236\u9650\u4e8b\u9805: *   JSON\u69cb\u6587: \u30bb\u30eb\u306e\u5185\u5bb9\u306f\u6709\u52b9\u306aJSON\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff08\u4f8b: \u30c0\u30d6\u30eb\u30af\u30a9\u30fc\u30c8 <code>{\"a\": 1}</code>\uff09\u3002\u4e0d\u6b63\u306aJSON\u306f <code>ValueError</code> \u3092\u767a\u751f\u3055\u305b\u307e\u3059\u3002 *   \u5358\u7d14\u306a\u8f9e\u66f8\u89e3\u6790: <code>to_models(dict)</code> \u306f\u3001\u30ab\u30b9\u30bf\u30e0\u30b9\u30ad\u30fc\u30de\u3092\u4f7f\u7528\u3057\u306a\u3044\u9650\u308a\u3001\u5185\u90e8\u306eJSON\u6587\u5b57\u5217\u3092\u81ea\u52d5\u7684\u306b\u306f\u89e3\u6790 \u3057\u307e\u305b\u3093\u3002\u6587\u5b57\u5217\u306e\u6d45\u3044\u8f9e\u66f8\u3092\u4f5c\u6210\u3059\u308b\u3060\u3051\u3067\u3059\u3002</p>"},{"location":"ja/#4-pandas","title":"4. Pandas\u9023\u643a\u3068\u30a8\u30af\u30b9\u30dd\u30fc\u30c8","text":"<p>\u3053\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306f\u3001Markdown\u3068 Pandas \u306a\u3069\u306e\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u30c4\u30fc\u30eb\u306e\u67b6\u3051\u6a4b\u3068\u306a\u308b\u3088\u3046\u306b\u8a2d\u8a08\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p> <p>DataFrame\u3078\u306e\u5909\u63db (\u6700\u3082\u7c21\u5358\u306a\u65b9\u6cd5) DataFrame\u3092\u4f5c\u6210\u3059\u308b\u6700\u3082\u304d\u308c\u3044\u306a\u65b9\u6cd5\u306f\u3001<code>to_models(dict)</code> \u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u3053\u308c\u306fPandas\u304c\u76f4\u63a5\u53d6\u308a\u8fbc\u3081\u308b\u8f9e\u66f8\u306e\u30ea\u30b9\u30c8\u3092\u8fd4\u3057\u307e\u3059\u3002</p> <pre><code>import pandas as pd\nfrom md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| Date       | Sales | Region |\n|------------|-------|--------|\n| 2023-01-01 | 100   | US     |\n| 2023-01-02 | 150   | EU     |\n\"\"\"\n\ntable = parse_table(markdown)\n\n# 1. \u8f9e\u66f8\u306e\u30ea\u30b9\u30c8\u306b\u5909\u63db\ndata = table.to_models(dict)\n\n# 2. DataFrame\u306e\u4f5c\u6210\ndf = pd.DataFrame(data)\n\n# 3. \u5f8c\u51e6\u7406: \u578b\u5909\u63db (Pandas\u306f\u901a\u5e38\u3001\u6700\u521d\u306f\u6587\u5b57\u5217\u3068\u3057\u3066\u63a8\u8ad6\u3057\u307e\u3059)\ndf[\"Sales\"] = pd.to_numeric(df[\"Sales\"])\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\n\nprint(df.dtypes)\n# Date      datetime64[ns]\n# Sales              int64\n# Region            object\n</code></pre> <p>\u578b\u5b89\u5168\u306a\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304b\u3089\u306e\u5909\u63db DataFrame\u3092\u4f5c\u6210\u3059\u308b \u524d \u306b\u30c7\u30fc\u30bf\u3092\u691c\u8a3c\u3057\u305f\u3044\u5834\u5408\uff08\u4f8b: \u89e3\u6790\u4e2d\u306b \"Sales\" \u304c\u6574\u6570\u3067\u3042\u308b\u3053\u3068\u3092\u4fdd\u8a3c\u3059\u308b\uff09\u306f\u3001<code>dataclass</code> \u3092\u4f7f\u7528\u3057\u3066\u304b\u3089Pandas\u306b\u5909\u63db\u3057\u307e\u3059\u3002</p> <pre><code>from dataclasses import dataclass, asdict\n\n@dataclass\nclass SalesRecord:\n    date: str\n    amount: int\n    region: str\n\n# 1. \u89e3\u6790\u3068\u691c\u8a3c (\u7121\u52b9\u306a\u5834\u5408\u306fTableValidationError\u304c\u767a\u751f)\nrecords = parse_table(markdown).to_models(SalesRecord)\n\n# 2. asdict()\u3092\u4f7f\u7528\u3057\u3066DataFrame\u306b\u5909\u63db\ndf = pd.DataFrame([asdict(r) for r in records])\n\n# 'amount' \u5217\u306f\u691c\u8a3c\u6642\u306b\u5909\u63db\u3055\u308c\u3066\u3044\u308b\u305f\u3081\u3001\u3059\u3067\u306bint64\u3067\u3059\nprint(df[\"amount\"].dtype) # int64\n</code></pre> <p>JSON\u30a8\u30af\u30b9\u30dd\u30fc\u30c8 \u3059\u3079\u3066\u306e\u7d50\u679c\u30aa\u30d6\u30b8\u30a7\u30af\u30c8 (<code>Workbook</code>, <code>Sheet</code>, <code>Table</code>) \u306b\u306f\u3001\u30b7\u30ea\u30a2\u30e9\u30a4\u30ba\u306b\u9069\u3057\u305f\u8f9e\u66f8\u69cb\u9020\u3092\u8fd4\u3059 <code>.json</code> \u30d7\u30ed\u30d1\u30c6\u30a3\u304c\u3042\u308a\u307e\u3059\u3002</p> <pre><code>import json\n\n# \u30ef\u30fc\u30af\u30d6\u30c3\u30af\u69cb\u9020\u5168\u4f53\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\nprint(json.dumps(workbook.json, indent=2))\n</code></pre>"},{"location":"ja/#5-excel","title":"5. Excel\u30a4\u30f3\u30dd\u30fc\u30c8","text":"<p>\u7d50\u5408\u30bb\u30eb\u3084\u968e\u5c64\u30d8\u30c3\u30c0\u30fc\u3092\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306b\u51e6\u7406\u3057\u3066\u3001Excel\u30c7\u30fc\u30bf\uff08TSV/CSV\u307e\u305f\u306f <code>openpyxl</code> \u7d4c\u7531\uff09\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\u3057\u307e\u3059\u3002</p> <p>[!NOTE] TSV/CSV\u30c6\u30ad\u30b9\u30c8\u304b\u3089\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\u306f \u4f9d\u5b58\u95a2\u4fc2\u30bc\u30ed \u3067\u52d5\u4f5c\u3057\u307e\u3059\u3002<code>.xlsx</code> \u30d5\u30a1\u30a4\u30eb\u306e\u76f4\u63a5\u8aad\u307f\u8fbc\u307f\u306b\u306f <code>openpyxl</code>\uff08\u30e6\u30fc\u30b6\u30fc\u7ba1\u7406\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u4f9d\u5b58\u95a2\u4fc2\uff09\u304c\u5fc5\u8981\u3067\u3059\u3002</p> <p>\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9</p> <p>\ud83d\ude80 \u3088\u308a\u5305\u62ec\u7684\u306a\u30ec\u30b7\u30d4\u306b\u3064\u3044\u3066\u306f Cookbook \u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002</p> <pre><code>from md_spreadsheet_parser import parse_excel\n\n# TSV/CSV\u304b\u3089 (\u4f9d\u5b58\u95a2\u4fc2\u30bc\u30ed)\ntable = parse_excel(\"Name\\tAge\\nAlice\\t30\")\n\n# .xlsx\u304b\u3089 (openpyxl\u304c\u5fc5\u8981)\nimport openpyxl\nwb = openpyxl.load_workbook(\"data.xlsx\")\ntable = parse_excel(wb.active)\n</code></pre> <p>\u7d50\u5408\u30d8\u30c3\u30c0\u30fc\u306e\u51e6\u7406</p> <p>Excel\u304c\u7d50\u5408\u30bb\u30eb\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3059\u308b\u3068\u3001\u305d\u308c\u3089\u306f\u7a7a\u306e\u30bb\u30eb\u3068\u3057\u3066\u8868\u793a\u3055\u308c\u307e\u3059\u3002\u30d1\u30fc\u30b5\u30fc\u306f\u3053\u308c\u3089\u306e\u30ae\u30e3\u30c3\u30d7\u3092\u81ea\u52d5\u7684\u306b\u524d\u65b9\u57cb\u3081\u3057\u307e\u3059\uff1a</p> <pre><code>Excel (\u7d50\u5408\u30d8\u30c3\u30c0\u30fc):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Category (3 cols)      \u2502  Info  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    A    \u2502    B    \u2502    C    \u2502   D    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n          \u2193 parse_excel()\n\nMarkdown:\n| Category | Category | Category | Info |\n|----------|----------|----------|------|\n| A        | B        | C        | D    |\n</code></pre> <p>2\u884c\u968e\u5c64\u30d8\u30c3\u30c0\u30fc</p> <p>\u89aa\u5b50\u95a2\u4fc2\u306e\u3042\u308b\u8907\u96d1\u306a\u30d8\u30c3\u30c0\u30fc\u306b\u306f\u3001<code>ExcelParsingSchema(header_rows=2)</code> \u3092\u4f7f\u7528\u3057\u307e\u3059\uff1a</p> <pre><code>Excel (2\u884c\u30d8\u30c3\u30c0\u30fc):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       Info        \u2502      Metrics      \u2502  \u2190 Row 1 (Parent)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Name   \u2502   ID    \u2502  Score  \u2502  Rank   \u2502  \u2190 Row 2 (Child)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Alice  \u2502   001   \u2502   95    \u2502    1    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n          \u2193 parse_excel(schema=ExcelParsingSchema(header_rows=2))\n\nMarkdown:\n| Info - Name | Info - ID | Metrics - Score | Metrics - Rank |\n|-------------|-----------|-----------------|----------------|\n| Alice       | 001       | 95              | 1              |\n</code></pre> <p>\u6ce8: \u73fe\u5728\u3001\u6700\u59272\u884c\u306e\u30d8\u30c3\u30c0\u30fc\u884c\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002\u3088\u308a\u6df1\u3044\u968e\u5c64\u306e\u5834\u5408\u306f\u3001\u89e3\u6790\u524d\u306b\u30c7\u30fc\u30bf\u3092\u524d\u51e6\u7406\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <p>Excel\u304b\u3089\u69cb\u9020\u5316\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3078\uff08\u300c\u30ad\u30e9\u30fc\u300d\u6a5f\u80fd\uff09</p> <p>\u5358\u306b\u30c6\u30ad\u30b9\u30c8\u306b\u5909\u63db\u3059\u308b\u3060\u3051\u3067\u306a\u304f\u3001Excel\u3092\u30ef\u30f3\u30b9\u30c6\u30c3\u30d7\u3067\u6709\u52b9\u3067\u578b\u5b89\u5168\u306aPython\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u76f4\u63a5\u5909\u63db\u3057\u307e\u3059\u3002</p> <pre><code>@dataclass\nclass SalesRecord:\n    category: str\n    item: str\n    amount: int  # \u6587\u5b57\u5217\u304b\u3089int\u3078\u306e\u81ea\u52d5\u5909\u63db\n\n# 1. Excel\u3092\u89e3\u6790 (\u7d50\u5408\u30bb\u30eb\u3092\u81ea\u52d5\u7684\u306b\u51e6\u7406)\n# 2. \u691c\u8a3c\u3068\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3078\u306e\u5909\u63db\nrecords = parse_excel(ws).to_models(SalesRecord)\n\n# \u3053\u308c\u3067\u304d\u308c\u3044\u306a\u578b\u4ed8\u304d\u30c7\u30fc\u30bf\u304c\u5f97\u3089\u308c\u307e\u3059\nassert records[0].amount == 1000\n</code></pre> <p>\u8a2d\u5b9a</p> <p>\u89e3\u6790\u52d5\u4f5c\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3059\u308b\u306b\u306f <code>ExcelParsingSchema</code> \u3092\u4f7f\u7528\u3057\u307e\u3059\uff1a</p> <pre><code>from md_spreadsheet_parser import parse_excel, ExcelParsingSchema\n\nschema = ExcelParsingSchema(\n    header_rows=2,\n    fill_merged_headers=True,\n    header_separator=\" / \"\n)\n\ntable = parse_excel(source, schema)\n</code></pre> \u30aa\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 \u8aac\u660e <code>header_rows</code> <code>1</code> \u30d8\u30c3\u30c0\u30fc\u884c\u306e\u6570 (1 or 2)\u3002 <code>fill_merged_headers</code> <code>True</code> \u7a7a\u306e\u30d8\u30c3\u30c0\u30fc\u30bb\u30eb\u3092\u524d\u65b9\u57cb\u3081\u3057\u307e\u3059\u3002 <code>header_separator</code> <code>\" - \"</code> \u30d5\u30e9\u30c3\u30c8\u5316\u3055\u308c\u305f2\u884c\u30d8\u30c3\u30c0\u30fc\u306e\u533a\u5207\u308a\u6587\u5b57\u3002 <code>delimiter</code> <code>\"\\t\"</code> TSV/CSV\u306e\u5217\u533a\u5207\u308a\u6587\u5b57\u3002"},{"location":"ja/#6-markdown","title":"6. Markdown\u751f\u6210 (\u30e9\u30a6\u30f3\u30c9\u30c8\u30ea\u30c3\u30d7)","text":"<p>\u89e3\u6790\u3055\u308c\u305f\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u5909\u66f4\u3057\u3001<code>to_markdown()</code> \u3092\u4f7f\u7528\u3057\u3066Markdown\u6587\u5b57\u5217\u306b\u623b\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u5b8c\u5168\u306a\u300c\u89e3\u6790 -&gt; \u5909\u66f4 -&gt; \u751f\u6210\u300d\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u304c\u53ef\u80fd\u306b\u306a\u308a\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import parse_table, ParsingSchema\n\nmarkdown = \"| A | B |\\n|---|---| \\n| 1 | 2 |\"\ntable = parse_table(markdown)\n\n# \u30c7\u30fc\u30bf\u306e\u5909\u66f4\ntable.rows.append([\"3\", \"4\"])\n\n# Markdown\u306e\u751f\u6210\n# \u30b9\u30ad\u30fc\u30de\u3092\u4f7f\u7528\u3057\u3066\u51fa\u529b\u5f62\u5f0f\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3067\u304d\u307e\u3059\nschema = ParsingSchema(require_outer_pipes=True)\nprint(table.to_markdown(schema))\n# | A | B |\n# | --- | --- |\n# | 1 | 2 |\n# | 3 | 4 |\n</code></pre>"},{"location":"ja/#7","title":"7. \u9ad8\u5ea6\u306a\u6a5f\u80fd","text":"<p>\u30e1\u30bf\u30c7\u30fc\u30bf\u62bd\u51fa\u306e\u8a2d\u5b9a \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u3001\u30d1\u30fc\u30b5\u30fc\u306f\u30c6\u30fc\u30d6\u30eb\u540d\uff08\u30ec\u30d9\u30eb3\u30d8\u30c3\u30c0\u30fc\uff09\u3068\u8aac\u660e\u3092\u30ad\u30e3\u30d7\u30c1\u30e3\u3057\u307e\u3059\u3002<code>MultiTableParsingSchema</code> \u3067\u3053\u306e\u52d5\u4f5c\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3067\u304d\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import MultiTableParsingSchema\n\nschema = MultiTableParsingSchema(\n    table_header_level=3,     # ### Header \u3092\u30c6\u30fc\u30d6\u30eb\u540d\u3068\u3057\u3066\u6271\u3046\n    capture_description=True  # \u30d8\u30c3\u30c0\u30fc\u3068\u30c6\u30fc\u30d6\u30eb\u306e\u9593\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u30ad\u30e3\u30d7\u30c1\u30e3\n)\n# parse_workbook \u306b\u30b9\u30ad\u30fc\u30de\u3092\u6e21\u3059...\n</code></pre>"},{"location":"ja/#8","title":"8. \u9ad8\u5ea6\u306a\u578b\u5909\u63db","text":"<p><code>to_models()</code> \u306b <code>ConversionSchema</code> \u3092\u6e21\u3059\u3053\u3068\u3067\u3001\u6587\u5b57\u5217\u5024\u304cPython\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3055\u308c\u308b\u65b9\u6cd5\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3067\u304d\u307e\u3059\u3002\u3053\u308c\u306f\u56fd\u969b\u5316 (I18N) \u3084\u30ab\u30b9\u30bf\u30e0\u578b\u306e\u51e6\u7406\u306b\u5f79\u7acb\u3061\u307e\u3059\u3002</p> <p>\u56fd\u969b\u5316 (I18N): \u30ab\u30b9\u30bf\u30e0\u30d6\u30fc\u30eb\u5024\u30da\u30a2</p> <p>\u3069\u306e\u6587\u5b57\u5217\u30da\u30a2\u3092 <code>True</code>/<code>False</code> \u306b\u30de\u30c3\u30d4\u30f3\u30b0\u3059\u308b\u304b\u3092\u8a2d\u5b9a\u3057\u307e\u3059\uff08\u5927\u6587\u5b57\u5c0f\u6587\u5b57\u3092\u533a\u5225\u3057\u307e\u305b\u3093\uff09\u3002</p> <pre><code>from md_spreadsheet_parser import parse_table, ConversionSchema\n\nmarkdown = \"\"\"\n| User | Active? |\n| --- | --- |\n| Tanaka | \u306f\u3044 |\n| Suzuki | \u3044\u3044\u3048 |\n\"\"\"\n\n# \"\u306f\u3044\" -&gt; True, \"\u3044\u3044\u3048\" -&gt; False \u3092\u8a2d\u5b9a\u3001\u305d\u308c\u306b\u30bf\u30b9\u30af\u30ea\u30b9\u30c8\u3082\nschema = ConversionSchema(\n    boolean_pairs=(\n        (\"\u306f\u3044\", \"\u3044\u3044\u3048\"),\n        (\"[x]\", \"[ ]\")\n    )\n)\n\nusers = parse_table(markdown).to_models(User, conversion_schema=schema)\n# Tanaka.active is True\n</code></pre> <p>\u30ab\u30b9\u30bf\u30e0\u578b\u30b3\u30f3\u30d0\u30fc\u30bf</p> <p>\u7279\u5b9a\u306e\u578b\u306e\u30ab\u30b9\u30bf\u30e0\u5909\u63db\u95a2\u6570\u3092\u767b\u9332\u3057\u307e\u3059\u3002\u4ee5\u4e0b\u3092\u542b\u3080 \u4efb\u610f\u306ePython\u578b \u3092\u30ad\u30fc\u3068\u3057\u3066\u4f7f\u7528\u3067\u304d\u307e\u3059\uff1a</p> <ul> <li>\u7d44\u307f\u8fbc\u307f: <code>int</code>, <code>float</code>, <code>bool</code> (\u30c7\u30d5\u30a9\u30eb\u30c8\u52d5\u4f5c\u306e\u4e0a\u66f8\u304d)</li> <li>\u6a19\u6e96\u30e9\u30a4\u30d6\u30e9\u30ea: <code>Decimal</code>, <code>datetime</code>, <code>date</code>, <code>ZoneInfo</code>, <code>UUID</code></li> <li>\u30ab\u30b9\u30bf\u30e0\u30af\u30e9\u30b9: \u72ec\u81ea\u306e\u30c7\u30fc\u30bf\u30af\u30e9\u30b9\u3084\u30aa\u30d6\u30b8\u30a7\u30af\u30c8</li> </ul> <p>\u6a19\u6e96\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u578b\u3068\u30ab\u30b9\u30bf\u30e0\u30af\u30e9\u30b9\u3092\u4f7f\u7528\u3057\u305f\u4f8b\uff1a</p> <pre><code>from dataclasses import dataclass\nfrom uuid import UUID\nfrom zoneinfo import ZoneInfo\nfrom md_spreadsheet_parser import ConversionSchema, parse_table\n\n@dataclass\nclass Color:\n    r: int\n    g: int\n    b: int\n\n@dataclass\nclass Config:\n    timezone: ZoneInfo\n    session_id: UUID\n    theme_color: Color\n\nmarkdown = \"\"\"\n| Timezone | Session ID | Theme Color |\n| --- | --- | --- |\n| Asia/Tokyo | 12345678-1234-5678-1234-567812345678 | 255,0,0 |\n\"\"\"\n\nschema = ConversionSchema(\n    custom_converters={\n        # \u6a19\u6e96\u30e9\u30a4\u30d6\u30e9\u30ea\u578b\n        ZoneInfo: lambda v: ZoneInfo(v),\n        UUID: lambda v: UUID(v),\n        # \u30ab\u30b9\u30bf\u30e0\u30af\u30e9\u30b9\n        Color: lambda v: Color(*map(int, v.split(\",\")))\n    }\n)\n\ndata = parse_table(markdown).to_models(Config, conversion_schema=schema)\n# data[0].timezone is ZoneInfo(\"Asia/Tokyo\")\n# data[0].theme_color is Color(255, 0, 0)\n</code></pre> <p>\u30d5\u30a3\u30fc\u30eb\u30c9\u56fa\u6709\u306e\u30b3\u30f3\u30d0\u30fc\u30bf</p> <p>\u8a73\u7d30\u306a\u5236\u5fa1\u306e\u305f\u3081\u306b\u3001\u7279\u5b9a\u306e\u30d5\u30a3\u30fc\u30eb\u30c9\u540d\u306b\u5bfe\u3059\u308b\u30b3\u30f3\u30d0\u30fc\u30bf\u3092\u5b9a\u7fa9\u3067\u304d\u3001\u3053\u308c\u3089\u306f\u578b\u30d9\u30fc\u30b9\u306e\u30b3\u30f3\u30d0\u30fc\u30bf\u3088\u308a\u3082\u512a\u5148\u3055\u308c\u307e\u3059\u3002</p> <pre><code>def parse_usd(val): ...\ndef parse_jpy(val): ...\n\nschema = ConversionSchema(\n    # \u578b\u30d9\u30fc\u30b9\u306e\u30c7\u30d5\u30a9\u30eb\u30c8 (\u4f4e\u512a\u5148\u5ea6)\n    custom_converters={\n        Decimal: parse_usd \n    },\n    # \u30d5\u30a3\u30fc\u30eb\u30c9\u540d\u306e\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9 (\u9ad8\u512a\u5148\u5ea6)\n    field_converters={\n        \"price_jpy\": parse_jpy,\n        \"created_at\": lambda x: datetime.strptime(x, \"%Y/%m/%d\")\n    }\n)\n\n# price_usd (\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\u306a\u3057) -&gt; custom_converters (parse_usd)\n# price_jpy (\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9)    -&gt; field_converters (parse_jpy)\ndata = parse_table(markdown).to_models(Product, conversion_schema=schema)\n</code></pre> <p>\u6a19\u6e96\u30b3\u30f3\u30d0\u30fc\u30bf\u30e9\u30a4\u30d6\u30e9\u30ea</p> <p>\u4e00\u822c\u7684\u306a\u30d1\u30bf\u30fc\u30f3\uff08\u901a\u8ca8\u3001\u30ea\u30b9\u30c8\uff09\u306b\u3064\u3044\u3066\u306f\u3001\u72ec\u81ea\u306b\u8a18\u8ff0\u3059\u308b\u4ee3\u308f\u308a\u306b\u3001<code>md_spreadsheet_parser.converters</code> \u306b\u3042\u308b\u7d44\u307f\u8fbc\u307f\u30d8\u30eb\u30d1\u30fc\u95a2\u6570\u3092\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser.converters import (\n    to_decimal_clean,        # \"$1,000\", \"\u00a5500\" -&gt; Decimal\n    make_datetime_converter, # \u89e3\u6790/TZ\u30ed\u30b8\u30c3\u30af\u306e\u30d5\u30a1\u30af\u30c8\u30ea\n    make_list_converter,     # \"a,b,c\" -&gt; [\"a\", \"b\", \"c\"]\n    make_bool_converter      # \u30ab\u30b9\u30bf\u30e0\u306e\u53b3\u5bc6\u306a\u30d6\u30fc\u30eb\u5024\u30bb\u30c3\u30c8\n)\n\nschema = ConversionSchema(\n    custom_converters={\n        # \u901a\u8ca8: $, \u00a5, \u20ac, \u00a3, \u30ab\u30f3\u30de, \u30b9\u30da\u30fc\u30b9\u3092\u524a\u9664\n        Decimal: to_decimal_clean,\n        # DateTime: ISO\u5f62\u5f0f\u30c7\u30d5\u30a9\u30eb\u30c8, \u30ca\u30a4\u30fc\u30d6\u306a\u5834\u5408\u306fTokyo TZ\u3092\u4ed8\u4e0e\n        datetime: make_datetime_converter(tz=ZoneInfo(\"Asia/Tokyo\")),\n        # \u30ea\u30b9\u30c8: \u30ab\u30f3\u30de\u3067\u5206\u5272, \u7a7a\u767d\u3092\u9664\u53bb\n        list: make_list_converter(separator=\",\")\n    },\n    field_converters={\n        # \u7279\u5b9a\u306e\u30d5\u30a3\u30fc\u30eb\u30c9\u306b\u5bfe\u3059\u308b\u30ab\u30b9\u30bf\u30e0\u30d6\u30fc\u30eb\u5024\n        \"is_valid\": make_bool_converter(true_values=[\"OK\"], false_values=[\"NG\"])\n    }\n)\n</code></pre>"},{"location":"ja/#9","title":"9. \u5805\u7262\u6027 (\u4e0d\u6b63\u306a\u30c6\u30fc\u30d6\u30eb\u306e\u51e6\u7406)","text":"<p>\u30d1\u30fc\u30b5\u30fc\u306f\u3001\u4e0d\u5b8c\u5168\u306aMarkdown\u30c6\u30fc\u30d6\u30eb\u3092\u9069\u5207\u306b\u51e6\u7406\u3059\u308b\u3088\u3046\u306b\u8a2d\u8a08\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p> <ul> <li>\u5217\u306e\u6b20\u843d: \u30d8\u30c3\u30c0\u30fc\u3088\u308a\u3082\u5217\u304c\u5c11\u306a\u3044\u884c\u306f\u3001\u81ea\u52d5\u7684\u306b\u7a7a\u6587\u5b57\u5217\u3067 \u30d1\u30c7\u30a3\u30f3\u30b0 \u3055\u308c\u307e\u3059\u3002</li> <li>\u4f59\u5206\u306a\u5217: \u30d8\u30c3\u30c0\u30fc\u3088\u308a\u3082\u5217\u304c\u591a\u3044\u884c\u306f\u3001\u81ea\u52d5\u7684\u306b \u5207\u308a\u6368\u3066 \u3089\u308c\u307e\u3059\u3002</li> </ul> <pre><code>from md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| A | B |\n|---|---|\n| 1 |       &lt;-- \u5217\u306e\u6b20\u843d\n| 1 | 2 | 3 &lt;-- \u4f59\u5206\u306a\u5217\n\"\"\"\n\ntable = parse_table(markdown)\n\nprint(table.rows)\n# [['1', ''], ['1', '2']]\n</code></pre> <p>\u3053\u308c\u306b\u3088\u308a\u3001<code>table.rows</code> \u306f\u5e38\u306b <code>table.headers</code> \u306e\u69cb\u9020\u3068\u4e00\u81f4\u3059\u308b\u3053\u3068\u304c\u4fdd\u8a3c\u3055\u308c\u3001\u53cd\u5fa9\u3084\u691c\u8a3c\u4e2d\u306e\u30af\u30e9\u30c3\u30b7\u30e5\u3092\u9632\u304e\u307e\u3059\u3002</p>"},{"location":"ja/#10","title":"10. \u30bb\u30eb\u5185\u6539\u884c\u306e\u30b5\u30dd\u30fc\u30c8","text":"<p>\u30d1\u30fc\u30b5\u30fc\u306f\u3001HTML\u306e\u6539\u884c\u30bf\u30b0\u3092\u81ea\u52d5\u7684\u306bPython\u306e\u6539\u884c (<code>\\n</code>) \u306b\u5909\u63db\u3057\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u8907\u6570\u884c\u306e\u30bb\u30eb\u3092\u81ea\u7136\u306b\u6271\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <p>\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u308b\u30bf\u30b0 (\u5927\u6587\u5b57\u5c0f\u6587\u5b57\u533a\u5225\u306a\u3057): - <code>&lt;br&gt;</code> - <code>&lt;br/&gt;</code> - <code>&lt;br /&gt;</code></p> <pre><code>markdown = \"| Line1&lt;br&gt;Line2 |\"\ntable = parse_table(markdown)\n# table.rows[0][0] == \"Line1\\nLine2\"\n</code></pre> <p>\u30e9\u30a6\u30f3\u30c9\u30c8\u30ea\u30c3\u30d7\u30b5\u30dd\u30fc\u30c8: Markdown\u3092\u751f\u6210\u3059\u308b\u5834\u5408\uff08\u4f8b: <code>table.to_markdown()</code>\uff09\u3001Python\u306e\u6539\u884c (<code>\\n</code>) \u306f\u3001\u30c6\u30fc\u30d6\u30eb\u69cb\u9020\u3092\u7dad\u6301\u3059\u308b\u305f\u3081\u306b\u81ea\u52d5\u7684\u306b <code>&lt;br&gt;</code> \u30bf\u30b0\u306b\u5909\u63db\u3055\u308c\u307e\u3059\u3002</p> <p>\u3053\u308c\u3092\u7121\u52b9\u306b\u3059\u308b\u306b\u306f\u3001<code>ParsingSchema</code> \u3067 <code>convert_br_to_newline=False</code> \u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002</p>"},{"location":"ja/#11-api","title":"11. \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3 (\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0API)","text":"<p>\u672c\u5f53\u306b10GB\u306eMarkdown\u30d5\u30a1\u30a4\u30eb\u304c\u3042\u308a\u307e\u3059\u304b\uff1f</p> <p>\u304a\u305d\u3089\u304f\u306a\u3044\u3067\u3057\u3087\u3046\u3002\u305d\u3046\u3067\u306a\u3044\u3053\u3068\u3092\u5fc3\u304b\u3089\u9858\u3063\u3066\u3044\u307e\u3059\u3002Markdown\u306f\u305d\u306e\u305f\u3081\u306b\u4f5c\u3089\u308c\u305f\u3082\u306e\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002</p> <p>\u3057\u304b\u3057 \u4e07\u304c\u4e00\u3042\u308b\u5834\u5408 \u2014\u305f\u3068\u3048\u3070\u3001\u81a8\u5927\u306a\u30ed\u30b0\u3092\u751f\u6210\u3057\u3066\u3044\u305f\u308a\u3001\u6a19\u6e96\u30b3\u30f3\u30d0\u30fc\u30bf\u306e\u76e3\u67fb\u3092\u884c\u3063\u3066\u3044\u308b\u5834\u5408\u2014\u3053\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306f\u3042\u306a\u305f\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059\u3002Excel\u304c1,048,576\u884c\u3067\u8ae6\u3081\u308b\u4e00\u65b9\u3067\u3001<code>md-spreadsheet-parser</code> \u306f \u7121\u5236\u9650\u306e\u30b5\u30a4\u30ba \u306e\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u51e6\u7406\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3001\u30e1\u30e2\u30ea\u4f7f\u7528\u91cf\u3092\u4e00\u5b9a\u306b\u4fdd\u3061\u307e\u3059\u3002</p> <p>scan_tables_iter: \u3053\u306e\u95a2\u6570\u306f\u30d5\u30a1\u30a4\u30eb\u3092\u884c\u3054\u3068\u306b\u8aad\u307f\u8fbc\u307f\u3001<code>Table</code> \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c\u898b\u3064\u304b\u308b\u305f\u3073\u306byield\u3057\u307e\u3059\u3002\u30d5\u30a1\u30a4\u30eb\u5168\u4f53\u3092\u30e1\u30e2\u30ea\u306b\u8aad\u307f\u8fbc\u3080\u3053\u3068\u306f \u3042\u308a\u307e\u305b\u3093\u3002</p> <pre><code>from md_spreadsheet_parser import scan_tables_iter\n\n# \u5de8\u5927\u306a\u30ed\u30b0\u30d5\u30a1\u30a4\u30eb\u3092\u51e6\u7406 (\u4f8b: 10GB)\n# \u30e1\u30e2\u30ea\u4f7f\u7528\u91cf\u306f\u4f4e\u3044\u307e\u307e (\u5358\u4e00\u306e\u30c6\u30fc\u30d6\u30eb\u30d6\u30ed\u30c3\u30af\u306e\u30b5\u30a4\u30ba\u306e\u307f)\nfor table in scan_tables_iter(\"huge_server_log.md\"):\n    print(f\"Found table with {len(table.rows)} rows\")\n\n    # \u884c\u306e\u51e6\u7406...\n    for row in table.rows:\n        pass\n</code></pre> <p>\u3053\u308c\u306f\u3001\u30c7\u30fc\u30bf\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3001\u30ed\u30b0\u5206\u6790\u3001\u304a\u3088\u3073\u6a19\u6e96\u7684\u306a\u30b9\u30d7\u30ec\u30c3\u30c9\u30b7\u30fc\u30c8\u30a8\u30c7\u30a3\u30bf\u3067\u958b\u304f\u306b\u306f\u5927\u304d\u3059\u304e\u308b\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u306e\u51e6\u7406\u306b\u6700\u9069\u3067\u3059\u3002</p>"},{"location":"ja/#12","title":"12. \u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u3088\u308b\u64cd\u4f5c","text":"<p>\u3053\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306f\u3001\u30c7\u30fc\u30bf\u69cb\u9020\u3092\u5909\u66f4\u3059\u308b\u305f\u3081\u306e\u4e0d\u5909\u30e1\u30bd\u30c3\u30c9\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u30e1\u30bd\u30c3\u30c9\u306f\u3001\u5909\u66f4\u304c\u9069\u7528\u3055\u308c\u305f \u65b0\u3057\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9 \u3092\u8fd4\u3057\u3001\u5143\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306f\u5909\u66f4\u3057\u307e\u305b\u3093\u3002</p> <p>\u30ef\u30fc\u30af\u30d6\u30c3\u30af\u64cd\u4f5c</p> <pre><code># \u65b0\u3057\u3044\u30b7\u30fc\u30c8\u306e\u8ffd\u52a0 (\u30d8\u30c3\u30c0\u30fcA, B, C\u3092\u6301\u3064\u30c7\u30d5\u30a9\u30eb\u30c8\u30c6\u30fc\u30d6\u30eb\u3092\u4f5c\u6210)\nnew_wb = workbook.add_sheet(\"New Sheet\")\n\n# \u30b7\u30fc\u30c8\u540d\u306e\u5909\u66f4\nnew_wb = workbook.rename_sheet(sheet_index=0, new_name(\"Budget 2024\"))\n\n# \u30b7\u30fc\u30c8\u306e\u524a\u9664\nnew_wb = workbook.delete_sheet(sheet_index=1)\n</code></pre> <p>\u30b7\u30fc\u30c8\u64cd\u4f5c</p> <pre><code># \u30b7\u30fc\u30c8\u540d\u306e\u5909\u66f4 (\u76f4\u63a5\u30e1\u30bd\u30c3\u30c9)\nnew_sheet = sheet.rename(\"Q1 Data\")\n\n# \u30c6\u30fc\u30d6\u30eb\u30e1\u30bf\u30c7\u30fc\u30bf\u306e\u66f4\u65b0\nnew_sheet = sheet.update_table_metadata(\n    table_index=0, \n    name=\"Expenses\", \n    description=\"Monthly expense report\"\n)\n</code></pre> <p>\u30c6\u30fc\u30d6\u30eb\u64cd\u4f5c</p> <pre><code># \u30bb\u30eb\u306e\u66f4\u65b0 (\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u304c\u7bc4\u56f2\u5916\u306e\u5834\u5408\u3001\u81ea\u52d5\u7684\u306b\u30c6\u30fc\u30d6\u30eb\u3092\u62e1\u5f35)\nnew_table = table.update_cell(row_idx=5, col_idx=2, value=\"Updated\")\n\n# \u884c\u306e\u524a\u9664 (\u69cb\u9020\u7684\u306a\u524a\u9664)\nnew_table = table.delete_row(row_idx=2)\n\n# \u5217\u30c7\u30fc\u30bf\u306e\u30af\u30ea\u30a2 (\u30d8\u30c3\u30c0\u30fc\u3068\u884c\u69cb\u9020\u306f\u4fdd\u6301\u3057\u3001\u30bb\u30eb\u3092\u7a7a\u306b\u3059\u308b)\nnew_table = table.clear_column_data(col_idx=3)\n</code></pre>"},{"location":"ja/#13","title":"13. \u30d3\u30b8\u30e5\u30a2\u30eb\u30e1\u30bf\u30c7\u30fc\u30bf\u306e\u6c38\u7d9a\u5316","text":"<p>\u3053\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306f\u3001Markdown\u30c6\u30fc\u30d6\u30eb\u306e\u69cb\u9020\u81ea\u4f53\u3092\u5909\u66f4\u3059\u308b\u3053\u3068\u306a\u304f\u3001\u30d3\u30b8\u30e5\u30a2\u30eb\u72b6\u614b\uff08\u5217\u5e45\u3084\u30d5\u30a3\u30eb\u30bf\u8a2d\u5b9a\u306a\u3069\uff09\u3092\u6c38\u7d9a\u5316\u3059\u308b\u3053\u3068\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u30c6\u30fc\u30d6\u30eb\u306e\u5f8c\u306b\u8ffd\u52a0\u3055\u308c\u308b\u96a0\u3057HTML\u30b3\u30e1\u30f3\u30c8\u306b\u3088\u3063\u3066\u5b9f\u73fe\u3055\u308c\u307e\u3059\u3002</p> <pre><code>| A | B |\n|---|---|\n| 1 | 2 |\n\n&lt;!-- md-spreadsheet-table-metadata: {\"columnWidths\": [100, 200]} --&gt;\n</code></pre> <p>\u3053\u308c\u306b\u3088\u308a\u3001\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u4fdd\u8a3c\u3055\u308c\u307e\u3059\uff1a 1.  \u30af\u30ea\u30fc\u30f3\u306a\u30c7\u30fc\u30bf: \u30c6\u30fc\u30d6\u30eb\u306f\u6a19\u6e96\u7684\u306aMarkdown\u306e\u307e\u307e\u3067\u3042\u308a\u3001\u3069\u306e\u30ec\u30f3\u30c0\u30e9\u30fc\u3067\u3082\u8aad\u307f\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 2.  \u30ea\u30c3\u30c1\u306a\u72b6\u614b: \u4e92\u63db\u6027\u306e\u3042\u308b\u30c4\u30fc\u30eb\uff08\u79c1\u305f\u3061\u304c\u63d0\u4f9b\u3059\u308bVS Code\u62e1\u5f35\u6a5f\u80fd\u306a\u3069\uff09\u306f\u3001\u3053\u306e\u30b3\u30e1\u30f3\u30c8\u3092\u8aad\u307f\u53d6\u3063\u3066UI\u306e\u72b6\u614b\uff08\u5217\u5e45\u3001\u975e\u8868\u793a\u5217\u306a\u3069\uff09\u3092\u5fa9\u5143\u3067\u304d\u307e\u3059\u3002 3.  \u5805\u7262\u6027: \u30d1\u30fc\u30b5\u30fc\u306f\u3001\u7a7a\u884c\u3067\u533a\u5207\u3089\u308c\u3066\u3044\u3066\u3082\u3001\u3053\u306e\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u76f4\u524d\u306e\u30c6\u30fc\u30d6\u30eb\u306b\u81ea\u52d5\u7684\u306b\u95a2\u9023\u4ed8\u3051\u307e\u3059\u3002</p>"},{"location":"ja/#cli","title":"\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9 (CLI)","text":"<p><code>md-spreadsheet-parser</code> \u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u7528\u3057\u3066Markdown\u30d5\u30a1\u30a4\u30eb\u3092\u89e3\u6790\u3057\u3001JSON\u3092\u51fa\u529b\u3067\u304d\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u30c7\u30fc\u30bf\u3092\u4ed6\u306e\u30c4\u30fc\u30eb\u306b\u30d1\u30a4\u30d7\u51e6\u7406\u3059\u308b\u5834\u5408\u306b\u4fbf\u5229\u3067\u3059\u3002</p> <pre><code># \u30d5\u30a1\u30a4\u30eb\u304b\u3089\u8aad\u307f\u8fbc\u3080\nmd-spreadsheet-parser input.md\n\n# \u6a19\u6e96\u5165\u529b\uff08\u30d1\u30a4\u30d7\uff09\u304b\u3089\u8aad\u307f\u8fbc\u3080\ncat input.md | md-spreadsheet-parser\n</code></pre> <p>\u30aa\u30d7\u30b7\u30e7\u30f3: - <code>--scan</code>: \u30ef\u30fc\u30af\u30d6\u30c3\u30af\u69cb\u9020\u3092\u7121\u8996\u3057\u3066\u3059\u3079\u3066\u306e\u30c6\u30fc\u30d6\u30eb\u3092\u30b9\u30ad\u30e3\u30f3\u3057\u307e\u3059\uff08\u30c6\u30fc\u30d6\u30eb\u306e\u30ea\u30b9\u30c8\u3092\u8fd4\u3057\u307e\u3059\uff09\u3002 - <code>--root-marker</code>: \u30eb\u30fc\u30c8\u30de\u30fc\u30ab\u30fc\u3092\u660e\u793a\u7684\u306b\u8a2d\u5b9a\u3057\u307e\u3059\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: \u81ea\u52d5\u691c\u51fa\uff09\u3002 - <code>--sheet-header-level</code>: \u30b7\u30fc\u30c8\u306e\u30d8\u30c3\u30c0\u30fc\u30ec\u30d9\u30eb\u3092\u8a2d\u5b9a\u3057\u307e\u3059\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: 2\uff09\u3002 - <code>--table-header-level</code>: \u30c6\u30fc\u30d6\u30eb\u306e\u30d8\u30c3\u30c0\u30fc\u30ec\u30d9\u30eb\u3092\u8a2d\u5b9a\u3057\u307e\u3059\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: 3\uff09\u3002 - <code>--capture-description</code>: \u30c6\u30fc\u30d6\u30eb\u306e\u8aac\u660e\u3092\u30ad\u30e3\u30d7\u30c1\u30e3\u3057\u307e\u3059\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: True\uff09\u3002 - <code>--column-separator</code>: \u5217\u306e\u533a\u5207\u308a\u306b\u4f7f\u7528\u3059\u308b\u6587\u5b57\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: <code>|</code>\uff09\u3002 - <code>--header-separator-char</code>: \u533a\u5207\u308a\u884c\u3067\u4f7f\u7528\u3059\u308b\u6587\u5b57\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: <code>-</code>\uff09\u3002 - <code>--no-outer-pipes</code>: \u5916\u5074\u306e\u30d1\u30a4\u30d7\u304c\u306a\u3044\u30c6\u30fc\u30d6\u30eb\u3092\u8a31\u53ef\u3057\u307e\u3059\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: False\uff09\u3002 - <code>--no-strip-whitespace</code>: \u30bb\u30eb\u306e\u5024\u304b\u3089\u7a7a\u767d\u3092\u9664\u53bb\u3057\u307e\u305b\u3093\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: False\uff09\u3002 - <code>--no-br-conversion</code>: <code>&lt;br&gt;</code> \u30bf\u30b0\u306e\u6539\u884c\u3078\u306e\u81ea\u52d5\u5909\u63db\u3092\u7121\u52b9\u306b\u3057\u307e\u3059\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: False\uff09\u3002</p>"},{"location":"ja/#configuration","title":"\u8a2d\u5b9a (Configuration)","text":"<p><code>ParsingSchema</code> \u3068 <code>MultiTableParsingSchema</code> \u3092\u4f7f\u7528\u3057\u3066\u3001\u89e3\u6790\u52d5\u4f5c\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3067\u304d\u307e\u3059\u3002</p> \u30aa\u30d7\u30b7\u30e7\u30f3 \u30c7\u30d5\u30a9\u30eb\u30c8 \u8aac\u660e <code>column_separator</code> <code>\\|</code> \u5217\u306e\u533a\u5207\u308a\u306b\u4f7f\u7528\u3059\u308b\u6587\u5b57\u3002 <code>header_separator_char</code> <code>-</code> \u533a\u5207\u308a\u884c\u3067\u4f7f\u7528\u3059\u308b\u6587\u5b57\u3002 <code>require_outer_pipes</code> <code>True</code> <code>True</code> \u306e\u5834\u5408\u3001\u751f\u6210\u3055\u308c\u308bMarkdown\u30c6\u30fc\u30d6\u30eb\u306b\u5916\u5074\u306e\u30d1\u30a4\u30d7\u304c\u542b\u307e\u308c\u307e\u3059\u3002 <code>strip_whitespace</code> <code>True</code> <code>True</code> \u306e\u5834\u5408\u3001\u30bb\u30eb\u306e\u5024\u304b\u3089\u7a7a\u767d\u304c\u9664\u53bb\u3055\u308c\u307e\u3059\u3002 <code>convert_br_to_newline</code> <code>True</code> <code>True</code> \u306e\u5834\u5408\u3001<code>&lt;br&gt;</code> \u30bf\u30b0\u306f <code>\\n</code> \u306b\u5909\u63db\u3055\u308c\u307e\u3059\uff08\u9006\u3082\u540c\u69d8\uff09\u3002 <code>root_marker</code> <code>None</code> (MultiTable) \u30c7\u30fc\u30bf\u30bb\u30af\u30b7\u30e7\u30f3\u306e\u958b\u59cb\u3092\u793a\u3059\u30de\u30fc\u30ab\u30fc\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f\u81ea\u52d5\u691c\u51fa\u3002 <code>sheet_header_level</code> <code>2</code> (MultiTable) \u30b7\u30fc\u30c8\u306e\u30d8\u30c3\u30c0\u30fc\u30ec\u30d9\u30eb\u3002 <code>table_header_level</code> <code>3</code> (MultiTable) \u30c6\u30fc\u30d6\u30eb\u306e\u30d8\u30c3\u30c0\u30fc\u30ec\u30d9\u30eb\u3002 <code>capture_description</code> <code>True</code> (MultiTable) \u30d8\u30c3\u30c0\u30fc\u3068\u30c6\u30fc\u30d6\u30eb\u306e\u9593\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u30ad\u30e3\u30d7\u30c1\u30e3\u3057\u307e\u3059\u3002"},{"location":"ja/#ecosystem","title":"\u30a8\u30b3\u30b7\u30b9\u30c6\u30e0 (Ecosystem)","text":"<p>\u3053\u306e\u30d1\u30fc\u30b5\u30fc\u306f\u3001\u65b0\u3057\u3044\u30a8\u30b3\u30b7\u30b9\u30c6\u30e0\u3067\u3042\u308b \u30c6\u30ad\u30b9\u30c8\u30d9\u30fc\u30b9\u306e\u8868\u8a08\u7b97\u7ba1\u7406 \u306e\u4e2d\u6838\u3068\u306a\u308b\u57fa\u76e4\u3067\u3059\u3002</p> <p>Markdown\u30d5\u30a1\u30a4\u30eb\u306e\u5b8c\u5168\u306aGUI\u30b9\u30d7\u30ec\u30c3\u30c9\u30b7\u30fc\u30c8\u30a8\u30c7\u30a3\u30bf\u3068\u3057\u3066\u6a5f\u80fd\u3059\u308b PengSheets \u3092\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>\u30d3\u30b8\u30e7\u30f3: \"Excel\u306e\u3088\u3046\u306aUX\u3001Git\u30cd\u30a4\u30c6\u30a3\u30d6\u306a\u30c7\u30fc\u30bf\" \u9ad8\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306a\u30a8\u30c7\u30a3\u30bf\u3068\u3053\u306e\u5805\u7262\u306a\u30d1\u30fc\u30b5\u30fc\u3092\u7d44\u307f\u5408\u308f\u305b\u308b\u3053\u3068\u3067\u3001\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u304a\u3051\u308b\u30d0\u30a4\u30ca\u30ea\u30b9\u30d7\u30ec\u30c3\u30c9\u30b7\u30fc\u30c8\u30d5\u30a1\u30a4\u30eb\u306e\u7ba1\u7406\u3068\u3044\u3046\u9577\u5e74\u306e\u554f\u984c\u3092\u89e3\u6c7a\u3059\u308b\u3053\u3068\u3092\u76ee\u6307\u3057\u3066\u3044\u307e\u3059\u3002 *   \u4eba\u9593\u306e\u305f\u3081\u306b: \u5feb\u9069\u3067\u99b4\u67d3\u307f\u306e\u3042\u308bUI\uff08\u30bb\u30eb\u306e\u66f8\u5f0f\u8a2d\u5b9a\u3001\u6539\u5584\u3055\u308c\u305f\u30ca\u30d3\u30b2\u30fc\u30b7\u30e7\u30f3\u3001\u8996\u899a\u7684\u306a\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\uff09\u3067\u30c7\u30fc\u30bf\u3092\u7de8\u96c6\u3067\u304d\u307e\u3059\u3002 *   \u30de\u30b7\u30f3\u306e\u305f\u3081\u306b: \u30c7\u30fc\u30bf\u306f\u30af\u30ea\u30fc\u30f3\u3067\u5dee\u5206\u53ef\u80fd\u306aMarkdown\u3068\u3057\u3066\u4fdd\u5b58\u3055\u308c\u3001\u3053\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u77ac\u6642\u306b\u89e3\u6790\u3001\u691c\u8a3c\u3001Python\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3078\u306e\u5909\u63db\u3092\u884c\u3044\u307e\u3059\u3002</p>"},{"location":"ja/#_5","title":"\u30e9\u30a4\u30bb\u30f3\u30b9","text":"<p>\u3053\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306f MIT License \u306e\u4e0b\u3067\u30e9\u30a4\u30bb\u30f3\u30b9\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"ja/COOKBOOK/","title":"\u30ec\u30b7\u30d4\u96c6","text":"<p>\u3053\u306e\u30ac\u30a4\u30c9\u3067\u306f\u3001\u4e00\u822c\u7684\u306a\u30bf\u30b9\u30af\u306b\u5bfe\u3059\u308b\u5373\u5ea7\u306e\u89e3\u6c7a\u7b56\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"ja/COOKBOOK/#_2","title":"\u76ee\u6b21","text":"<ol> <li>\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb</li> <li>\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30c6\u30fc\u30d6\u30eb\u3092\u8aad\u307f\u8fbc\u3080</li> <li>\u30c6\u30ad\u30b9\u30c8\u304b\u3089\u30c6\u30fc\u30d6\u30eb\u3092\u8aad\u307f\u8fbc\u3080</li> <li>Excel \u9023\u643a</li> <li>Pandas \u9023\u643a</li> <li>\u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u3088\u308b\u7de8\u96c6</li> <li>\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3068Lint</li> <li>JSON\u5909\u63db</li> <li>\u578b\u5b89\u5168\u306a\u691c\u8a3c</li> </ol>"},{"location":"ja/COOKBOOK/#1","title":"1. \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code>pip install md-spreadsheet-parser\n</code></pre>"},{"location":"ja/COOKBOOK/#2","title":"2. \u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30c6\u30fc\u30d6\u30eb\u3092\u8aad\u307f\u8fbc\u3080 (\u63a8\u5968)","text":"<p>Markdown\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\u3059\u308b\u6700\u3082\u7c21\u5358\u306a\u65b9\u6cd5\u306f <code>scan_tables_from_file</code> \u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u3053\u308c\u306f\u30d5\u30a1\u30a4\u30eb\u69cb\u9020\uff08<code>#</code> \u3084 <code>##</code> \u306a\u3069\u306e\u30d8\u30c3\u30c0\u30fc\uff09\u306b\u95a2\u4fc2\u306a\u304f\u6a5f\u80fd\u3057\u307e\u3059\u3002</p> <p>data.md</p> <pre><code>| ID | Name |\n| -- | ---- |\n| 1  | Alice |\n| 2  | Bob   |\n</code></pre> <p>Python</p> <pre><code>from md_spreadsheet_parser import scan_tables_from_file\n\n# Table\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u30ea\u30b9\u30c8\u3092\u8fd4\u3057\u307e\u3059\ntables = scan_tables_from_file(\"data.md\")\n\nfor table in tables:\n    print(table.rows)\n    # [['1', 'Alice'], ['2', 'Bob']]\n</code></pre>"},{"location":"ja/COOKBOOK/#3","title":"3. \u30c6\u30ad\u30b9\u30c8\u304b\u3089\u30c6\u30fc\u30d6\u30eb\u3092\u8aad\u307f\u8fbc\u3080 (\u30b7\u30f3\u30d7\u30eb)","text":"<p>Markdown\u6587\u5b57\u5217\u304c\u3042\u308b\u5834\u5408\u306f\u3001<code>parse_table</code> \u3092\u4f7f\u7528\u3057\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| ID | Name |\n| -- | ---- |\n| 1  | Alice |\n\"\"\"\n\ntable = parse_table(markdown)\nprint(table.headers) # ['ID', 'Name']\nprint(table.rows[0]) # ['1', 'Alice']\n</code></pre>"},{"location":"ja/COOKBOOK/#4-excel","title":"4. Excel \u9023\u643a","text":""},{"location":"ja/COOKBOOK/#excel-tsvcsv-markdown","title":"Excel (TSV/CSV) \u2192 Markdown","text":"<p>\u3053\u308c\u304c\u6700\u3082\u7c21\u5358\u306a\u65b9\u6cd5\u3067\u3059\uff01 Excel\u306e\u30bb\u30eb\u3092\u30b3\u30d4\u30fc\u3057\u3066\u3001\u6587\u5b57\u5217\u3068\u3057\u3066\u8cbc\u308a\u4ed8\u3051\u308b\u3060\u3051\u3067\u3059\u3002</p> <p>Excel\u304b\u3089\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3055\u308c\u305fTSV\u307e\u305f\u306fCSV\u30c7\u30fc\u30bf\u3092Markdown\u306b\u5909\u63db\u3057\u307e\u3059\u3002\u7d50\u5408\u3055\u308c\u305f\u30d8\u30c3\u30c0\u30fc\u3084\u30bb\u30eb\u5185\u6539\u884c\u3082\u51e6\u7406\u3057\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import parse_excel, ExcelParsingSchema\n\n# Excel\u30c7\u30fc\u30bf (TSV\u5f62\u5f0f) \u3092\u8cbc\u308a\u4ed8\u3051\u307e\u3059\ntsv_data = \"\"\"\nID\\tName\\tNotes\n1\\tAlice\\t\"Lines\ninclude\nnewlines\"\n2\\tBob\\tSimple\n\"\"\".strip()\n\ntable = parse_excel(tsv_data)\nprint(table.to_markdown())\n</code></pre> <p>\u7d50\u5408\u30d8\u30c3\u30c0\u30fc\u3042\u308a (\u524d\u65b9\u57cb\u3081)</p> <pre><code># Excel\u306e\u7d50\u5408\u30bb\u30eb\u306f\u6b21\u306e\u3088\u3046\u306b\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3055\u308c\u307e\u3059: \"Category\\t\\t\\tInfo\"\ntsv = \"Category\\t\\t\\tInfo\\nA\\tB\\tC\\tD\"\ntable = parse_excel(tsv)\n# Headers: [\"Category\", \"Category\", \"Category\", \"Info\"]\n</code></pre> <p>2\u884c\u968e\u5c64\u30d8\u30c3\u30c0\u30fc\u3042\u308a</p> <pre><code># \u89aa\u884c: \"Info\\t\\tMetrics\\t\"\n# \u5b50\u884c: \"Name\\tID\\tScore\\tRank\"\ntsv = \"Info\\t\\tMetrics\\t\\nName\\tID\\tScore\\tRank\\nAlice\\t001\\t95\\t1\"\ntable = parse_excel(tsv, ExcelParsingSchema(header_rows=2))\n# Headers: [\"Info - Name\", \"Info - ID\", \"Metrics - Score\", \"Metrics - Rank\"]\n</code></pre>"},{"location":"ja/COOKBOOK/#excel-xlsx-markdown-with-openpyxl","title":"Excel (.xlsx) \u2192 Markdown (with openpyxl)","text":"<p><code>openpyxl</code> \u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u306f\u3001Worksheet\u3092\u76f4\u63a5\u6e21\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <pre><code># pip install openpyxl  # \u30e6\u30fc\u30b6\u30fc\u7ba1\u7406\u306e\u4f9d\u5b58\u95a2\u4fc2\nimport openpyxl\nfrom md_spreadsheet_parser import parse_excel, ExcelParsingSchema\n\nwb = openpyxl.load_workbook(\"report.xlsx\", data_only=True)\nws = wb[\"SalesData\"]  # \u540d\u524d\u3067\u30b7\u30fc\u30c8\u3092\u9078\u629e\n\ntable = parse_excel(ws, ExcelParsingSchema(header_rows=2))\nprint(table.to_markdown())\n</code></pre>"},{"location":"ja/COOKBOOK/#5-pandas","title":"5. Pandas \u9023\u643a","text":"<p>\u3053\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306f\u3001Markdown\u3068\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30b9\u30c4\u30fc\u30eb\u306e\u67b6\u3051\u6a4b\u3068\u3057\u3066\u6a5f\u80fd\u3057\u307e\u3059\u3002</p>"},{"location":"ja/COOKBOOK/#markdown-pandas-dataframe","title":"Markdown -&gt; Pandas DataFrame","text":"<p>\u89e3\u6790\u3055\u308c\u305f\u30c6\u30fc\u30d6\u30eb\u3092\u76f4\u63a5\u8f9e\u66f8\u306e\u30ea\u30b9\u30c8\u306b\u5909\u63db\u3057\u3001Pandas\u306b\u53d6\u308a\u8fbc\u3081\u308b\u3088\u3046\u306b\u3057\u307e\u3059\u3002</p> <pre><code>import pandas as pd\nfrom md_spreadsheet_parser import scan_tables_from_file\n\ntables = scan_tables_from_file(\"data.md\")\ndf = pd.DataFrame(tables[0].to_models(dict))\n\nprint(df)\n#   ID   Name\n# 0  1  Alice\n# 1  2    Bob\n</code></pre>"},{"location":"ja/COOKBOOK/#pandas-dataframe-markdown","title":"Pandas DataFrame -&gt; Markdown","text":"<p>Pandas DataFrame \u3092 <code>Table</code> \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3057\u3066Markdown\u3092\u751f\u6210\u3057\u307e\u3059\u3002</p> <pre><code>import pandas as pd\nfrom md_spreadsheet_parser import Table\n\n# 1. DataFrame\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\ndf = pd.DataFrame({\n    \"ID\": [1, 2],\n    \"Name\": [\"Alice\", \"Bob\"]\n})\n\n# 2. Table\u3078\u306e\u5909\u63db\n# \u30d1\u30fc\u30b5\u30fc\u306e\u305f\u3081\u306b\u3059\u3079\u3066\u306e\u30c7\u30fc\u30bf\u304c\u6587\u5b57\u5217\u5316\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\nheaders = df.columns.tolist()\nrows = df.astype(str).values.tolist()\n\ntable = Table(headers=headers, rows=rows)\n\n# 3. Markdown\u306e\u751f\u6210\nprint(table.to_markdown())\n# | ID | Name |\n# | --- | --- |\n# | 1 | Alice |\n# | 2 | Bob |\n</code></pre>"},{"location":"ja/COOKBOOK/#6-excel","title":"6. \u30d7\u30ed\u30b0\u30e9\u30e0\u306b\u3088\u308b\u7de8\u96c6 (Excel\u30e9\u30a4\u30af)","text":"<p>\u30c6\u30fc\u30d6\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u3001\u30ed\u30b8\u30c3\u30af\uff08\u6570\u5f0f\u306a\u3069\uff09\u306b\u57fa\u3065\u3044\u3066\u5024\u3092\u5909\u66f4\u3057\u3001\u4fdd\u5b58\u3057\u76f4\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| Item | Price | Qty | Total |\n|---|---|---|---|\n| Apple | 100 | 2 | |\n| Banana | 50 | 3 | |\n\"\"\"\n\ntable = parse_table(markdown)\n\n# \"Total\" \u5217\u306e\u66f4\u65b0\n# 1. \u57fa\u672c\u7684\u306a\u6587\u5b57\u5217\u89e3\u6790 (\u307e\u305f\u306f\u5b89\u5168\u306a\u578b\u306e\u305f\u3081\u306b to_models \u3092\u4f7f\u7528)\nnew_rows = []\nfor row in table.rows:\n    price = int(row[1])\n    qty = int(row[2])\n    total = price * qty\n\n    # \u66f4\u65b0\u3055\u308c\u305fTotal\u3092\u542b\u3080\u65b0\u3057\u3044\u884c\u3092\u4f5c\u6210\n    new_rows.append([row[0], row[1], row[2], str(total)])\n\n# 2. \u66f4\u65b0\u3055\u308c\u305f\u30c6\u30fc\u30d6\u30eb\u306e\u4f5c\u6210\nupdated_table = Table(headers=table.headers, rows=new_rows)\nprint(updated_table.to_markdown())\n</code></pre>"},{"location":"ja/COOKBOOK/#7-lint","title":"7. \u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3068Lint","text":"<p>\u4e71\u96d1\u3067\u914d\u7f6e\u306e\u305a\u308c\u305fMarkdown\u30c6\u30fc\u30d6\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u3001\u5b8c\u74a7\u306b\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3057\u3066\u51fa\u529b\u3057\u307e\u3059\u3002</p> <pre><code>from md_spreadsheet_parser import parse_table\n\n# \u4e71\u96d1\u306a\u5165\u529b\nmessy_markdown = \"\"\"\n|Name|Age|\n|---|---|\n|Alice|30|\n|Bob|25|\n\"\"\"\n\ntable = parse_table(messy_markdown)\n\n# \u304d\u308c\u3044\u306aMarkdown\u3092\u51fa\u529b\nprint(table.to_markdown())\n# | Name | Age |\n# | --- | --- |\n# | Alice | 30 |\n# | Bob | 25 |\n</code></pre>"},{"location":"ja/COOKBOOK/#8-json","title":"8. JSON\u5909\u63db","text":"<p>\u30c6\u30fc\u30d6\u30eb\u3092\u76f4\u63a5JSON\u6587\u5b57\u5217\u307e\u305f\u306fAPI\u5229\u7528\u306e\u305f\u3081\u306e\u8f9e\u66f8\u306e\u30ea\u30b9\u30c8\u306b\u5909\u63db\u3057\u307e\u3059\u3002</p> <pre><code>import json\nfrom md_spreadsheet_parser import parse_table\n\nmarkdown = \"\"\"\n| ID | Status |\n| -- | ------ |\n| 1  | Open   |\n\"\"\"\n\ntable = parse_table(markdown)\n\n# \u8f9e\u66f8\u306e\u30ea\u30b9\u30c8\u306b\u5909\u63db\ndata = table.to_models(dict)\n\n# JSON\u3078\u306e\u30c0\u30f3\u30d7\nprint(json.dumps(data, indent=2))\n# [\n#   {\n#     \"ID\": \"1\",\n#     \"Status\": \"Open\"\n#   }\n# ]\n</code></pre>"},{"location":"ja/COOKBOOK/#9","title":"9. \u578b\u5b89\u5168\u306a\u691c\u8a3c","text":"<p>\u30eb\u30fc\u30ba\u306a\u30c6\u30ad\u30b9\u30c8\u3092\u5f37\u304f\u578b\u4ed8\u3051\u3055\u308c\u305fPython\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u5909\u63db\u3057\u307e\u3059\u3002</p> <pre><code>from dataclasses import dataclass\nfrom md_spreadsheet_parser import parse_table\n\n@dataclass\nclass User:\n    id: int\n    name: str\n    active: bool = True\n\nmarkdown = \"\"\"\n| id | name | active |\n| -- | ---- | ------ |\n| 1  | Alice| yes    |\n| 2  | Bob  | no     |\n\"\"\"\n\nusers = parse_table(markdown).to_models(User)\n\nfor user in users:\n    print(f\"{user.name} (Active: {user.active})\")\n    # Alice (Active: True)\n    # Bob (Active: False)\n</code></pre>"}]}